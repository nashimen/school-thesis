{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          sentence\n0              很不错\n1             服务很好\n2            很好很方便\n3            交通很方便\n4            房间很干净\n...            ...\n1304779       没有热水\n1304780       巴适的板\n1304781     非常干净整洁\n1304782  离三里屯近位置不错\n1304783       适合商务\n\n[1304784 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>服务很好</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>很好很方便</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>交通很方便</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>房间很干净</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304779</th>\n      <td>没有热水</td>\n    </tr>\n    <tr>\n      <th>1304780</th>\n      <td>巴适的板</td>\n    </tr>\n    <tr>\n      <th>1304781</th>\n      <td>非常干净整洁</td>\n    </tr>\n    <tr>\n      <th>1304782</th>\n      <td>离三里屯近位置不错</td>\n    </tr>\n    <tr>\n      <th>1304783</th>\n      <td>适合商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1304784 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算情感得分，基于kansei情感词。\n",
    "'''\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "sentences = pd.read_csv('../data/only_sentence.txt', sep='\\t')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m stop_words \u001B[38;5;241m=\u001B[39m read_file(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/baidu_stopwords.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 去掉停用词中的情感词\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# 情感词与停用词有重合导致一些文本分数为0\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m stop_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame(stop_words)\n\u001B[0;32m     17\u001B[0m senti_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/5_Kansei_word_sentiment_lexicon.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     18\u001B[0m stop_df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKansei words\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 读取文件，文件读取函数\n",
    "def read_file(filename):\n",
    "    # with open(filename, 'rb')as f:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # 返回list类型数据\n",
    "        text = text.split('\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "# 读取所需文件\n",
    "# 读取停用词表\n",
    "stop_words = read_file(r\"../data/baidu_stopwords.txt\")\n",
    "# 去掉停用词中的情感词\n",
    "# 情感词与停用词有重合导致一些文本分数为0\n",
    "stop_df = pd.DataFrame(stop_words)\n",
    "senti_df = pd.read_excel('../data/5_Kansei_word_sentiment_lexicon.xlsx')\n",
    "stop_df.columns = ['word']\n",
    "duplicated = pd.merge(stop_df, senti_df, on='word')['word'].tolist()\n",
    "stop_words = list(filter(lambda x: x not in duplicated, stop_words))\n",
    "\n",
    "most = read_file(\"../data/lexicons/most.txt\")\n",
    "very = read_file(\"../data/lexicons/very.txt\")\n",
    "more = read_file(\"../data/lexicons/more.txt\")\n",
    "ish = read_file(\"../data/lexicons/ish.txt\")\n",
    "insufficiently = read_file(\"../data/lexicons/insufficiently.txt\")\n",
    "inverse = read_file(\"../data/lexicons/inverse.txt\")\n",
    "\n",
    "\n",
    "# 读取情感词及分数\n",
    "def get_senti_word(polar):\n",
    "    \"\"\"\n",
    "    读取情感词，Boson或Kansei\n",
    "    :param polar: pos or neg\n",
    "    :return: {sentiment word: score}\n",
    "    \"\"\"\n",
    "\n",
    "    if polar == 'pos':\n",
    "        pos_senti = senti_df[senti_df['sentiment'] > 0]\n",
    "        senti_dict = pos_senti.set_index(keys='word')['sentiment'].to_dict()\n",
    "        return senti_dict\n",
    "    elif polar == 'neg':\n",
    "        neg_senti = senti_df[senti_df['sentiment'] < 0]\n",
    "        senti_dict = neg_senti.set_index(keys='word')['sentiment'].to_dict()\n",
    "        return senti_dict\n",
    "\n",
    "\n",
    "# 去停用词函数\n",
    "def del_stopwords(words):\n",
    "    # 去除停用词后的句子\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "# 获取六种权值的词，根据要求返回list，这个函数是为了配合Django的views下的函数使用\n",
    "def weighted_value(request):\n",
    "    result_dict = []\n",
    "    if request == \"most\":\n",
    "        result_dict = most\n",
    "    elif request == \"very\":\n",
    "        result_dict = very\n",
    "    elif request == \"more\":\n",
    "        result_dict = more\n",
    "    elif request == \"ish\":\n",
    "        result_dict = ish\n",
    "    elif request == \"insufficiently\":\n",
    "        result_dict = insufficiently\n",
    "    elif request == \"inverse\":\n",
    "        result_dict = inverse\n",
    "    elif request == 'pos_dict':\n",
    "        result_dict = get_senti_word(polar='pos')\n",
    "    elif request == 'neg_dict':\n",
    "        result_dict = get_senti_word(polar='neg')\n",
    "    else:\n",
    "        pass\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "print(\"reading sentiment dict .......\")\n",
    "# 读取情感词典\n",
    "pos_dict = weighted_value('pos_dict')\n",
    "neg_dict = weighted_value('neg_dict')\n",
    "# 读取程度副词词典\n",
    "# 权值为2\n",
    "most_dict = weighted_value('most')\n",
    "# 权值为1.75\n",
    "very_dict = weighted_value('very')\n",
    "# 权值为1.50\n",
    "more_dict = weighted_value('more')\n",
    "# 权值为1.25\n",
    "ish_dict = weighted_value('ish')\n",
    "# 权值为0.25\n",
    "insufficient_dict = weighted_value('insufficiently')\n",
    "# 权值为-1\n",
    "inverse_dict = weighted_value('inverse')\n",
    "\n",
    "\n",
    "# 程度副词处理，对不同的程度副词给予不同的权重\n",
    "def match_adverb(word, sentiment_value):\n",
    "    # 最高级权重为\n",
    "    if word in most_dict:\n",
    "        sentiment_value *= 8\n",
    "    # 比较级权重\n",
    "    elif word in very_dict:\n",
    "        sentiment_value *= 6\n",
    "    # 比较级权重\n",
    "    elif word in more_dict:\n",
    "        sentiment_value *= 4\n",
    "    # 轻微程度词权重\n",
    "    elif word in ish_dict:\n",
    "        sentiment_value *= 2\n",
    "    # 相对程度词权重\n",
    "    elif word in insufficient_dict:\n",
    "        sentiment_value *= 0.5\n",
    "    # 否定词权重\n",
    "    elif word in inverse_dict:\n",
    "        sentiment_value *= -1\n",
    "    else:\n",
    "        sentiment_value *= 1\n",
    "    return sentiment_value\n",
    "\n",
    "\n",
    "# 对每一条微博打分\n",
    "def single_sentiment_score(sent):\n",
    "    if pd.isna(sent):\n",
    "        return -2\n",
    "    # 分词\n",
    "    words = list(jieba.cut(sent))\n",
    "    seg_words = del_stopwords(words)\n",
    "    # i，s 记录情感词和程度词出现的位置\n",
    "    i = 0  # 记录扫描到的词位置\n",
    "    s = 0  # 记录情感词的位置\n",
    "    pos_score = []  # 记录正向情感分数\n",
    "    neg_score = []  # 记录负向情感分数\n",
    "\n",
    "    # 逐个查找情感词\n",
    "    for word in seg_words:\n",
    "        # 如果为积极词汇\n",
    "        if word in pos_dict.keys():\n",
    "            pos_word_score = pos_dict.get(word)\n",
    "            # 在情感词前面寻找程度副词\n",
    "            for w in seg_words[s:i]:\n",
    "                pos_word_score = match_adverb(w, pos_word_score)\n",
    "            pos_score.append(pos_word_score)\n",
    "            s = i + 1  # 记录情感词位置\n",
    "            # 如果是消极情感词\n",
    "        elif word in neg_dict.keys():\n",
    "            neg_word_score = neg_dict.get(word)\n",
    "            for w in seg_words[s:i]:\n",
    "                neg_word_score = match_adverb(w, neg_word_score)\n",
    "            neg_score.append(neg_word_score)\n",
    "            s = i + 1\n",
    "        i += 1  # 定位情感词的位置\n",
    "    # 计算情感值\n",
    "    sentiment_score = sum(pos_score) + sum(neg_score)\n",
    "\n",
    "    return sentiment_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "          sentence  sentiment\n0              很不错   3.273251\n1             服务很好   0.000000\n2            很好很方便  53.832072\n3            交通很方便   1.495335\n4            房间很干净   4.909877\n...            ...        ...\n1304779       没有热水   0.000000\n1304780       巴适的板   0.000000\n1304781     非常干净整洁   1.473783\n1304782  离三里屯近位置不错   1.002088\n1304783       适合商务   0.000000\n\n[1304784 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n      <td>3.273251</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>服务很好</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>很好很方便</td>\n      <td>53.832072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>交通很方便</td>\n      <td>1.495335</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>房间很干净</td>\n      <td>4.909877</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304779</th>\n      <td>没有热水</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1304780</th>\n      <td>巴适的板</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1304781</th>\n      <td>非常干净整洁</td>\n      <td>1.473783</td>\n    </tr>\n    <tr>\n      <th>1304782</th>\n      <td>离三里屯近位置不错</td>\n      <td>1.002088</td>\n    </tr>\n    <tr>\n      <th>1304783</th>\n      <td>适合商务</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1304784 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['sentiment'] = sentences['sentence'].apply(single_sentiment_score)\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_274904\\2420715111.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zeros['word'] = zeros['sentence'].apply(lambda x: list(jieba.cut(x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": "         sentence  sentiment                word\n1            服务很好        0.0          [服务, 很, 好]\n6          但是布局合理        0.0          [但是, 布局合理]\n7        没有太拥挤的感觉        0.0  [没有, 太, 拥挤, 的, 感觉]\n9         很喜欢这个花洒        0.0     [很, 喜欢, 这个, 花洒]\n11         必须五星好评        0.0        [必须, 五星, 好评]\n...           ...        ...                 ...\n1304777      适合孩子        0.0            [适合, 孩子]\n1304778    就是房间漏水        0.0        [就是, 房间, 漏水]\n1304779      没有热水        0.0            [没有, 热水]\n1304780      巴适的板        0.0          [巴适, 的, 板]\n1304783      适合商务        0.0            [适合, 商务]\n\n[880239 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>服务很好</td>\n      <td>0.0</td>\n      <td>[服务, 很, 好]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>但是布局合理</td>\n      <td>0.0</td>\n      <td>[但是, 布局合理]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>没有太拥挤的感觉</td>\n      <td>0.0</td>\n      <td>[没有, 太, 拥挤, 的, 感觉]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>很喜欢这个花洒</td>\n      <td>0.0</td>\n      <td>[很, 喜欢, 这个, 花洒]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>必须五星好评</td>\n      <td>0.0</td>\n      <td>[必须, 五星, 好评]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304777</th>\n      <td>适合孩子</td>\n      <td>0.0</td>\n      <td>[适合, 孩子]</td>\n    </tr>\n    <tr>\n      <th>1304778</th>\n      <td>就是房间漏水</td>\n      <td>0.0</td>\n      <td>[就是, 房间, 漏水]</td>\n    </tr>\n    <tr>\n      <th>1304779</th>\n      <td>没有热水</td>\n      <td>0.0</td>\n      <td>[没有, 热水]</td>\n    </tr>\n    <tr>\n      <th>1304780</th>\n      <td>巴适的板</td>\n      <td>0.0</td>\n      <td>[巴适, 的, 板]</td>\n    </tr>\n    <tr>\n      <th>1304783</th>\n      <td>适合商务</td>\n      <td>0.0</td>\n      <td>[适合, 商务]</td>\n    </tr>\n  </tbody>\n</table>\n<p>880239 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = sentences[sentences['sentiment'] == 0]\n",
    "zeros['word'] = zeros['sentence'].apply(lambda x: list(jieba.cut(x)))\n",
    "zeros"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "sentences.to_csv('../data/sentence_sentiment.csv', sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "sentences.to_csv('../data/sentence_sentiment.txt', sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
