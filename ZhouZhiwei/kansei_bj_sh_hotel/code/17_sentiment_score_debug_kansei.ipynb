{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        sentence\n0            很不错\n1           服务很好\n2             很好\n3            很方便\n4          交通很方便\n...          ...\n1396546     巴适的板\n1396547   非常干净整洁\n1396548    离三里屯近\n1396549     位置不错\n1396550     适合商务\n\n[1396551 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>服务很好</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>很好</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>很方便</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>交通很方便</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1396546</th>\n      <td>巴适的板</td>\n    </tr>\n    <tr>\n      <th>1396547</th>\n      <td>非常干净整洁</td>\n    </tr>\n    <tr>\n      <th>1396548</th>\n      <td>离三里屯近</td>\n    </tr>\n    <tr>\n      <th>1396549</th>\n      <td>位置不错</td>\n    </tr>\n    <tr>\n      <th>1396550</th>\n      <td>适合商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1396551 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算情感得分，基于kansei情感词。调整计算规则，防止情感得分过大。\n",
    "'''\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "sentences = pd.read_csv('../data/only_sentence_2.csv', sep='\\t')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin stop length: 1395\n",
      "remove sentiment stop length: 1378\n",
      "remove degree stop length: 1355\n",
      "reading sentiment dict .......\n"
     ]
    }
   ],
   "source": [
    "# 读取文件，文件读取函数\n",
    "def read_file(filename):\n",
    "    # with open(filename, 'rb')as f:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # 返回list类型数据\n",
    "        text = text.split('\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "# 读取所需文件\n",
    "most = read_file(\"../data/lexicons/most.txt\")\n",
    "very = read_file(\"../data/lexicons/very.txt\")\n",
    "more = read_file(\"../data/lexicons/more.txt\")\n",
    "ish = read_file(\"../data/lexicons/ish.txt\")\n",
    "insufficiently = read_file(\"../data/lexicons/insufficiently.txt\")\n",
    "inverse = read_file(\"../data/lexicons/inverse.txt\")\n",
    "\n",
    "# 读取停用词表\n",
    "stop_words = read_file(r\"../data/baidu_stopwords.txt\")\n",
    "print('origin stop length: ' + str(len(stop_words)))\n",
    "\n",
    "# 去掉停用词中的情感词\n",
    "# 情感词与停用词有重合导致一些文本分数为0\n",
    "stop_df = pd.DataFrame(stop_words)\n",
    "senti_df = pd.read_excel('../data/5_Kansei_word_sentiment_lexicon-20221002.xlsx')\n",
    "stop_df.columns = ['word']\n",
    "duplicated = pd.merge(stop_df, senti_df, on='word')['word'].tolist()\n",
    "stop_words = list(filter(lambda x: x not in duplicated, stop_words))\n",
    "print('remove sentiment stop length: ' + str(len(stop_words)))\n",
    "\n",
    "# 去掉停用词中的程度词\n",
    "# 合并程度词\n",
    "degree_word = most + very + more + ish + insufficiently + inverse\n",
    "stop_words = list(filter(lambda x: x not in degree_word, stop_words))\n",
    "print('remove degree stop length: ' + str(len(stop_words)))\n",
    "\n",
    "\n",
    "# 读取情感词及分数\n",
    "def get_senti_word():\n",
    "    sentiment_dict = senti_df.set_index(keys='word')['sentiment'].to_dict()\n",
    "    return sentiment_dict\n",
    "\n",
    "\n",
    "# 去停用词函数\n",
    "def del_stopwords(words):\n",
    "    # 去除停用词后的句子\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "# 获取六种权值的词，根据要求返回list，这个函数是为了配合Django的views下的函数使用\n",
    "def weighted_value(request):\n",
    "    result_dict = []\n",
    "    if request == \"most\":\n",
    "        result_dict = most\n",
    "    elif request == \"very\":\n",
    "        result_dict = very\n",
    "    elif request == \"more\":\n",
    "        result_dict = more\n",
    "    elif request == \"ish\":\n",
    "        result_dict = ish\n",
    "    elif request == \"insufficiently\":\n",
    "        result_dict = insufficiently\n",
    "    elif request == \"inverse\":\n",
    "        result_dict = inverse\n",
    "    elif request == 'senti':\n",
    "        result_dict = get_senti_word()\n",
    "    # elif request == 'pos_dict':\n",
    "    #     result_dict = get_senti_word(polar='pos')\n",
    "    # elif request == 'neg_dict':\n",
    "    #     result_dict = get_senti_word(polar='neg')\n",
    "    else:\n",
    "        pass\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "print(\"reading sentiment dict .......\")\n",
    "# 读取情感词典\n",
    "senti_dict = weighted_value('senti')\n",
    "\n",
    "# 读取程度副词词典\n",
    "# 权值为2\n",
    "most_dict = weighted_value('most')\n",
    "# 权值为1.75\n",
    "very_dict = weighted_value('very')\n",
    "# 权值为1.50\n",
    "more_dict = weighted_value('more')\n",
    "# 权值为1.25\n",
    "ish_dict = weighted_value('ish')\n",
    "# 权值为0.25\n",
    "insufficient_dict = weighted_value('insufficiently')\n",
    "# 权值为-1\n",
    "inverse_dict = weighted_value('inverse')\n",
    "\n",
    "\n",
    "# 程度副词处理，对不同的程度副词给予不同的权重\n",
    "def match_adverb(word, sentiment_value):\n",
    "    # 最高级权重为\n",
    "    if word in most_dict:\n",
    "        sentiment_value *= 2\n",
    "    # 比较级权重\n",
    "    elif word in very_dict:\n",
    "        sentiment_value *= 1.75\n",
    "    # 比较级权重\n",
    "    elif word in more_dict:\n",
    "        sentiment_value *= 1.5\n",
    "    # 轻微程度词权重\n",
    "    elif word in ish_dict:\n",
    "        sentiment_value *= 1.25\n",
    "    # 相对程度词权重\n",
    "    elif word in insufficient_dict:\n",
    "        sentiment_value *= 0.25\n",
    "    # 否定词权重\n",
    "    elif word in inverse_dict:\n",
    "        sentiment_value *= -1\n",
    "    else:\n",
    "        sentiment_value *= 1\n",
    "    return sentiment_value\n",
    "\n",
    "\n",
    "# 每个句子打分\n",
    "def single_sentiment_score(sent):\n",
    "    if pd.isna(sent):\n",
    "        return -2\n",
    "    # 预处理\n",
    "    words = list(jieba.cut(sent))\n",
    "    seg_words = del_stopwords(words)\n",
    "    senti_pos = []\n",
    "    score = []\n",
    "    # 记录情感词位置\n",
    "    for i, word in enumerate(seg_words):\n",
    "        if word in senti_dict.keys():\n",
    "            senti_pos.append(i)\n",
    "\n",
    "    # 计算情感分数\n",
    "    for i in range(len(senti_pos)):\n",
    "        pos = senti_pos[i]\n",
    "        senti_word = seg_words[pos]\n",
    "        word_score = senti_dict.get(senti_word)\n",
    "        # 每个情感词的程度词范围为此情感词与上个情感词之间\n",
    "        if i == 0:\n",
    "            last_pos = 0\n",
    "        else:\n",
    "            last_pos = senti_pos[i - 1]\n",
    "\n",
    "        # 程度词范围\n",
    "        degree_range = seg_words[last_pos + 1: pos]\n",
    "        # 对程度词范围去重，出现多个相同程度词时只计算一次\n",
    "        degree_range = set(degree_range)\n",
    "        for w in degree_range:\n",
    "            word_score = match_adverb(w, word_score)\n",
    "        score.append(word_score)\n",
    "\n",
    "    sentiment_score = sum(score)\n",
    "    return sentiment_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\62774\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.854 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.7049770317971706"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sentiment_score(\n",
    "    '很好很好很好很好很好很好很好很好哈哈哈哈哈很好很好很好很好很好很好很好很好很好很好很好很好很好很好好很好')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1396551/1396551 [02:16<00:00, 10242.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        sentence  sentiment\n0            很不错   1.000000\n1           服务很好   0.000000\n2             很好   0.000000\n3            很方便   0.913670\n4          交通很方便   1.598922\n...          ...        ...\n1396546     巴适的板   0.000000\n1396547   非常干净整洁   1.801001\n1396548    离三里屯近   0.557911\n1396549     位置不错   1.000000\n1396550     适合商务   0.000000\n\n[1396551 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>服务很好</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>很好</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>很方便</td>\n      <td>0.913670</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>交通很方便</td>\n      <td>1.598922</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1396546</th>\n      <td>巴适的板</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1396547</th>\n      <td>非常干净整洁</td>\n      <td>1.801001</td>\n    </tr>\n    <tr>\n      <th>1396548</th>\n      <td>离三里屯近</td>\n      <td>0.557911</td>\n    </tr>\n    <tr>\n      <th>1396549</th>\n      <td>位置不错</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1396550</th>\n      <td>适合商务</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1396551 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "sentences['sentiment'] = sentences['sentence'].progress_apply(single_sentiment_score)\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sentences.to_csv('../data/sentence_sentiment_2.csv', sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
