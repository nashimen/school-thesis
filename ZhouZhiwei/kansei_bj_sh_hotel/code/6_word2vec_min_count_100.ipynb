{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "生成word2vec词向量，min_count=100\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        corpus_path = '../data/word2vec_corpus_with_stoped_punctuation.txt'\n",
    "        for line in open(corpus_path, encoding='utf-8'):\n",
    "            yield utils.simple_preprocess(line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:15:13,327 : INFO : collecting all words and their counts\n",
      "2022-08-23 16:15:13,432 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-23 16:15:13,646 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-23 16:15:13,848 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-23 16:15:14,013 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-23 16:15:14,201 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-23 16:15:14,650 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-23 16:15:14,872 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-23 16:15:15,127 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-23 16:15:15,400 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-23 16:15:15,641 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-23 16:15:15,853 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-23 16:15:16,050 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-23 16:15:16,262 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-23 16:15:16,466 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-23 16:15:16,664 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-23 16:15:16,830 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-23 16:15:17,002 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-23 16:15:17,167 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-23 16:15:17,334 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-23 16:15:17,505 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-23 16:15:17,678 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-23 16:15:17,862 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-23 16:15:18,044 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-23 16:15:18,248 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-23 16:15:18,445 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-23 16:15:18,615 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-23 16:15:18,843 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-23 16:15:19,039 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-23 16:15:19,208 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-23 16:15:19,403 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-23 16:15:19,735 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-23 16:15:20,009 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-23 16:15:20,169 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-23 16:15:20,171 : INFO : Creating a fresh vocabulary\n",
      "2022-08-23 16:15:20,210 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 retains 2796 unique words (3.27% of original 85482, drops 82686)', 'datetime': '2022-08-23T16:15:20.210275', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:15:20,211 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 leaves 3382051 word corpus (88.94% of original 3802827, drops 420776)', 'datetime': '2022-08-23T16:15:20.211264', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:15:20,225 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-23 16:15:20,229 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2022-08-23 16:15:20,230 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2571478.7696258705 word corpus (76.0%% of prior 3382051)', 'datetime': '2022-08-23T16:15:20.230264', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:15:20,251 : INFO : estimated required memory for 2796 words and 200 dimensions: 5871600 bytes\n",
      "2022-08-23 16:15:20,252 : INFO : resetting layer weights\n",
      "2022-08-23 16:15:20,257 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-23T16:15:20.257267', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-23 16:15:20,258 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 2796 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-23T16:15:20.258269', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:15:21,274 : INFO : EPOCH 0 - PROGRESS: at 13.22% examples, 342518 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:22,300 : INFO : EPOCH 0 - PROGRESS: at 25.71% examples, 357320 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:23,306 : INFO : EPOCH 0 - PROGRESS: at 40.45% examples, 363750 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:24,310 : INFO : EPOCH 0 - PROGRESS: at 55.26% examples, 354277 words/s, in_qsize 2, out_qsize 2\n",
      "2022-08-23 16:15:25,319 : INFO : EPOCH 0 - PROGRESS: at 72.19% examples, 360592 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:26,364 : INFO : EPOCH 0 - PROGRESS: at 85.54% examples, 353010 words/s, in_qsize 3, out_qsize 1\n",
      "2022-08-23 16:15:27,349 : INFO : EPOCH 0: training on 3802827 raw words (2571328 effective words) took 7.1s, 362718 effective words/s\n",
      "2022-08-23 16:15:28,356 : INFO : EPOCH 1 - PROGRESS: at 13.08% examples, 331970 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:15:29,422 : INFO : EPOCH 1 - PROGRESS: at 25.11% examples, 346062 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:15:30,440 : INFO : EPOCH 1 - PROGRESS: at 41.18% examples, 365679 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:31,444 : INFO : EPOCH 1 - PROGRESS: at 56.81% examples, 359031 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:32,454 : INFO : EPOCH 1 - PROGRESS: at 72.43% examples, 359044 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:33,467 : INFO : EPOCH 1 - PROGRESS: at 87.56% examples, 360147 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:34,467 : INFO : EPOCH 1 - PROGRESS: at 99.17% examples, 358748 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-23 16:15:34,476 : INFO : EPOCH 1: training on 3802827 raw words (2572233 effective words) took 7.1s, 361100 effective words/s\n",
      "2022-08-23 16:15:35,481 : INFO : EPOCH 2 - PROGRESS: at 13.30% examples, 354050 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:36,490 : INFO : EPOCH 2 - PROGRESS: at 25.81% examples, 365717 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:37,498 : INFO : EPOCH 2 - PROGRESS: at 39.72% examples, 360422 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:38,522 : INFO : EPOCH 2 - PROGRESS: at 54.41% examples, 350137 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-23 16:15:39,527 : INFO : EPOCH 2 - PROGRESS: at 72.00% examples, 360061 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:40,536 : INFO : EPOCH 2 - PROGRESS: at 87.02% examples, 361225 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:41,551 : INFO : EPOCH 2 - PROGRESS: at 99.17% examples, 360804 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:41,581 : INFO : EPOCH 2: training on 3802827 raw words (2571307 effective words) took 7.1s, 362077 effective words/s\n",
      "2022-08-23 16:15:42,586 : INFO : EPOCH 3 - PROGRESS: at 13.80% examples, 382815 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:43,594 : INFO : EPOCH 3 - PROGRESS: at 25.31% examples, 359204 words/s, in_qsize 4, out_qsize 1\n",
      "2022-08-23 16:15:44,598 : INFO : EPOCH 3 - PROGRESS: at 39.95% examples, 363210 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:15:45,640 : INFO : EPOCH 3 - PROGRESS: at 56.55% examples, 360363 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-23 16:15:46,656 : INFO : EPOCH 3 - PROGRESS: at 73.44% examples, 366217 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:15:47,697 : INFO : EPOCH 3 - PROGRESS: at 89.34% examples, 366752 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:15:48,526 : INFO : EPOCH 3: training on 3802827 raw words (2571846 effective words) took 6.9s, 370459 effective words/s\n",
      "2022-08-23 16:15:49,554 : INFO : EPOCH 4 - PROGRESS: at 13.30% examples, 345888 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:15:50,578 : INFO : EPOCH 4 - PROGRESS: at 27.03% examples, 378957 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:51,600 : INFO : EPOCH 4 - PROGRESS: at 42.06% examples, 373930 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:15:52,604 : INFO : EPOCH 4 - PROGRESS: at 58.55% examples, 369967 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:53,633 : INFO : EPOCH 4 - PROGRESS: at 73.73% examples, 364971 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:15:54,649 : INFO : EPOCH 4 - PROGRESS: at 87.54% examples, 359511 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-23 16:15:55,525 : INFO : EPOCH 4: training on 3802827 raw words (2570716 effective words) took 7.0s, 367443 effective words/s\n",
      "2022-08-23 16:15:55,525 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (12857430 effective words) took 35.3s, 364570 effective words/s', 'datetime': '2022-08-23T16:15:55.525989', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:15:55,526 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=2796, vector_size=200, alpha=0.025>', 'datetime': '2022-08-23T16:15:55.526987', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "# CBOW 200\n",
    "cbow200 = gensim.models.Word2Vec(sentences=sentences, vector_size=200, min_count=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:15:55,548 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-u5eb3fed', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-23T16:15:55.548000', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-23 16:15:55,548 : INFO : not storing attribute cum_table\n",
      "2022-08-23 16:15:55,555 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-u5eb3fed\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    cbow200.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:15:55,564 : INFO : collecting all words and their counts\n",
      "2022-08-23 16:15:55,565 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-23 16:15:55,755 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-23 16:15:55,968 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-23 16:15:56,119 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-23 16:15:56,297 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-23 16:15:56,669 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-23 16:15:56,870 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-23 16:15:57,111 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-23 16:15:57,358 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-23 16:15:57,581 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-23 16:15:57,782 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-23 16:15:57,970 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-23 16:15:58,168 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-23 16:15:58,372 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-23 16:15:58,578 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-23 16:15:58,751 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-23 16:15:58,922 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-23 16:15:59,093 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-23 16:15:59,258 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-23 16:15:59,435 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-23 16:15:59,605 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-23 16:15:59,780 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-23 16:15:59,960 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-23 16:16:00,162 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-23 16:16:00,353 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-23 16:16:00,519 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-23 16:16:00,743 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-23 16:16:00,924 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-23 16:16:01,087 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-23 16:16:01,278 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-23 16:16:01,607 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-23 16:16:01,795 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-23 16:16:01,951 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-23 16:16:01,952 : INFO : Creating a fresh vocabulary\n",
      "2022-08-23 16:16:01,986 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 retains 2796 unique words (3.27% of original 85482, drops 82686)', 'datetime': '2022-08-23T16:16:01.986915', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:01,987 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 leaves 3382051 word corpus (88.94% of original 3802827, drops 420776)', 'datetime': '2022-08-23T16:16:01.987909', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:02,001 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-23 16:16:02,004 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2022-08-23 16:16:02,005 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2571478.7696258705 word corpus (76.0%% of prior 3382051)', 'datetime': '2022-08-23T16:16:02.005922', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:02,027 : INFO : estimated required memory for 2796 words and 300 dimensions: 8108400 bytes\n",
      "2022-08-23 16:16:02,028 : INFO : resetting layer weights\n",
      "2022-08-23 16:16:02,031 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-23T16:16:02.031915', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-23 16:16:02,032 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 2796 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-23T16:16:02.032913', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:16:03,053 : INFO : EPOCH 0 - PROGRESS: at 13.30% examples, 348907 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:04,065 : INFO : EPOCH 0 - PROGRESS: at 25.81% examples, 362554 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:16:05,081 : INFO : EPOCH 0 - PROGRESS: at 39.95% examples, 359526 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:16:06,119 : INFO : EPOCH 0 - PROGRESS: at 57.22% examples, 361335 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:07,158 : INFO : EPOCH 0 - PROGRESS: at 72.43% examples, 357475 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:08,160 : INFO : EPOCH 0 - PROGRESS: at 86.28% examples, 355116 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:16:09,153 : INFO : EPOCH 0: training on 3802827 raw words (2571862 effective words) took 7.1s, 361354 effective words/s\n",
      "2022-08-23 16:16:10,174 : INFO : EPOCH 1 - PROGRESS: at 13.02% examples, 319816 words/s, in_qsize 2, out_qsize 1\n",
      "2022-08-23 16:16:11,176 : INFO : EPOCH 1 - PROGRESS: at 25.52% examples, 357579 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:12,266 : INFO : EPOCH 1 - PROGRESS: at 39.44% examples, 347756 words/s, in_qsize 5, out_qsize 2\n",
      "2022-08-23 16:16:13,275 : INFO : EPOCH 1 - PROGRESS: at 57.22% examples, 358255 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:14,277 : INFO : EPOCH 1 - PROGRESS: at 72.80% examples, 358922 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:15,300 : INFO : EPOCH 1 - PROGRESS: at 88.27% examples, 360543 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:16,263 : INFO : EPOCH 1: training on 3802827 raw words (2572572 effective words) took 7.1s, 361904 effective words/s\n",
      "2022-08-23 16:16:17,278 : INFO : EPOCH 2 - PROGRESS: at 13.47% examples, 365215 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:18,290 : INFO : EPOCH 2 - PROGRESS: at 25.11% examples, 353477 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:16:19,308 : INFO : EPOCH 2 - PROGRESS: at 40.45% examples, 364238 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:16:20,324 : INFO : EPOCH 2 - PROGRESS: at 57.59% examples, 365173 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:16:21,344 : INFO : EPOCH 2 - PROGRESS: at 72.36% examples, 359178 words/s, in_qsize 1, out_qsize 2\n",
      "2022-08-23 16:16:22,345 : INFO : EPOCH 2 - PROGRESS: at 87.84% examples, 363118 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:23,305 : INFO : EPOCH 2: training on 3802827 raw words (2571216 effective words) took 7.0s, 365240 effective words/s\n",
      "2022-08-23 16:16:24,317 : INFO : EPOCH 3 - PROGRESS: at 13.22% examples, 344269 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:16:25,328 : INFO : EPOCH 3 - PROGRESS: at 25.31% examples, 357769 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:16:26,340 : INFO : EPOCH 3 - PROGRESS: at 40.45% examples, 365581 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:27,358 : INFO : EPOCH 3 - PROGRESS: at 55.26% examples, 354523 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-23 16:16:28,372 : INFO : EPOCH 3 - PROGRESS: at 72.80% examples, 363037 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:29,378 : INFO : EPOCH 3 - PROGRESS: at 87.02% examples, 360599 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:30,373 : INFO : EPOCH 3: training on 3802827 raw words (2572632 effective words) took 7.1s, 364140 effective words/s\n",
      "2022-08-23 16:16:31,376 : INFO : EPOCH 4 - PROGRESS: at 13.47% examples, 369354 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:32,380 : INFO : EPOCH 4 - PROGRESS: at 25.71% examples, 363360 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:33,400 : INFO : EPOCH 4 - PROGRESS: at 39.95% examples, 361892 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:16:34,414 : INFO : EPOCH 4 - PROGRESS: at 55.06% examples, 353752 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:16:35,416 : INFO : EPOCH 4 - PROGRESS: at 72.00% examples, 360634 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:36,423 : INFO : EPOCH 4 - PROGRESS: at 87.02% examples, 361866 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:37,428 : INFO : EPOCH 4 - PROGRESS: at 99.33% examples, 362830 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:37,451 : INFO : EPOCH 4: training on 3802827 raw words (2571630 effective words) took 7.1s, 363497 effective words/s\n",
      "2022-08-23 16:16:37,452 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (12859912 effective words) took 35.4s, 363084 effective words/s', 'datetime': '2022-08-23T16:16:37.452538', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:16:37,452 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=2796, vector_size=300, alpha=0.025>', 'datetime': '2022-08-23T16:16:37.452538', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# CBOW 300\n",
    "cbow300 = gensim.models.Word2Vec(sentences=sentences, vector_size=300, min_count=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:16:37,460 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-97iuk_mn', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-23T16:16:37.460539', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-23 16:16:37,461 : INFO : not storing attribute cum_table\n",
      "2022-08-23 16:16:37,468 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-97iuk_mn\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    cbow300.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:16:37,475 : INFO : collecting all words and their counts\n",
      "2022-08-23 16:16:37,477 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-23 16:16:37,668 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-23 16:16:37,854 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-23 16:16:38,002 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-23 16:16:38,176 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-23 16:16:38,508 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-23 16:16:38,726 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-23 16:16:38,980 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-23 16:16:39,218 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-23 16:16:39,445 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-23 16:16:39,648 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-23 16:16:39,830 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-23 16:16:40,039 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-23 16:16:40,226 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-23 16:16:40,419 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-23 16:16:40,586 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-23 16:16:40,764 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-23 16:16:40,929 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-23 16:16:41,102 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-23 16:16:41,271 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-23 16:16:41,456 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-23 16:16:41,643 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-23 16:16:41,832 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-23 16:16:42,040 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-23 16:16:42,229 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-23 16:16:42,392 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-23 16:16:42,629 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-23 16:16:42,813 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-23 16:16:42,976 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-23 16:16:43,160 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-23 16:16:43,482 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-23 16:16:43,670 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-23 16:16:43,827 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-23 16:16:43,827 : INFO : Creating a fresh vocabulary\n",
      "2022-08-23 16:16:43,860 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 retains 2796 unique words (3.27% of original 85482, drops 82686)', 'datetime': '2022-08-23T16:16:43.860539', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:43,861 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 leaves 3382051 word corpus (88.94% of original 3802827, drops 420776)', 'datetime': '2022-08-23T16:16:43.861531', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:43,875 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-23 16:16:43,879 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2022-08-23 16:16:43,880 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2571478.7696258705 word corpus (76.0%% of prior 3382051)', 'datetime': '2022-08-23T16:16:43.880526', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:16:43,902 : INFO : estimated required memory for 2796 words and 200 dimensions: 5871600 bytes\n",
      "2022-08-23 16:16:43,903 : INFO : resetting layer weights\n",
      "2022-08-23 16:16:43,906 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-23T16:16:43.906532', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-23 16:16:43,907 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 2796 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-23T16:16:43.907516', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:16:44,921 : INFO : EPOCH 0 - PROGRESS: at 13.08% examples, 328883 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:16:45,942 : INFO : EPOCH 0 - PROGRESS: at 24.64% examples, 345305 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:16:46,955 : INFO : EPOCH 0 - PROGRESS: at 39.44% examples, 354932 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:47,970 : INFO : EPOCH 0 - PROGRESS: at 55.26% examples, 353367 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:48,983 : INFO : EPOCH 0 - PROGRESS: at 70.24% examples, 348900 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:49,986 : INFO : EPOCH 0 - PROGRESS: at 84.00% examples, 350177 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:50,990 : INFO : EPOCH 0 - PROGRESS: at 96.26% examples, 349918 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:51,203 : INFO : EPOCH 0: training on 3802827 raw words (2570917 effective words) took 7.3s, 352497 effective words/s\n",
      "2022-08-23 16:16:52,210 : INFO : EPOCH 1 - PROGRESS: at 13.02% examples, 324291 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-23 16:16:53,256 : INFO : EPOCH 1 - PROGRESS: at 24.13% examples, 332723 words/s, in_qsize 4, out_qsize 2\n",
      "2022-08-23 16:16:54,285 : INFO : EPOCH 1 - PROGRESS: at 38.53% examples, 346840 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:16:55,302 : INFO : EPOCH 1 - PROGRESS: at 54.41% examples, 345417 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:16:56,307 : INFO : EPOCH 1 - PROGRESS: at 70.24% examples, 347059 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:57,311 : INFO : EPOCH 1 - PROGRESS: at 84.00% examples, 348535 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:58,324 : INFO : EPOCH 1 - PROGRESS: at 97.14% examples, 350870 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:16:58,545 : INFO : EPOCH 1: training on 3802827 raw words (2570932 effective words) took 7.3s, 350321 effective words/s\n",
      "2022-08-23 16:16:59,559 : INFO : EPOCH 2 - PROGRESS: at 13.08% examples, 329555 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:17:00,582 : INFO : EPOCH 2 - PROGRESS: at 25.11% examples, 352062 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:01,591 : INFO : EPOCH 2 - PROGRESS: at 39.44% examples, 355392 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:02,606 : INFO : EPOCH 2 - PROGRESS: at 55.26% examples, 353703 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:17:03,620 : INFO : EPOCH 2 - PROGRESS: at 70.98% examples, 351713 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:04,628 : INFO : EPOCH 2 - PROGRESS: at 85.16% examples, 353366 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:05,640 : INFO : EPOCH 2 - PROGRESS: at 96.67% examples, 351424 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:05,856 : INFO : EPOCH 2: training on 3802827 raw words (2572610 effective words) took 7.3s, 352018 effective words/s\n",
      "2022-08-23 16:17:06,876 : INFO : EPOCH 3 - PROGRESS: at 12.82% examples, 297926 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:07,885 : INFO : EPOCH 3 - PROGRESS: at 24.22% examples, 339901 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:08,903 : INFO : EPOCH 3 - PROGRESS: at 37.18% examples, 339830 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:17:09,906 : INFO : EPOCH 3 - PROGRESS: at 53.37% examples, 344847 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:10,926 : INFO : EPOCH 3 - PROGRESS: at 68.57% examples, 342809 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:11,927 : INFO : EPOCH 3 - PROGRESS: at 82.34% examples, 342749 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:12,937 : INFO : EPOCH 3 - PROGRESS: at 94.53% examples, 343420 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-23 16:17:13,246 : INFO : EPOCH 3: training on 3802827 raw words (2571104 effective words) took 7.4s, 348056 effective words/s\n",
      "2022-08-23 16:17:14,263 : INFO : EPOCH 4 - PROGRESS: at 13.15% examples, 335709 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:15,287 : INFO : EPOCH 4 - PROGRESS: at 24.10% examples, 334751 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:16,288 : INFO : EPOCH 4 - PROGRESS: at 36.06% examples, 331539 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:17,299 : INFO : EPOCH 4 - PROGRESS: at 50.45% examples, 329891 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:18,304 : INFO : EPOCH 4 - PROGRESS: at 65.59% examples, 328890 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:17:19,316 : INFO : EPOCH 4 - PROGRESS: at 79.36% examples, 326988 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-23 16:17:20,333 : INFO : EPOCH 4 - PROGRESS: at 93.27% examples, 331446 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:20,911 : INFO : EPOCH 4: training on 3802827 raw words (2572068 effective words) took 7.7s, 335690 effective words/s\n",
      "2022-08-23 16:17:20,912 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (12857631 effective words) took 37.0s, 347458 effective words/s', 'datetime': '2022-08-23T16:17:20.912959', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:17:20,913 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=2796, vector_size=200, alpha=0.025>', 'datetime': '2022-08-23T16:17:20.913964', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# SG 200\n",
    "sg200 = gensim.models.Word2Vec(sentences=sentences, vector_size=200, sg=1, min_count=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:17:20,933 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-vax796a1', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-23T16:17:20.933959', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-23 16:17:20,934 : INFO : not storing attribute cum_table\n",
      "2022-08-23 16:17:20,941 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-vax796a1\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    sg200.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:17:20,948 : INFO : collecting all words and their counts\n",
      "2022-08-23 16:17:20,949 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-23 16:17:21,139 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-23 16:17:21,338 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-23 16:17:21,508 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-23 16:17:21,717 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-23 16:17:22,083 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-23 16:17:22,294 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-23 16:17:22,536 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-23 16:17:22,797 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-23 16:17:23,029 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-23 16:17:23,226 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-23 16:17:23,420 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-23 16:17:23,644 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-23 16:17:23,837 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-23 16:17:24,032 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-23 16:17:24,214 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-23 16:17:24,402 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-23 16:17:24,582 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-23 16:17:24,757 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-23 16:17:24,954 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-23 16:17:25,127 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-23 16:17:25,311 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-23 16:17:25,512 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-23 16:17:25,723 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-23 16:17:25,924 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-23 16:17:26,102 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-23 16:17:26,351 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-23 16:17:26,552 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-23 16:17:26,734 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-23 16:17:26,940 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-23 16:17:27,278 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-23 16:17:27,494 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-23 16:17:27,657 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-23 16:17:27,658 : INFO : Creating a fresh vocabulary\n",
      "2022-08-23 16:17:27,692 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 retains 2796 unique words (3.27% of original 85482, drops 82686)', 'datetime': '2022-08-23T16:17:27.692737', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:17:27,692 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=100 leaves 3382051 word corpus (88.94% of original 3802827, drops 420776)', 'datetime': '2022-08-23T16:17:27.692737', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:17:27,706 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-23 16:17:27,709 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2022-08-23 16:17:27,710 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2571478.7696258705 word corpus (76.0%% of prior 3382051)', 'datetime': '2022-08-23T16:17:27.710778', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-23 16:17:27,732 : INFO : estimated required memory for 2796 words and 300 dimensions: 8108400 bytes\n",
      "2022-08-23 16:17:27,733 : INFO : resetting layer weights\n",
      "2022-08-23 16:17:27,739 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-23T16:17:27.739786', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-23 16:17:27,740 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 2796 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-23T16:17:27.740768', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:17:28,766 : INFO : EPOCH 0 - PROGRESS: at 12.75% examples, 289404 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:29,778 : INFO : EPOCH 0 - PROGRESS: at 23.16% examples, 322050 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:30,823 : INFO : EPOCH 0 - PROGRESS: at 36.06% examples, 327070 words/s, in_qsize 1, out_qsize 1\n",
      "2022-08-23 16:17:31,838 : INFO : EPOCH 0 - PROGRESS: at 50.97% examples, 329444 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:32,850 : INFO : EPOCH 0 - PROGRESS: at 67.08% examples, 331966 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:33,861 : INFO : EPOCH 0 - PROGRESS: at 81.22% examples, 333040 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:34,884 : INFO : EPOCH 0 - PROGRESS: at 93.44% examples, 331634 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:35,421 : INFO : EPOCH 0: training on 3802827 raw words (2570961 effective words) took 7.7s, 334889 effective words/s\n",
      "2022-08-23 16:17:36,442 : INFO : EPOCH 1 - PROGRESS: at 13.08% examples, 326927 words/s, in_qsize 1, out_qsize 1\n",
      "2022-08-23 16:17:37,456 : INFO : EPOCH 1 - PROGRESS: at 24.64% examples, 345584 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-23 16:17:38,464 : INFO : EPOCH 1 - PROGRESS: at 38.04% examples, 346931 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:17:39,492 : INFO : EPOCH 1 - PROGRESS: at 54.72% examples, 349482 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:40,496 : INFO : EPOCH 1 - PROGRESS: at 70.64% examples, 350358 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:41,508 : INFO : EPOCH 1 - PROGRESS: at 83.50% examples, 347548 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:42,513 : INFO : EPOCH 1 - PROGRESS: at 95.94% examples, 347612 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:42,811 : INFO : EPOCH 1: training on 3802827 raw words (2571619 effective words) took 7.4s, 348136 effective words/s\n",
      "2022-08-23 16:17:43,837 : INFO : EPOCH 2 - PROGRESS: at 13.08% examples, 325108 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:17:44,861 : INFO : EPOCH 2 - PROGRESS: at 25.11% examples, 349392 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:45,876 : INFO : EPOCH 2 - PROGRESS: at 38.04% examples, 344244 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:17:46,897 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 344825 words/s, in_qsize 4, out_qsize 1\n",
      "2022-08-23 16:17:47,920 : INFO : EPOCH 2 - PROGRESS: at 70.64% examples, 347969 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-23 16:17:48,935 : INFO : EPOCH 2 - PROGRESS: at 85.16% examples, 350823 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:17:49,953 : INFO : EPOCH 2 - PROGRESS: at 97.70% examples, 351699 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-23 16:17:50,087 : INFO : EPOCH 2: training on 3802827 raw words (2570625 effective words) took 7.3s, 353479 effective words/s\n",
      "2022-08-23 16:17:51,116 : INFO : EPOCH 3 - PROGRESS: at 13.02% examples, 317229 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:52,118 : INFO : EPOCH 3 - PROGRESS: at 23.16% examples, 322983 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:53,126 : INFO : EPOCH 3 - PROGRESS: at 35.61% examples, 327175 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:54,170 : INFO : EPOCH 3 - PROGRESS: at 50.67% examples, 329073 words/s, in_qsize 1, out_qsize 1\n",
      "2022-08-23 16:17:55,184 : INFO : EPOCH 3 - PROGRESS: at 67.59% examples, 337012 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:56,213 : INFO : EPOCH 3 - PROGRESS: at 81.66% examples, 336327 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:17:57,218 : INFO : EPOCH 3 - PROGRESS: at 93.85% examples, 337194 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-23 16:17:57,628 : INFO : EPOCH 3: training on 3802827 raw words (2571869 effective words) took 7.5s, 341158 effective words/s\n",
      "2022-08-23 16:17:58,652 : INFO : EPOCH 4 - PROGRESS: at 13.15% examples, 333232 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-23 16:17:59,663 : INFO : EPOCH 4 - PROGRESS: at 24.64% examples, 345493 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:18:00,666 : INFO : EPOCH 4 - PROGRESS: at 37.18% examples, 340716 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:18:01,680 : INFO : EPOCH 4 - PROGRESS: at 52.32% examples, 339606 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:18:02,682 : INFO : EPOCH 4 - PROGRESS: at 67.59% examples, 339638 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-23 16:18:03,684 : INFO : EPOCH 4 - PROGRESS: at 81.66% examples, 340041 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-23 16:18:04,710 : INFO : EPOCH 4 - PROGRESS: at 94.24% examples, 342332 words/s, in_qsize 1, out_qsize 1\n",
      "2022-08-23 16:18:05,088 : INFO : EPOCH 4: training on 3802827 raw words (2570911 effective words) took 7.5s, 344717 effective words/s\n",
      "2022-08-23 16:18:05,089 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (12855985 effective words) took 37.3s, 344220 effective words/s', 'datetime': '2022-08-23T16:18:05.089841', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-23 16:18:05,090 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=2796, vector_size=300, alpha=0.025>', 'datetime': '2022-08-23T16:18:05.090840', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# SG 300\n",
    "sg300 = gensim.models.Word2Vec(sentences=sentences, vector_size=300, sg=1, min_count=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:18:05,109 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-785adv31', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-23T16:18:05.109848', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-23 16:18:05,110 : INFO : not storing attribute cum_table\n",
      "2022-08-23 16:18:05,117 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-785adv31\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    sg300.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Unnamed: 0\n0                                                     NaN\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[317417 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>317417 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算不同模型的名词词向量：CBOW200, CBOW300 SG200 SG300\n",
    "import pandas as pd\n",
    "\n",
    "nouns = pd.read_csv('../data/nouns.txt')\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    nouns\n0                                                     NaN\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[317417 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>317417 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns.columns = ['nouns']\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    nouns\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n5                房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[269156 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>269156 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = nouns[~ nouns['nouns'].isna()]\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 拆分函数\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_row(data, column):\n",
    "    \"\"\"拆分成行\n",
    "\n",
    "    :param data: 原始数据\n",
    "    :param column: 拆分的列名\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :type column: str\n",
    "    \"\"\"\n",
    "    row_len = list(map(len, data[column].values))\n",
    "    rows = []\n",
    "    for i in data.columns:\n",
    "        if i == column:\n",
    "            row = np.concatenate(data[i].values)\n",
    "        else:\n",
    "            row = np.repeat(data[i].values, row_len)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(np.dstack(tuple(rows))[0], columns=data.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\468032882.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns['temp'] = '1'\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                    nouns temp\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒    1\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议    1\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...    1\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店    1\n5                房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图    1\n...                                                   ...  ...\n317412                                                 孩子    1\n317413                                              房间 热水    1\n317414                                                  板    1\n317415                                                 位置    1\n317416                                                 商务    1\n\n[269156 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>269156 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['temp'] = '1'\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       temp noun\n1         1   交通\n1         1   房间\n1         1   房间\n1         1   面积\n1         1   布局\n...     ...  ...\n317413    1   房间\n317413    1   热水\n317414    1    板\n317415    1   位置\n317416    1   商务\n\n[1365335 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp</th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>1</td>\n      <td>热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>1</td>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>1</td>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>1</td>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365335 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns.drop(\"nouns\", axis=1).join(\n",
    "    nouns[\"nouns\"].str.split(\" \", expand=True).stack().reset_index(level=1, drop=True).rename(\"noun\"))\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun\n1        交通\n1        房间\n1        房间\n1        面积\n1        布局\n...     ...\n317413   房间\n317413   热水\n317414    板\n317415   位置\n317416   商务\n\n[1365335 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365335 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split.drop('temp', axis=1)\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "             noun\n1              交通\n1              房间\n1              面积\n1              布局\n1              感觉\n...           ...\n317315        大方面\n317318  DorisFeng\n317322        热水浴\n317327        布草篓\n317327         草篓\n\n[35468 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317315</th>\n      <td>大方面</td>\n    </tr>\n    <tr>\n      <th>317318</th>\n      <td>DorisFeng</td>\n    </tr>\n    <tr>\n      <th>317322</th>\n      <td>热水浴</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>布草篓</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>草篓</td>\n    </tr>\n  </tbody>\n</table>\n<p>35468 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split.drop_duplicates(subset='noun')\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun\n1        交通\n1        房间\n1        面积\n1        布局\n1        感觉\n...     ...\n313987   礼貌\n314423   合适\n315024  威斯汀\n315076   自助\n316645   不错\n\n[1201 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>313987</th>\n      <td>礼貌</td>\n    </tr>\n    <tr>\n      <th>314423</th>\n      <td>合适</td>\n    </tr>\n    <tr>\n      <th>315024</th>\n      <td>威斯汀</td>\n    </tr>\n    <tr>\n      <th>315076</th>\n      <td>自助</td>\n    </tr>\n    <tr>\n      <th>316645</th>\n      <td>不错</td>\n    </tr>\n  </tbody>\n</table>\n<p>1201 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split[nouns_split['noun'].apply(lambda x: x in cbow200.wv.index_to_key)]\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\3093000328.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\3093000328.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\3093000328.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\3093000328.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n1        交通  [0.42336562, -1.1400625, -2.0374057, -1.919435...   \n1        房间  [0.28802317, -0.4507514, 0.35016647, -0.430556...   \n1        面积  [1.1007886, -0.69985676, 0.23117578, -1.801510...   \n1        布局  [0.7827691, -0.91875976, -1.3275683, 0.1982481...   \n1        感觉  [0.3510958, 1.6568456, -0.9951775, 0.26438335,...   \n...     ...                                                ...   \n313987   礼貌  [1.1424041, 0.91151, 0.43261242, 0.6441254, 0....   \n314423   合适  [-0.42161575, -0.19991678, 1.7154243, -0.18634...   \n315024  威斯汀  [-0.28125665, 0.091284014, 0.24053097, -0.0747...   \n315076   自助  [-0.5054578, 2.0775445, 1.0326135, -0.01245087...   \n316645   不错  [-0.37493014, -0.05675228, -0.19319299, -1.045...   \n\n                                                  CBOW300  \\\n1       [-0.06610227, 0.4988237, 0.13218886, -0.776386...   \n1       [0.12421269, 0.024913808, -0.01602313, 1.11401...   \n1       [0.44881797, -0.6757507, 0.74121505, 0.0876074...   \n1       [-0.8795247, -0.32223016, 0.24907054, -0.61571...   \n1       [0.3619895, 0.14452918, -0.15129763, -0.555666...   \n...                                                   ...   \n313987  [-0.46472156, 0.32605383, -0.73007, 0.9956819,...   \n314423  [0.836252, 0.31240836, 0.034565493, -0.4628917...   \n315024  [0.21199425, -0.13832602, -0.09146086, -0.0933...   \n315076  [-0.755431, 0.6866077, -0.060408723, -0.023249...   \n316645  [0.25392136, -0.9081178, -0.34746647, -0.38154...   \n\n                                                    SG200  \\\n1       [-0.012540849, -0.38462433, -0.32319498, -0.18...   \n1       [0.19959436, -0.32069674, -0.14715314, 0.06170...   \n1       [0.2180409, -0.31570902, 0.16386202, -0.186760...   \n1       [0.24405675, -0.41571265, -0.17313722, 0.07100...   \n1       [0.2606882, 0.07442919, -0.35957494, 0.2398521...   \n...                                                   ...   \n313987  [0.30669054, -0.12392349, 0.01986696, 0.033570...   \n314423  [0.12132719, -0.42330444, 0.15789798, 0.167093...   \n315024  [-0.3902142, -0.058192953, -0.1316207, -0.2172...   \n315076  [0.12675922, 0.10627268, 0.045253187, 0.176560...   \n316645  [-0.2043458, -0.2967028, -0.05167222, 0.093228...   \n\n                                                    SG300  \n1       [0.023853732, -0.09414571, -0.23024663, 0.0388...  \n1       [0.17186686, -0.013962293, -0.13654591, 0.1969...  \n1       [-0.0023564755, 0.14263394, -0.27440792, 0.032...  \n1       [0.15417029, -0.06498914, -0.15444419, -0.1932...  \n1       [0.09512662, 0.20621958, -0.018997584, -0.3680...  \n...                                                   ...  \n313987  [-0.029739557, -0.0032241284, -0.1473059, 0.15...  \n314423  [-0.21083379, 0.13041505, -0.13174589, -0.0949...  \n315024  [0.15095249, 0.24139097, -0.13767847, -0.09924...  \n315076  [-0.22230288, 0.3992527, -0.21021116, 0.111188...  \n316645  [0.08284405, -0.18486665, -0.020791149, 0.0251...  \n\n[1201 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n      <td>[0.42336562, -1.1400625, -2.0374057, -1.919435...</td>\n      <td>[-0.06610227, 0.4988237, 0.13218886, -0.776386...</td>\n      <td>[-0.012540849, -0.38462433, -0.32319498, -0.18...</td>\n      <td>[0.023853732, -0.09414571, -0.23024663, 0.0388...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>[0.28802317, -0.4507514, 0.35016647, -0.430556...</td>\n      <td>[0.12421269, 0.024913808, -0.01602313, 1.11401...</td>\n      <td>[0.19959436, -0.32069674, -0.14715314, 0.06170...</td>\n      <td>[0.17186686, -0.013962293, -0.13654591, 0.1969...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n      <td>[1.1007886, -0.69985676, 0.23117578, -1.801510...</td>\n      <td>[0.44881797, -0.6757507, 0.74121505, 0.0876074...</td>\n      <td>[0.2180409, -0.31570902, 0.16386202, -0.186760...</td>\n      <td>[-0.0023564755, 0.14263394, -0.27440792, 0.032...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n      <td>[0.7827691, -0.91875976, -1.3275683, 0.1982481...</td>\n      <td>[-0.8795247, -0.32223016, 0.24907054, -0.61571...</td>\n      <td>[0.24405675, -0.41571265, -0.17313722, 0.07100...</td>\n      <td>[0.15417029, -0.06498914, -0.15444419, -0.1932...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n      <td>[0.3510958, 1.6568456, -0.9951775, 0.26438335,...</td>\n      <td>[0.3619895, 0.14452918, -0.15129763, -0.555666...</td>\n      <td>[0.2606882, 0.07442919, -0.35957494, 0.2398521...</td>\n      <td>[0.09512662, 0.20621958, -0.018997584, -0.3680...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>313987</th>\n      <td>礼貌</td>\n      <td>[1.1424041, 0.91151, 0.43261242, 0.6441254, 0....</td>\n      <td>[-0.46472156, 0.32605383, -0.73007, 0.9956819,...</td>\n      <td>[0.30669054, -0.12392349, 0.01986696, 0.033570...</td>\n      <td>[-0.029739557, -0.0032241284, -0.1473059, 0.15...</td>\n    </tr>\n    <tr>\n      <th>314423</th>\n      <td>合适</td>\n      <td>[-0.42161575, -0.19991678, 1.7154243, -0.18634...</td>\n      <td>[0.836252, 0.31240836, 0.034565493, -0.4628917...</td>\n      <td>[0.12132719, -0.42330444, 0.15789798, 0.167093...</td>\n      <td>[-0.21083379, 0.13041505, -0.13174589, -0.0949...</td>\n    </tr>\n    <tr>\n      <th>315024</th>\n      <td>威斯汀</td>\n      <td>[-0.28125665, 0.091284014, 0.24053097, -0.0747...</td>\n      <td>[0.21199425, -0.13832602, -0.09146086, -0.0933...</td>\n      <td>[-0.3902142, -0.058192953, -0.1316207, -0.2172...</td>\n      <td>[0.15095249, 0.24139097, -0.13767847, -0.09924...</td>\n    </tr>\n    <tr>\n      <th>315076</th>\n      <td>自助</td>\n      <td>[-0.5054578, 2.0775445, 1.0326135, -0.01245087...</td>\n      <td>[-0.755431, 0.6866077, -0.060408723, -0.023249...</td>\n      <td>[0.12675922, 0.10627268, 0.045253187, 0.176560...</td>\n      <td>[-0.22230288, 0.3992527, -0.21021116, 0.111188...</td>\n    </tr>\n    <tr>\n      <th>316645</th>\n      <td>不错</td>\n      <td>[-0.37493014, -0.05675228, -0.19319299, -1.045...</td>\n      <td>[0.25392136, -0.9081178, -0.34746647, -0.38154...</td>\n      <td>[-0.2043458, -0.2967028, -0.05167222, 0.093228...</td>\n      <td>[0.08284405, -0.18486665, -0.020791149, 0.0251...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1201 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
    "    lambda x: cbow200.wv[x]), nouns_split['noun'].apply(lambda x: cbow300.wv[x]), nouns_split['noun'].apply(\n",
    "    lambda x: sg200.wv[x]), nouns_split['noun'].apply(lambda x: sg300.wv[x])\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_57972\\939353274.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split[\n"
     ]
    },
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n1        交通  0.42336562 -1.1400625 -2.0374057 -1.9194353 0....   \n1        房间  0.28802317 -0.4507514 0.35016647 -0.43055606 0...   \n1        面积  1.1007886 -0.69985676 0.23117578 -1.8015103 -1...   \n1        布局  0.7827691 -0.91875976 -1.3275683 0.19824812 -0...   \n1        感觉  0.3510958 1.6568456 -0.9951775 0.26438335 0.72...   \n...     ...                                                ...   \n313987   礼貌  1.1424041 0.91151 0.43261242 0.6441254 0.60611...   \n314423   合适  -0.42161575 -0.19991678 1.7154243 -0.1863414 -...   \n315024  威斯汀  -0.28125665 0.091284014 0.24053097 -0.07472294...   \n315076   自助  -0.5054578 2.0775445 1.0326135 -0.012450871 -1...   \n316645   不错  -0.37493014 -0.05675228 -0.19319299 -1.0456878...   \n\n                                                  CBOW300  \\\n1       -0.06610227 0.4988237 0.13218886 -0.77638644 1...   \n1       0.12421269 0.024913808 -0.01602313 1.1140127 -...   \n1       0.44881797 -0.6757507 0.74121505 0.08760744 -0...   \n1       -0.8795247 -0.32223016 0.24907054 -0.6157134 -...   \n1       0.3619895 0.14452918 -0.15129763 -0.55566627 0...   \n...                                                   ...   \n313987  -0.46472156 0.32605383 -0.73007 0.9956819 -0.6...   \n314423  0.836252 0.31240836 0.034565493 -0.46289173 0....   \n315024  0.21199425 -0.13832602 -0.09146086 -0.09332652...   \n315076  -0.755431 0.6866077 -0.060408723 -0.023249513 ...   \n316645  0.25392136 -0.9081178 -0.34746647 -0.38154912 ...   \n\n                                                    SG200  \\\n1       -0.012540849 -0.38462433 -0.32319498 -0.182240...   \n1       0.19959436 -0.32069674 -0.14715314 0.061708618...   \n1       0.2180409 -0.31570902 0.16386202 -0.18676051 -...   \n1       0.24405675 -0.41571265 -0.17313722 0.071001776...   \n1       0.2606882 0.07442919 -0.35957494 0.23985219 0....   \n...                                                   ...   \n313987  0.30669054 -0.12392349 0.01986696 0.033570386 ...   \n314423  0.12132719 -0.42330444 0.15789798 0.16709346 0...   \n315024  -0.3902142 -0.058192953 -0.1316207 -0.21724865...   \n315076  0.12675922 0.10627268 0.045253187 0.17656054 -...   \n316645  -0.2043458 -0.2967028 -0.05167222 0.09322873 0...   \n\n                                                    SG300  \n1       0.023853732 -0.09414571 -0.23024663 0.03881392...  \n1       0.17186686 -0.013962293 -0.13654591 0.1969577 ...  \n1       -0.0023564755 0.14263394 -0.27440792 0.0326909...  \n1       0.15417029 -0.06498914 -0.15444419 -0.1932353 ...  \n1       0.09512662 0.20621958 -0.018997584 -0.3680405 ...  \n...                                                   ...  \n313987  -0.029739557 -0.0032241284 -0.1473059 0.151833...  \n314423  -0.21083379 0.13041505 -0.13174589 -0.09491256...  \n315024  0.15095249 0.24139097 -0.13767847 -0.099240825...  \n315076  -0.22230288 0.3992527 -0.21021116 0.11118822 0...  \n316645  0.08284405 -0.18486665 -0.020791149 0.02512368...  \n\n[1201 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n      <td>0.42336562 -1.1400625 -2.0374057 -1.9194353 0....</td>\n      <td>-0.06610227 0.4988237 0.13218886 -0.77638644 1...</td>\n      <td>-0.012540849 -0.38462433 -0.32319498 -0.182240...</td>\n      <td>0.023853732 -0.09414571 -0.23024663 0.03881392...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>0.28802317 -0.4507514 0.35016647 -0.43055606 0...</td>\n      <td>0.12421269 0.024913808 -0.01602313 1.1140127 -...</td>\n      <td>0.19959436 -0.32069674 -0.14715314 0.061708618...</td>\n      <td>0.17186686 -0.013962293 -0.13654591 0.1969577 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n      <td>1.1007886 -0.69985676 0.23117578 -1.8015103 -1...</td>\n      <td>0.44881797 -0.6757507 0.74121505 0.08760744 -0...</td>\n      <td>0.2180409 -0.31570902 0.16386202 -0.18676051 -...</td>\n      <td>-0.0023564755 0.14263394 -0.27440792 0.0326909...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n      <td>0.7827691 -0.91875976 -1.3275683 0.19824812 -0...</td>\n      <td>-0.8795247 -0.32223016 0.24907054 -0.6157134 -...</td>\n      <td>0.24405675 -0.41571265 -0.17313722 0.071001776...</td>\n      <td>0.15417029 -0.06498914 -0.15444419 -0.1932353 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n      <td>0.3510958 1.6568456 -0.9951775 0.26438335 0.72...</td>\n      <td>0.3619895 0.14452918 -0.15129763 -0.55566627 0...</td>\n      <td>0.2606882 0.07442919 -0.35957494 0.23985219 0....</td>\n      <td>0.09512662 0.20621958 -0.018997584 -0.3680405 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>313987</th>\n      <td>礼貌</td>\n      <td>1.1424041 0.91151 0.43261242 0.6441254 0.60611...</td>\n      <td>-0.46472156 0.32605383 -0.73007 0.9956819 -0.6...</td>\n      <td>0.30669054 -0.12392349 0.01986696 0.033570386 ...</td>\n      <td>-0.029739557 -0.0032241284 -0.1473059 0.151833...</td>\n    </tr>\n    <tr>\n      <th>314423</th>\n      <td>合适</td>\n      <td>-0.42161575 -0.19991678 1.7154243 -0.1863414 -...</td>\n      <td>0.836252 0.31240836 0.034565493 -0.46289173 0....</td>\n      <td>0.12132719 -0.42330444 0.15789798 0.16709346 0...</td>\n      <td>-0.21083379 0.13041505 -0.13174589 -0.09491256...</td>\n    </tr>\n    <tr>\n      <th>315024</th>\n      <td>威斯汀</td>\n      <td>-0.28125665 0.091284014 0.24053097 -0.07472294...</td>\n      <td>0.21199425 -0.13832602 -0.09146086 -0.09332652...</td>\n      <td>-0.3902142 -0.058192953 -0.1316207 -0.21724865...</td>\n      <td>0.15095249 0.24139097 -0.13767847 -0.099240825...</td>\n    </tr>\n    <tr>\n      <th>315076</th>\n      <td>自助</td>\n      <td>-0.5054578 2.0775445 1.0326135 -0.012450871 -1...</td>\n      <td>-0.755431 0.6866077 -0.060408723 -0.023249513 ...</td>\n      <td>0.12675922 0.10627268 0.045253187 0.17656054 -...</td>\n      <td>-0.22230288 0.3992527 -0.21021116 0.11118822 0...</td>\n    </tr>\n    <tr>\n      <th>316645</th>\n      <td>不错</td>\n      <td>-0.37493014 -0.05675228 -0.19319299 -1.0456878...</td>\n      <td>0.25392136 -0.9081178 -0.34746647 -0.38154912 ...</td>\n      <td>-0.2043458 -0.2967028 -0.05167222 0.09322873 0...</td>\n      <td>0.08284405 -0.18486665 -0.020791149 0.02512368...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1201 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split[\n",
    "                                                                                                 'CBOW200'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['CBOW300'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['SG200'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['SG300'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x]))\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "nouns_split.to_excel('../data/word2vec_min_count_100.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "2796"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cbow200.wv.index_to_key)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
