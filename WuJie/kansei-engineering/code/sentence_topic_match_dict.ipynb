{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            sentence  sentiment    dict\n0                很不错   1.000000  kansei\n1                很方便   0.913670  kansei\n2              交通很方便   1.598922  kansei\n3              房间很干净   1.750000  kansei\n4        虽然房间面积普遍都不大  -0.818779  kansei\n...              ...        ...     ...\n1365343         适合孩子   0.233304   boson\n1365344       就是房间漏水  -0.264336   boson\n1365345         没有热水  -0.113943   boson\n1365346         巴适的板   0.450991   boson\n1365347         适合商务   0.239832   boson\n\n[1365348 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n      <th>dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n      <td>1.000000</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>很方便</td>\n      <td>0.913670</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>交通很方便</td>\n      <td>1.598922</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>房间很干净</td>\n      <td>1.750000</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>虽然房间面积普遍都不大</td>\n      <td>-0.818779</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1365343</th>\n      <td>适合孩子</td>\n      <td>0.233304</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1365344</th>\n      <td>就是房间漏水</td>\n      <td>-0.264336</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1365345</th>\n      <td>没有热水</td>\n      <td>-0.113943</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1365346</th>\n      <td>巴适的板</td>\n      <td>0.450991</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1365347</th>\n      <td>适合商务</td>\n      <td>0.239832</td>\n      <td>boson</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365348 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentence = pd.read_csv('../data/sentiment_score_2.csv', sep='\\t')\n",
    "topic = pd.read_excel('../data/4_clusters_cbow200_kmeans-words_fixed-Wu.xlsx', engine='openpyxl')\n",
    "topic['Phrases'] = topic['Phrases'].apply(lambda x: x.split('，'))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_word = topic['Phrases'].tolist()\n",
    "facility = all_word[0]\n",
    "parking = all_word[1]\n",
    "service = all_word[2]\n",
    "special_care = all_word[3]\n",
    "room = all_word[4]\n",
    "value = all_word[5]\n",
    "booking = all_word[6]\n",
    "cleanliness = all_word[7]\n",
    "bathroom = all_word[8]\n",
    "location_transport = all_word[9]\n",
    "surrounding = all_word[10]\n",
    "decoration = all_word[11]\n",
    "food_drink = all_word[12]\n",
    "# 构造dict\n",
    "# 0: facility,\n",
    "# 1: parking,\n",
    "# 2: service,\n",
    "# 3: special_care,\n",
    "# 4: room,\n",
    "# 5: value,\n",
    "# 6: booking,\n",
    "# 7: cleanliness,\n",
    "# 8: bathroom,\n",
    "# 9: location_transport,\n",
    "# 10: surrounding,\n",
    "# 11: decoration,\n",
    "# 12: food_drink\n",
    "topic_dict = {\n",
    "    0: facility,\n",
    "    1: parking,\n",
    "    2: service,\n",
    "    3: special_care,\n",
    "    4: room,\n",
    "    5: value,\n",
    "    6: booking,\n",
    "    7: cleanliness,\n",
    "    8: bathroom,\n",
    "    9: location_transport,\n",
    "    10: surrounding,\n",
    "    11: decoration,\n",
    "    12: food_drink\n",
    "}\n",
    "word_dict = {}\n",
    "for i, words in enumerate(all_word):\n",
    "    for word in words:\n",
    "        word_dict[word] = i\n",
    "# word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import jieba\n",
    "import xiangshi as xs\n",
    "\n",
    "digits = '0123456789'\n",
    "# 去掉baidu_stopwords中的属性词\n",
    "stop_df = pd.read_csv('../data/baidu_stopwords.txt')\n",
    "all_df = pd.DataFrame([y for x in all_word for y in x])\n",
    "stop_df.columns = ['word']\n",
    "all_df.columns = ['word']\n",
    "word_duplicated = pd.merge(stop_df, all_df, on='word')['word']\n",
    "stop_list = list(filter(lambda x: x not in word_duplicated, stop_df))\n",
    "\n",
    "\n",
    "# 保留中文字符，删除非中文字符\n",
    "def find_chinese(doc):\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    chinese = re.sub(pattern, \"\", doc)\n",
    "    return chinese\n",
    "\n",
    "\n",
    "def pre_process(text0):\n",
    "    # 去标点符号\n",
    "    text0 = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\'～]+|[+——！，。？?、~@#￥%……&*（）．；：】【|]+\", \"\", str(text0))\n",
    "    # 去掉数字\n",
    "    text0 = text0.translate(str.maketrans('', '', digits))\n",
    "    # 去掉非中文字符\n",
    "    text0 = find_chinese(text0)\n",
    "    # 分词\n",
    "    text0 = jieba.cut(text0)\n",
    "    # 去停用词\n",
    "    text0 = [word.strip() for word in text0 if word not in stop_list]\n",
    "\n",
    "    return text0\n",
    "\n",
    "\n",
    "# 判断短文本属于哪个主题，根据dictionary\n",
    "def match_topic(word_list):\n",
    "    # 42作为没有匹配的标志\n",
    "    result = 42\n",
    "    for word in word_list:\n",
    "        # 遍历先验词库\n",
    "        # 将首次出现的词作为分类依据\n",
    "        if word in topic_dict.get(0):\n",
    "            result = 0\n",
    "            break\n",
    "        elif word in topic_dict.get(1):\n",
    "            result = 1\n",
    "            break\n",
    "        elif word in topic_dict.get(2):\n",
    "            result = 2\n",
    "            break\n",
    "        elif word in topic_dict.get(3):\n",
    "            result = 3\n",
    "            break\n",
    "        elif word in topic_dict.get(4):\n",
    "            result = 4\n",
    "            break\n",
    "        elif word in topic_dict.get(5):\n",
    "            result = 5\n",
    "            break\n",
    "        elif word in topic_dict.get(6):\n",
    "            result = 6\n",
    "            break\n",
    "        elif word in topic_dict.get(7):\n",
    "            result = 7\n",
    "            break\n",
    "        elif word in topic_dict.get(8):\n",
    "            result = 8\n",
    "            break\n",
    "        elif word in topic_dict.get(9):\n",
    "            result = 9\n",
    "            break\n",
    "        elif word in topic_dict.get(10):\n",
    "            result = 10\n",
    "            break\n",
    "        elif word in topic_dict.get(11):\n",
    "            result = 11\n",
    "            break\n",
    "        elif word in topic_dict.get(12):\n",
    "            result = 12\n",
    "            break\n",
    "\n",
    "    # 字典中没有匹配，返回-1\n",
    "    if result == 42:\n",
    "        result = -1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 根据相似度匹配属性\n",
    "def match_by_similarity(text1):\n",
    "    try:\n",
    "        # 计算text与字典中所有key的相似度，取最大值为最终结果\n",
    "        max_similarity = 0\n",
    "\n",
    "        result = -1\n",
    "        for key, value_list in topic_dict.items():\n",
    "            sim = 0\n",
    "            for v in value_list:\n",
    "                sim = max(sim, xs.cossim([text1, v]))  # 找到当前key下最大的相似度\n",
    "            if max_similarity < sim:\n",
    "                max_similarity = sim\n",
    "                result = key\n",
    "\n",
    "        return result\n",
    "    except TypeError:\n",
    "        # 出错返回-2\n",
    "        return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1365348/1365348 [00:58<00:00, 23232.20it/s]\n",
      "100%|██████████| 1365348/1365348 [00:33<00:00, 40673.51it/s]\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_15336\\1181994722.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dict_topic['match'] = 'dict'\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_15336\\1181994722.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sim_topic['match'] = 'sim'\n"
     ]
    },
    {
     "data": {
      "text/plain": "((859689, 6), (505659, 6))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "sentence['words'] = sentence['sentence'].progress_apply(pre_process)\n",
    "sentence['topic'] = sentence['words'].progress_apply(match_topic)\n",
    "dict_topic = sentence[sentence['topic'] != -1]\n",
    "sim_topic = sentence[sentence['topic'] == -1]\n",
    "dict_topic['match'] = 'dict'\n",
    "sim_topic['match'] = 'sim'\n",
    "dict_topic.shape, sim_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_topic = dict_topic.drop(labels=['words', 'match'], axis=1)\n",
    "sim_topic = sim_topic.drop(labels=['words', 'match'], axis=1)\n",
    "dict_topic.to_csv('../data/sentence_match_result_dict.csv_2', sep='\\t', index=False)\n",
    "sim_topic.to_csv('../data/sentence_match_result_without_match_2.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
