{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "词向量降维聚类\n",
    "\"\"\"\n",
    "import umap\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    noun                                            CBOW200  \\\n0     交通  0.42336562 -1.1400625 -2.0374057 -1.9194353 0....   \n1     房间  0.28802317 -0.4507514 0.35016647 -0.43055606 0...   \n2     面积  1.1007886 -0.69985676 0.23117578 -1.8015103 -1...   \n3     布局  0.7827691 -0.91875976 -1.3275683 0.19824812 -0...   \n4     卫浴  0.60243356 -0.9301406 -0.243199 -0.7276225 -0....   \n..   ...                                                ...   \n935   三晚  -0.09600455 -0.24936976 0.08400188 0.089544974...   \n936   礼貌  1.1424041 0.91151 0.43261242 0.6441254 0.60611...   \n937   合适  -0.42161575 -0.19991678 1.7154243 -0.1863414 -...   \n938  威斯汀  -0.28125665 0.091284014 0.24053097 -0.07472294...   \n939   自助  -0.5054578 2.0775445 1.0326135 -0.012450871 -1...   \n\n                                               CBOW300  \\\n0    -0.06610227 0.4988237 0.13218886 -0.77638644 1...   \n1    0.12421269 0.024913808 -0.01602313 1.1140127 -...   \n2    0.44881797 -0.6757507 0.74121505 0.08760744 -0...   \n3    -0.8795247 -0.32223016 0.24907054 -0.6157134 -...   \n4    -0.12032523 0.20740871 0.35552785 0.07866025 -...   \n..                                                 ...   \n935  0.07487932 0.25357836 0.07852432 -0.0952891 0....   \n936  -0.46472156 0.32605383 -0.73007 0.9956819 -0.6...   \n937  0.836252 0.31240836 0.034565493 -0.46289173 0....   \n938  0.21199425 -0.13832602 -0.09146086 -0.09332652...   \n939  -0.755431 0.6866077 -0.060408723 -0.023249513 ...   \n\n                                                 SG200  \\\n0    -0.012540849 -0.38462433 -0.32319498 -0.182240...   \n1    0.19959436 -0.32069674 -0.14715314 0.061708618...   \n2    0.2180409 -0.31570902 0.16386202 -0.18676051 -...   \n3    0.24405675 -0.41571265 -0.17313722 0.071001776...   \n4    0.25761604 -0.07487154 -0.19477549 0.028649133...   \n..                                                 ...   \n935  0.2406698 -0.5435254 0.10679261 0.0504834 -0.1...   \n936  0.30669054 -0.12392349 0.01986696 0.033570386 ...   \n937  0.12132719 -0.42330444 0.15789798 0.16709346 0...   \n938  -0.3902142 -0.058192953 -0.1316207 -0.21724865...   \n939  0.12675922 0.10627268 0.045253187 0.17656054 -...   \n\n                                                 SG300  \\\n0    0.023853732 -0.09414571 -0.23024663 0.03881392...   \n1    0.17186686 -0.013962293 -0.13654591 0.1969577 ...   \n2    -0.0023564755 0.14263394 -0.27440792 0.0326909...   \n3    0.15417029 -0.06498914 -0.15444419 -0.1932353 ...   \n4    0.19327797 0.098093584 0.0371605 -0.029816944 ...   \n..                                                 ...   \n935  0.123874895 -0.011844655 0.017515218 -0.050921...   \n936  -0.029739557 -0.0032241284 -0.1473059 0.151833...   \n937  -0.21083379 0.13041505 -0.13174589 -0.09491256...   \n938  0.15095249 0.24139097 -0.13767847 -0.099240825...   \n939  -0.22230288 0.3992527 -0.21021116 0.11118822 0...   \n\n                                           roberta_wwm  \\\n0    -0.08571069687604904 0.05334413796663284 0.758...   \n1    -0.26072731614112854 0.6660227179527283 0.2643...   \n2    -0.4051162004470825 0.6650103330612183 0.01912...   \n3    0.0831306055188179 0.5076727867126465 0.217217...   \n4    -0.3666742742061615 0.4476194381713867 0.67427...   \n..                                                 ...   \n935  0.22766144573688507 0.20426048338413239 0.3718...   \n936  -0.09216073155403137 0.6346340179443359 0.4351...   \n937  0.039119869470596313 0.3964913487434387 -0.013...   \n938  -0.4285953640937805 0.3718821406364441 0.07398...   \n939  -0.008615642786026001 0.47842586040496826 0.27...   \n\n                                            tencent200  \\\n0    -0.097999 -0.172532 0.674114 -0.103633 0.24910...   \n1    0.181897 0.389742 -0.06113 0.242304 -0.028627 ...   \n2    0.311055 0.039625 0.333128 0.215967 -0.111913 ...   \n3    0.266127 0.316716 0.021962 0.075516 0.086151 -...   \n4    0.230336 -0.213324 0.503645 0.260184 0.126454 ...   \n..                                                 ...   \n935  -0.00788 0.306547 0.304058 0.261574 -0.089843 ...   \n936  -0.324412 0.066763 0.139822 0.105918 -0.272539...   \n937  -0.266707 0.312565 -0.102081 0.449369 -0.25977...   \n938  -0.099088 0.133279 -0.222177 -0.11384 -0.31356...   \n939  -0.183511 -0.062141 0.210427 -0.105497 0.09846...   \n\n                                  sentence_transformer  \n0    -0.0059281155 0.085107535 -0.018252835 0.06734...  \n1    0.01048636 -0.015002572 -0.017642647 -0.040445...  \n2    -0.06143476 -0.044589818 -0.019351065 0.036645...  \n3    -0.037475087 -0.01469476 -0.02024162 0.0472815...  \n4    0.028435966 -0.098250374 -0.019702565 -0.08827...  \n..                                                 ...  \n935  0.005660566 -0.17151478 -0.012845519 0.0224691...  \n936  0.035092603 0.1269345 -0.019277968 0.072855875...  \n937  0.021969374 0.031377662 -0.020527236 0.0181356...  \n938  -0.07128871 0.10444158 -0.018124782 0.08321853...  \n939  -0.006896859 0.028956452 -0.021312095 0.030632...  \n\n[940 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n      <th>roberta_wwm</th>\n      <th>tencent200</th>\n      <th>sentence_transformer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.42336562 -1.1400625 -2.0374057 -1.9194353 0....</td>\n      <td>-0.06610227 0.4988237 0.13218886 -0.77638644 1...</td>\n      <td>-0.012540849 -0.38462433 -0.32319498 -0.182240...</td>\n      <td>0.023853732 -0.09414571 -0.23024663 0.03881392...</td>\n      <td>-0.08571069687604904 0.05334413796663284 0.758...</td>\n      <td>-0.097999 -0.172532 0.674114 -0.103633 0.24910...</td>\n      <td>-0.0059281155 0.085107535 -0.018252835 0.06734...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>0.28802317 -0.4507514 0.35016647 -0.43055606 0...</td>\n      <td>0.12421269 0.024913808 -0.01602313 1.1140127 -...</td>\n      <td>0.19959436 -0.32069674 -0.14715314 0.061708618...</td>\n      <td>0.17186686 -0.013962293 -0.13654591 0.1969577 ...</td>\n      <td>-0.26072731614112854 0.6660227179527283 0.2643...</td>\n      <td>0.181897 0.389742 -0.06113 0.242304 -0.028627 ...</td>\n      <td>0.01048636 -0.015002572 -0.017642647 -0.040445...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>1.1007886 -0.69985676 0.23117578 -1.8015103 -1...</td>\n      <td>0.44881797 -0.6757507 0.74121505 0.08760744 -0...</td>\n      <td>0.2180409 -0.31570902 0.16386202 -0.18676051 -...</td>\n      <td>-0.0023564755 0.14263394 -0.27440792 0.0326909...</td>\n      <td>-0.4051162004470825 0.6650103330612183 0.01912...</td>\n      <td>0.311055 0.039625 0.333128 0.215967 -0.111913 ...</td>\n      <td>-0.06143476 -0.044589818 -0.019351065 0.036645...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.7827691 -0.91875976 -1.3275683 0.19824812 -0...</td>\n      <td>-0.8795247 -0.32223016 0.24907054 -0.6157134 -...</td>\n      <td>0.24405675 -0.41571265 -0.17313722 0.071001776...</td>\n      <td>0.15417029 -0.06498914 -0.15444419 -0.1932353 ...</td>\n      <td>0.0831306055188179 0.5076727867126465 0.217217...</td>\n      <td>0.266127 0.316716 0.021962 0.075516 0.086151 -...</td>\n      <td>-0.037475087 -0.01469476 -0.02024162 0.0472815...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>卫浴</td>\n      <td>0.60243356 -0.9301406 -0.243199 -0.7276225 -0....</td>\n      <td>-0.12032523 0.20740871 0.35552785 0.07866025 -...</td>\n      <td>0.25761604 -0.07487154 -0.19477549 0.028649133...</td>\n      <td>0.19327797 0.098093584 0.0371605 -0.029816944 ...</td>\n      <td>-0.3666742742061615 0.4476194381713867 0.67427...</td>\n      <td>0.230336 -0.213324 0.503645 0.260184 0.126454 ...</td>\n      <td>0.028435966 -0.098250374 -0.019702565 -0.08827...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>935</th>\n      <td>三晚</td>\n      <td>-0.09600455 -0.24936976 0.08400188 0.089544974...</td>\n      <td>0.07487932 0.25357836 0.07852432 -0.0952891 0....</td>\n      <td>0.2406698 -0.5435254 0.10679261 0.0504834 -0.1...</td>\n      <td>0.123874895 -0.011844655 0.017515218 -0.050921...</td>\n      <td>0.22766144573688507 0.20426048338413239 0.3718...</td>\n      <td>-0.00788 0.306547 0.304058 0.261574 -0.089843 ...</td>\n      <td>0.005660566 -0.17151478 -0.012845519 0.0224691...</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>礼貌</td>\n      <td>1.1424041 0.91151 0.43261242 0.6441254 0.60611...</td>\n      <td>-0.46472156 0.32605383 -0.73007 0.9956819 -0.6...</td>\n      <td>0.30669054 -0.12392349 0.01986696 0.033570386 ...</td>\n      <td>-0.029739557 -0.0032241284 -0.1473059 0.151833...</td>\n      <td>-0.09216073155403137 0.6346340179443359 0.4351...</td>\n      <td>-0.324412 0.066763 0.139822 0.105918 -0.272539...</td>\n      <td>0.035092603 0.1269345 -0.019277968 0.072855875...</td>\n    </tr>\n    <tr>\n      <th>937</th>\n      <td>合适</td>\n      <td>-0.42161575 -0.19991678 1.7154243 -0.1863414 -...</td>\n      <td>0.836252 0.31240836 0.034565493 -0.46289173 0....</td>\n      <td>0.12132719 -0.42330444 0.15789798 0.16709346 0...</td>\n      <td>-0.21083379 0.13041505 -0.13174589 -0.09491256...</td>\n      <td>0.039119869470596313 0.3964913487434387 -0.013...</td>\n      <td>-0.266707 0.312565 -0.102081 0.449369 -0.25977...</td>\n      <td>0.021969374 0.031377662 -0.020527236 0.0181356...</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>威斯汀</td>\n      <td>-0.28125665 0.091284014 0.24053097 -0.07472294...</td>\n      <td>0.21199425 -0.13832602 -0.09146086 -0.09332652...</td>\n      <td>-0.3902142 -0.058192953 -0.1316207 -0.21724865...</td>\n      <td>0.15095249 0.24139097 -0.13767847 -0.099240825...</td>\n      <td>-0.4285953640937805 0.3718821406364441 0.07398...</td>\n      <td>-0.099088 0.133279 -0.222177 -0.11384 -0.31356...</td>\n      <td>-0.07128871 0.10444158 -0.018124782 0.08321853...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>自助</td>\n      <td>-0.5054578 2.0775445 1.0326135 -0.012450871 -1...</td>\n      <td>-0.755431 0.6866077 -0.060408723 -0.023249513 ...</td>\n      <td>0.12675922 0.10627268 0.045253187 0.17656054 -...</td>\n      <td>-0.22230288 0.3992527 -0.21021116 0.11118822 0...</td>\n      <td>-0.008615642786026001 0.47842586040496826 0.27...</td>\n      <td>-0.183511 -0.062141 0.210427 -0.105497 0.09846...</td>\n      <td>-0.006896859 0.028956452 -0.021312095 0.030632...</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../data/mywv_wwm_tencent_sentence_count100.xlsx')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\62774\\anaconda3\\envs\\kansei\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP(n_neighbors=15, n_components=5, metric='cosine', random_state=42)\n",
    "metric = pd.DataFrame()\n",
    "for name, column in data.iteritems():\n",
    "    if name == 'noun':\n",
    "        metric['metric'] = ['dvi', 'sc', 'chs', 'class_number']\n",
    "        continue\n",
    "\n",
    "    # 类型转换\n",
    "    embedding_list = column.apply(lambda x: [float(number) for number in x.split(' ')]).tolist()\n",
    "\n",
    "    # 降维\n",
    "    reduced = reducer.fit_transform(embedding_list)\n",
    "\n",
    "    # 聚类 k:kmeans, h:AgglomerativeClustering, hd:hdbscan\n",
    "    reduced_k = KMeans(n_clusters=35, random_state=42).fit(reduced)\n",
    "    original_k = KMeans(n_clusters=35, random_state=42).fit(embedding_list)\n",
    "    reduced_h = AgglomerativeClustering(n_clusters=35).fit(reduced)\n",
    "    original_h = AgglomerativeClustering(n_clusters=35).fit(embedding_list)\n",
    "    reduced_hd = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=1).fit(reduced)\n",
    "    original_hd = hdbscan.HDBSCAN(min_cluster_size=4, min_samples=1).fit(embedding_list)\n",
    "\n",
    "    # metric\n",
    "    # hdbscan去掉噪音点计算metric\n",
    "    non_noise_re, non_noise_labels_re = [], []\n",
    "    for sample, label in zip(reduced, reduced_hd.labels_):\n",
    "        if label != -1:\n",
    "            non_noise_re.append(sample)\n",
    "            non_noise_labels_re.append(label)\n",
    "\n",
    "    non_noise, non_noise_labels = [], []\n",
    "    for sample, label in zip(embedding_list, original_hd.labels_):\n",
    "        if label != -1:\n",
    "            non_noise.append(sample)\n",
    "            non_noise_labels.append(label)\n",
    "\n",
    "    dvi_re_k = metrics.davies_bouldin_score(reduced, reduced_k.labels_)\n",
    "    sc_re_k = metrics.silhouette_score(reduced, reduced_k.labels_)\n",
    "    chs_re_k = metrics.calinski_harabasz_score(reduced, reduced_k.labels_)\n",
    "\n",
    "    dvi_k = metrics.davies_bouldin_score(embedding_list, original_k.labels_)\n",
    "    sc_k = metrics.silhouette_score(embedding_list, original_k.labels_)\n",
    "    chs_k = metrics.calinski_harabasz_score(embedding_list, original_k.labels_)\n",
    "\n",
    "    dvi_re_h = metrics.davies_bouldin_score(reduced, reduced_h.labels_)\n",
    "    sc_re_h = metrics.silhouette_score(reduced, reduced_h.labels_)\n",
    "    chs_re_h = metrics.calinski_harabasz_score(reduced, reduced_h.labels_)\n",
    "\n",
    "    dvi_h = metrics.davies_bouldin_score(embedding_list, original_h.labels_)\n",
    "    sc_h = metrics.silhouette_score(embedding_list, original_h.labels_)\n",
    "    chs_h = metrics.calinski_harabasz_score(embedding_list, original_h.labels_)\n",
    "\n",
    "    dvi_re_hd = metrics.davies_bouldin_score(non_noise_re, non_noise_labels_re)\n",
    "    sc_re_hd = metrics.silhouette_score(non_noise_re, non_noise_labels_re)\n",
    "    chs_re_hd = metrics.calinski_harabasz_score(non_noise_re, non_noise_labels_re)\n",
    "\n",
    "    dvi_hd = metrics.davies_bouldin_score(non_noise, non_noise_labels)\n",
    "    sc_hd = metrics.silhouette_score(non_noise, non_noise_labels)\n",
    "    chs_hd = metrics.calinski_harabasz_score(non_noise, non_noise_labels)\n",
    "\n",
    "    # 保存聚类结果\n",
    "    data[name + '_re_k'] = reduced_k.labels_\n",
    "    data[name + '_k'] = original_k.labels_\n",
    "    data[name + '_re_h'] = reduced_h.labels_\n",
    "    data[name + '_h'] = original_h.labels_\n",
    "    data[name + '_re_hd'] = reduced_hd.labels_\n",
    "    data[name + '_hd'] = original_hd.labels_\n",
    "\n",
    "    metric[name + '_re_k'] = [dvi_re_k, sc_re_k, chs_re_k, reduced_k.labels_.max() +1]\n",
    "    metric[name + '_k'] = [dvi_k, sc_k, chs_k, original_k.labels_.max() + 1]\n",
    "    metric[name + '_re_h'] = [dvi_re_h, sc_re_h, chs_re_h, reduced_h.labels_.max() + 1]\n",
    "    metric[name + '_h'] = [dvi_h, sc_h, chs_h, original_h.labels_.max() + 1]\n",
    "    metric[name + '_re_hd'] = [dvi_re_hd, sc_re_hd, chs_re_hd, reduced_hd.labels_.max() + 1]\n",
    "    metric[name + '_hd'] = [dvi_hd, sc_hd, chs_hd, original_hd.labels_.max() + 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "    noun                                            CBOW200  \\\n0     交通  0.42336562 -1.1400625 -2.0374057 -1.9194353 0....   \n1     房间  0.28802317 -0.4507514 0.35016647 -0.43055606 0...   \n2     面积  1.1007886 -0.69985676 0.23117578 -1.8015103 -1...   \n3     布局  0.7827691 -0.91875976 -1.3275683 0.19824812 -0...   \n4     卫浴  0.60243356 -0.9301406 -0.243199 -0.7276225 -0....   \n..   ...                                                ...   \n935   三晚  -0.09600455 -0.24936976 0.08400188 0.089544974...   \n936   礼貌  1.1424041 0.91151 0.43261242 0.6441254 0.60611...   \n937   合适  -0.42161575 -0.19991678 1.7154243 -0.1863414 -...   \n938  威斯汀  -0.28125665 0.091284014 0.24053097 -0.07472294...   \n939   自助  -0.5054578 2.0775445 1.0326135 -0.012450871 -1...   \n\n                                               CBOW300  \\\n0    -0.06610227 0.4988237 0.13218886 -0.77638644 1...   \n1    0.12421269 0.024913808 -0.01602313 1.1140127 -...   \n2    0.44881797 -0.6757507 0.74121505 0.08760744 -0...   \n3    -0.8795247 -0.32223016 0.24907054 -0.6157134 -...   \n4    -0.12032523 0.20740871 0.35552785 0.07866025 -...   \n..                                                 ...   \n935  0.07487932 0.25357836 0.07852432 -0.0952891 0....   \n936  -0.46472156 0.32605383 -0.73007 0.9956819 -0.6...   \n937  0.836252 0.31240836 0.034565493 -0.46289173 0....   \n938  0.21199425 -0.13832602 -0.09146086 -0.09332652...   \n939  -0.755431 0.6866077 -0.060408723 -0.023249513 ...   \n\n                                                 SG200  \\\n0    -0.012540849 -0.38462433 -0.32319498 -0.182240...   \n1    0.19959436 -0.32069674 -0.14715314 0.061708618...   \n2    0.2180409 -0.31570902 0.16386202 -0.18676051 -...   \n3    0.24405675 -0.41571265 -0.17313722 0.071001776...   \n4    0.25761604 -0.07487154 -0.19477549 0.028649133...   \n..                                                 ...   \n935  0.2406698 -0.5435254 0.10679261 0.0504834 -0.1...   \n936  0.30669054 -0.12392349 0.01986696 0.033570386 ...   \n937  0.12132719 -0.42330444 0.15789798 0.16709346 0...   \n938  -0.3902142 -0.058192953 -0.1316207 -0.21724865...   \n939  0.12675922 0.10627268 0.045253187 0.17656054 -...   \n\n                                                 SG300  \\\n0    0.023853732 -0.09414571 -0.23024663 0.03881392...   \n1    0.17186686 -0.013962293 -0.13654591 0.1969577 ...   \n2    -0.0023564755 0.14263394 -0.27440792 0.0326909...   \n3    0.15417029 -0.06498914 -0.15444419 -0.1932353 ...   \n4    0.19327797 0.098093584 0.0371605 -0.029816944 ...   \n..                                                 ...   \n935  0.123874895 -0.011844655 0.017515218 -0.050921...   \n936  -0.029739557 -0.0032241284 -0.1473059 0.151833...   \n937  -0.21083379 0.13041505 -0.13174589 -0.09491256...   \n938  0.15095249 0.24139097 -0.13767847 -0.099240825...   \n939  -0.22230288 0.3992527 -0.21021116 0.11118822 0...   \n\n                                           roberta_wwm  \\\n0    -0.08571069687604904 0.05334413796663284 0.758...   \n1    -0.26072731614112854 0.6660227179527283 0.2643...   \n2    -0.4051162004470825 0.6650103330612183 0.01912...   \n3    0.0831306055188179 0.5076727867126465 0.217217...   \n4    -0.3666742742061615 0.4476194381713867 0.67427...   \n..                                                 ...   \n935  0.22766144573688507 0.20426048338413239 0.3718...   \n936  -0.09216073155403137 0.6346340179443359 0.4351...   \n937  0.039119869470596313 0.3964913487434387 -0.013...   \n938  -0.4285953640937805 0.3718821406364441 0.07398...   \n939  -0.008615642786026001 0.47842586040496826 0.27...   \n\n                                            tencent200  \\\n0    -0.097999 -0.172532 0.674114 -0.103633 0.24910...   \n1    0.181897 0.389742 -0.06113 0.242304 -0.028627 ...   \n2    0.311055 0.039625 0.333128 0.215967 -0.111913 ...   \n3    0.266127 0.316716 0.021962 0.075516 0.086151 -...   \n4    0.230336 -0.213324 0.503645 0.260184 0.126454 ...   \n..                                                 ...   \n935  -0.00788 0.306547 0.304058 0.261574 -0.089843 ...   \n936  -0.324412 0.066763 0.139822 0.105918 -0.272539...   \n937  -0.266707 0.312565 -0.102081 0.449369 -0.25977...   \n938  -0.099088 0.133279 -0.222177 -0.11384 -0.31356...   \n939  -0.183511 -0.062141 0.210427 -0.105497 0.09846...   \n\n                                  sentence_transformer  CBOW200_re_k  \\\n0    -0.0059281155 0.085107535 -0.018252835 0.06734...             2   \n1    0.01048636 -0.015002572 -0.017642647 -0.040445...            24   \n2    -0.06143476 -0.044589818 -0.019351065 0.036645...            16   \n3    -0.037475087 -0.01469476 -0.02024162 0.0472815...            16   \n4    0.028435966 -0.098250374 -0.019702565 -0.08827...            31   \n..                                                 ...           ...   \n935  0.005660566 -0.17151478 -0.012845519 0.0224691...             7   \n936  0.035092603 0.1269345 -0.019277968 0.072855875...            18   \n937  0.021969374 0.031377662 -0.020527236 0.0181356...            21   \n938  -0.07128871 0.10444158 -0.018124782 0.08321853...             6   \n939  -0.006896859 0.028956452 -0.021312095 0.030632...            10   \n\n     CBOW200_k  ...  tencent200_re_h  tencent200_h  tencent200_re_hd  \\\n0            0  ...               10             3                -1   \n1           17  ...               20            11                32   \n2           16  ...                1            29                19   \n3           30  ...                0            32                -1   \n4            4  ...               12            12                -1   \n..         ...  ...              ...           ...               ...   \n935          3  ...               15            34                30   \n936         28  ...               17            19                 2   \n937         12  ...               23             7                 3   \n938          3  ...               15            10                24   \n939          8  ...               31            22                10   \n\n     tencent200_hd  sentence_transformer_re_k  sentence_transformer_k  \\\n0                0                          3                      20   \n1                0                         27                       6   \n2                0                          7                      31   \n3                0                         10                      31   \n4                0                          9                      13   \n..             ...                        ...                     ...   \n935              0                         20                      28   \n936              0                         19                      21   \n937              0                         25                       2   \n938              0                         25                       2   \n939              0                         10                      31   \n\n     sentence_transformer_re_h  sentence_transformer_h  \\\n0                           20                      13   \n1                           15                       5   \n2                            0                      28   \n3                            4                       0   \n4                           29                      19   \n..                         ...                     ...   \n935                         16                      15   \n936                         11                       0   \n937                         10                       3   \n938                         10                       3   \n939                         12                       2   \n\n     sentence_transformer_re_hd  sentence_transformer_hd  \n0                            13                       -1  \n1                            20                       31  \n2                            -1                       -1  \n3                            31                       -1  \n4                            12                        9  \n..                          ...                      ...  \n935                           5                       -1  \n936                          10                       -1  \n937                          34                       35  \n938                          30                       -1  \n939                          29                       35  \n\n[940 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n      <th>roberta_wwm</th>\n      <th>tencent200</th>\n      <th>sentence_transformer</th>\n      <th>CBOW200_re_k</th>\n      <th>CBOW200_k</th>\n      <th>...</th>\n      <th>tencent200_re_h</th>\n      <th>tencent200_h</th>\n      <th>tencent200_re_hd</th>\n      <th>tencent200_hd</th>\n      <th>sentence_transformer_re_k</th>\n      <th>sentence_transformer_k</th>\n      <th>sentence_transformer_re_h</th>\n      <th>sentence_transformer_h</th>\n      <th>sentence_transformer_re_hd</th>\n      <th>sentence_transformer_hd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.42336562 -1.1400625 -2.0374057 -1.9194353 0....</td>\n      <td>-0.06610227 0.4988237 0.13218886 -0.77638644 1...</td>\n      <td>-0.012540849 -0.38462433 -0.32319498 -0.182240...</td>\n      <td>0.023853732 -0.09414571 -0.23024663 0.03881392...</td>\n      <td>-0.08571069687604904 0.05334413796663284 0.758...</td>\n      <td>-0.097999 -0.172532 0.674114 -0.103633 0.24910...</td>\n      <td>-0.0059281155 0.085107535 -0.018252835 0.06734...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>20</td>\n      <td>20</td>\n      <td>13</td>\n      <td>13</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>0.28802317 -0.4507514 0.35016647 -0.43055606 0...</td>\n      <td>0.12421269 0.024913808 -0.01602313 1.1140127 -...</td>\n      <td>0.19959436 -0.32069674 -0.14715314 0.061708618...</td>\n      <td>0.17186686 -0.013962293 -0.13654591 0.1969577 ...</td>\n      <td>-0.26072731614112854 0.6660227179527283 0.2643...</td>\n      <td>0.181897 0.389742 -0.06113 0.242304 -0.028627 ...</td>\n      <td>0.01048636 -0.015002572 -0.017642647 -0.040445...</td>\n      <td>24</td>\n      <td>17</td>\n      <td>...</td>\n      <td>20</td>\n      <td>11</td>\n      <td>32</td>\n      <td>0</td>\n      <td>27</td>\n      <td>6</td>\n      <td>15</td>\n      <td>5</td>\n      <td>20</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>1.1007886 -0.69985676 0.23117578 -1.8015103 -1...</td>\n      <td>0.44881797 -0.6757507 0.74121505 0.08760744 -0...</td>\n      <td>0.2180409 -0.31570902 0.16386202 -0.18676051 -...</td>\n      <td>-0.0023564755 0.14263394 -0.27440792 0.0326909...</td>\n      <td>-0.4051162004470825 0.6650103330612183 0.01912...</td>\n      <td>0.311055 0.039625 0.333128 0.215967 -0.111913 ...</td>\n      <td>-0.06143476 -0.044589818 -0.019351065 0.036645...</td>\n      <td>16</td>\n      <td>16</td>\n      <td>...</td>\n      <td>1</td>\n      <td>29</td>\n      <td>19</td>\n      <td>0</td>\n      <td>7</td>\n      <td>31</td>\n      <td>0</td>\n      <td>28</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.7827691 -0.91875976 -1.3275683 0.19824812 -0...</td>\n      <td>-0.8795247 -0.32223016 0.24907054 -0.6157134 -...</td>\n      <td>0.24405675 -0.41571265 -0.17313722 0.071001776...</td>\n      <td>0.15417029 -0.06498914 -0.15444419 -0.1932353 ...</td>\n      <td>0.0831306055188179 0.5076727867126465 0.217217...</td>\n      <td>0.266127 0.316716 0.021962 0.075516 0.086151 -...</td>\n      <td>-0.037475087 -0.01469476 -0.02024162 0.0472815...</td>\n      <td>16</td>\n      <td>30</td>\n      <td>...</td>\n      <td>0</td>\n      <td>32</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>10</td>\n      <td>31</td>\n      <td>4</td>\n      <td>0</td>\n      <td>31</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>卫浴</td>\n      <td>0.60243356 -0.9301406 -0.243199 -0.7276225 -0....</td>\n      <td>-0.12032523 0.20740871 0.35552785 0.07866025 -...</td>\n      <td>0.25761604 -0.07487154 -0.19477549 0.028649133...</td>\n      <td>0.19327797 0.098093584 0.0371605 -0.029816944 ...</td>\n      <td>-0.3666742742061615 0.4476194381713867 0.67427...</td>\n      <td>0.230336 -0.213324 0.503645 0.260184 0.126454 ...</td>\n      <td>0.028435966 -0.098250374 -0.019702565 -0.08827...</td>\n      <td>31</td>\n      <td>4</td>\n      <td>...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>13</td>\n      <td>29</td>\n      <td>19</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>935</th>\n      <td>三晚</td>\n      <td>-0.09600455 -0.24936976 0.08400188 0.089544974...</td>\n      <td>0.07487932 0.25357836 0.07852432 -0.0952891 0....</td>\n      <td>0.2406698 -0.5435254 0.10679261 0.0504834 -0.1...</td>\n      <td>0.123874895 -0.011844655 0.017515218 -0.050921...</td>\n      <td>0.22766144573688507 0.20426048338413239 0.3718...</td>\n      <td>-0.00788 0.306547 0.304058 0.261574 -0.089843 ...</td>\n      <td>0.005660566 -0.17151478 -0.012845519 0.0224691...</td>\n      <td>7</td>\n      <td>3</td>\n      <td>...</td>\n      <td>15</td>\n      <td>34</td>\n      <td>30</td>\n      <td>0</td>\n      <td>20</td>\n      <td>28</td>\n      <td>16</td>\n      <td>15</td>\n      <td>5</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>礼貌</td>\n      <td>1.1424041 0.91151 0.43261242 0.6441254 0.60611...</td>\n      <td>-0.46472156 0.32605383 -0.73007 0.9956819 -0.6...</td>\n      <td>0.30669054 -0.12392349 0.01986696 0.033570386 ...</td>\n      <td>-0.029739557 -0.0032241284 -0.1473059 0.151833...</td>\n      <td>-0.09216073155403137 0.6346340179443359 0.4351...</td>\n      <td>-0.324412 0.066763 0.139822 0.105918 -0.272539...</td>\n      <td>0.035092603 0.1269345 -0.019277968 0.072855875...</td>\n      <td>18</td>\n      <td>28</td>\n      <td>...</td>\n      <td>17</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0</td>\n      <td>19</td>\n      <td>21</td>\n      <td>11</td>\n      <td>0</td>\n      <td>10</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>937</th>\n      <td>合适</td>\n      <td>-0.42161575 -0.19991678 1.7154243 -0.1863414 -...</td>\n      <td>0.836252 0.31240836 0.034565493 -0.46289173 0....</td>\n      <td>0.12132719 -0.42330444 0.15789798 0.16709346 0...</td>\n      <td>-0.21083379 0.13041505 -0.13174589 -0.09491256...</td>\n      <td>0.039119869470596313 0.3964913487434387 -0.013...</td>\n      <td>-0.266707 0.312565 -0.102081 0.449369 -0.25977...</td>\n      <td>0.021969374 0.031377662 -0.020527236 0.0181356...</td>\n      <td>21</td>\n      <td>12</td>\n      <td>...</td>\n      <td>23</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>34</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>威斯汀</td>\n      <td>-0.28125665 0.091284014 0.24053097 -0.07472294...</td>\n      <td>0.21199425 -0.13832602 -0.09146086 -0.09332652...</td>\n      <td>-0.3902142 -0.058192953 -0.1316207 -0.21724865...</td>\n      <td>0.15095249 0.24139097 -0.13767847 -0.099240825...</td>\n      <td>-0.4285953640937805 0.3718821406364441 0.07398...</td>\n      <td>-0.099088 0.133279 -0.222177 -0.11384 -0.31356...</td>\n      <td>-0.07128871 0.10444158 -0.018124782 0.08321853...</td>\n      <td>6</td>\n      <td>3</td>\n      <td>...</td>\n      <td>15</td>\n      <td>10</td>\n      <td>24</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>30</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>自助</td>\n      <td>-0.5054578 2.0775445 1.0326135 -0.012450871 -1...</td>\n      <td>-0.755431 0.6866077 -0.060408723 -0.023249513 ...</td>\n      <td>0.12675922 0.10627268 0.045253187 0.17656054 -...</td>\n      <td>-0.22230288 0.3992527 -0.21021116 0.11118822 0...</td>\n      <td>-0.008615642786026001 0.47842586040496826 0.27...</td>\n      <td>-0.183511 -0.062141 0.210427 -0.105497 0.09846...</td>\n      <td>-0.006896859 0.028956452 -0.021312095 0.030632...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>...</td>\n      <td>31</td>\n      <td>22</td>\n      <td>10</td>\n      <td>0</td>\n      <td>10</td>\n      <td>31</td>\n      <td>12</td>\n      <td>2</td>\n      <td>29</td>\n      <td>35</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "         metric  CBOW200_re_k  CBOW200_k  CBOW200_re_h  CBOW200_h  \\\n0           dvi      0.755357   1.868656      0.777130   1.944642   \n1            sc      0.485533   0.062503      0.470005   0.054684   \n2           chs   1690.527647  25.264119   1628.450094  24.344150   \n3  class_number     35.000000  35.000000     35.000000  35.000000   \n\n   CBOW200_re_hd  CBOW200_hd  CBOW300_re_k  CBOW300_k  CBOW300_re_h  ...  \\\n0       0.667484    1.008059      0.757305   1.899508      0.765027  ...   \n1       0.539126    0.247141      0.477971   0.054602      0.474909  ...   \n2    1521.843525    8.501300   1635.542042  24.824583   1626.440177  ...   \n3      32.000000    2.000000     35.000000  35.000000     35.000000  ...   \n\n   tencent200_re_h  tencent200_h  tencent200_re_hd  tencent200_hd  \\\n0         0.866505      2.784710          0.741492       1.274969   \n1         0.386309      0.050869          0.451144       0.254959   \n2       596.139335     12.858956        644.311414      13.452291   \n3        35.000000     35.000000         36.000000       2.000000   \n\n   sentence_transformer_re_k  sentence_transformer_k  \\\n0                   0.755109                2.137338   \n1                   0.467150                0.095414   \n2                1055.220989               17.537720   \n3                  35.000000               35.000000   \n\n   sentence_transformer_re_h  sentence_transformer_h  \\\n0                   0.815374                2.213769   \n1                   0.436210                0.088782   \n2                 970.092257               17.227861   \n3                  35.000000               35.000000   \n\n   sentence_transformer_re_hd  sentence_transformer_hd  \n0                    0.708726                 1.078133  \n1                    0.473709                 0.229595  \n2                  978.633681                18.163454  \n3                   35.000000                37.000000  \n\n[4 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>CBOW200_re_k</th>\n      <th>CBOW200_k</th>\n      <th>CBOW200_re_h</th>\n      <th>CBOW200_h</th>\n      <th>CBOW200_re_hd</th>\n      <th>CBOW200_hd</th>\n      <th>CBOW300_re_k</th>\n      <th>CBOW300_k</th>\n      <th>CBOW300_re_h</th>\n      <th>...</th>\n      <th>tencent200_re_h</th>\n      <th>tencent200_h</th>\n      <th>tencent200_re_hd</th>\n      <th>tencent200_hd</th>\n      <th>sentence_transformer_re_k</th>\n      <th>sentence_transformer_k</th>\n      <th>sentence_transformer_re_h</th>\n      <th>sentence_transformer_h</th>\n      <th>sentence_transformer_re_hd</th>\n      <th>sentence_transformer_hd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dvi</td>\n      <td>0.755357</td>\n      <td>1.868656</td>\n      <td>0.777130</td>\n      <td>1.944642</td>\n      <td>0.667484</td>\n      <td>1.008059</td>\n      <td>0.757305</td>\n      <td>1.899508</td>\n      <td>0.765027</td>\n      <td>...</td>\n      <td>0.866505</td>\n      <td>2.784710</td>\n      <td>0.741492</td>\n      <td>1.274969</td>\n      <td>0.755109</td>\n      <td>2.137338</td>\n      <td>0.815374</td>\n      <td>2.213769</td>\n      <td>0.708726</td>\n      <td>1.078133</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sc</td>\n      <td>0.485533</td>\n      <td>0.062503</td>\n      <td>0.470005</td>\n      <td>0.054684</td>\n      <td>0.539126</td>\n      <td>0.247141</td>\n      <td>0.477971</td>\n      <td>0.054602</td>\n      <td>0.474909</td>\n      <td>...</td>\n      <td>0.386309</td>\n      <td>0.050869</td>\n      <td>0.451144</td>\n      <td>0.254959</td>\n      <td>0.467150</td>\n      <td>0.095414</td>\n      <td>0.436210</td>\n      <td>0.088782</td>\n      <td>0.473709</td>\n      <td>0.229595</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>chs</td>\n      <td>1690.527647</td>\n      <td>25.264119</td>\n      <td>1628.450094</td>\n      <td>24.344150</td>\n      <td>1521.843525</td>\n      <td>8.501300</td>\n      <td>1635.542042</td>\n      <td>24.824583</td>\n      <td>1626.440177</td>\n      <td>...</td>\n      <td>596.139335</td>\n      <td>12.858956</td>\n      <td>644.311414</td>\n      <td>13.452291</td>\n      <td>1055.220989</td>\n      <td>17.537720</td>\n      <td>970.092257</td>\n      <td>17.227861</td>\n      <td>978.633681</td>\n      <td>18.163454</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>class_number</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>32.000000</td>\n      <td>2.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>...</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>36.000000</td>\n      <td>2.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>37.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data.to_excel('../data/cluster_reduced_sentence.xlsx', index=False)\n",
    "metric.to_excel('../data/metric_reduced_sentence.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
