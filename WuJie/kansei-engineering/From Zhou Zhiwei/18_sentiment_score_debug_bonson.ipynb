{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((957357, 2), (439194, 2))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算情感得分，基于kansei情感词。调整计算规则，防止情感得分过大。\n",
    "'''\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "sentences = pd.read_csv('../data/sentence_sentiment_2.csv', sep='\\t')\n",
    "sentences_zero = sentences[sentences['sentiment'] == 0]\n",
    "sentences_not_zero = sentences[sentences['sentiment'] != 0]\n",
    "sentences_zero.shape, sentences_not_zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin stop length: 1395\n",
      "remove sentiment stop length: 243\n",
      "remove degree stop length: 243\n",
      "reading sentiment dict .......\n"
     ]
    }
   ],
   "source": [
    "# 读取文件，文件读取函数\n",
    "def read_file(filename):\n",
    "    # with open(filename, 'rb')as f:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # 返回list类型数据\n",
    "        text = text.split('\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "# 读取所需文件\n",
    "most = read_file(\"../data/lexicons/most.txt\")\n",
    "very = read_file(\"../data/lexicons/very.txt\")\n",
    "more = read_file(\"../data/lexicons/more.txt\")\n",
    "ish = read_file(\"../data/lexicons/ish.txt\")\n",
    "insufficiently = read_file(\"../data/lexicons/insufficiently.txt\")\n",
    "inverse = read_file(\"../data/lexicons/inverse.txt\")\n",
    "\n",
    "# 读取停用词表\n",
    "stop_words = read_file(r\"../data/baidu_stopwords.txt\")\n",
    "print('origin stop length: ' + str(len(stop_words)))\n",
    "\n",
    "# 去掉停用词中的情感词\n",
    "# 情感词与停用词有重合导致一些文本分数为0\n",
    "stop_df = pd.DataFrame(stop_words)\n",
    "senti_df = pd.read_excel('../data/8_BosonNLP_sentiment_lexicon.xlsx')\n",
    "stop_df.columns = ['word']\n",
    "duplicated = pd.merge(stop_df, senti_df, on='word')['word'].tolist()\n",
    "stop_words = list(filter(lambda x: x not in duplicated, stop_words))\n",
    "print('remove sentiment stop length: ' + str(len(stop_words)))\n",
    "\n",
    "# 去掉停用词中的程度词\n",
    "# 合并程度词\n",
    "degree_word = most + very + more + ish + insufficiently + inverse\n",
    "stop_words = list(filter(lambda x: x not in degree_word, stop_words))\n",
    "print('remove degree stop length: ' + str(len(stop_words)))\n",
    "\n",
    "\n",
    "# 读取情感词及分数\n",
    "def get_senti_word():\n",
    "    sentiment_dict = senti_df.set_index(keys='word')['sentiment'].to_dict()\n",
    "    return sentiment_dict\n",
    "\n",
    "\n",
    "# 去停用词函数\n",
    "def del_stopwords(words):\n",
    "    # 去除停用词后的句子\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "# 获取六种权值的词，根据要求返回list，这个函数是为了配合Django的views下的函数使用\n",
    "def weighted_value(request):\n",
    "    result_dict = []\n",
    "    if request == \"most\":\n",
    "        result_dict = most\n",
    "    elif request == \"very\":\n",
    "        result_dict = very\n",
    "    elif request == \"more\":\n",
    "        result_dict = more\n",
    "    elif request == \"ish\":\n",
    "        result_dict = ish\n",
    "    elif request == \"insufficiently\":\n",
    "        result_dict = insufficiently\n",
    "    elif request == \"inverse\":\n",
    "        result_dict = inverse\n",
    "    elif request == 'senti':\n",
    "        result_dict = get_senti_word()\n",
    "    # elif request == 'pos_dict':\n",
    "    #     result_dict = get_senti_word(polar='pos')\n",
    "    # elif request == 'neg_dict':\n",
    "    #     result_dict = get_senti_word(polar='neg')\n",
    "    else:\n",
    "        pass\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "print(\"reading sentiment dict .......\")\n",
    "# 读取情感词典\n",
    "senti_dict = weighted_value('senti')\n",
    "\n",
    "# 读取程度副词词典\n",
    "# 权值为2\n",
    "most_dict = weighted_value('most')\n",
    "# 权值为1.75\n",
    "very_dict = weighted_value('very')\n",
    "# 权值为1.50\n",
    "more_dict = weighted_value('more')\n",
    "# 权值为1.25\n",
    "ish_dict = weighted_value('ish')\n",
    "# 权值为0.25\n",
    "insufficient_dict = weighted_value('insufficiently')\n",
    "# 权值为-1\n",
    "inverse_dict = weighted_value('inverse')\n",
    "\n",
    "\n",
    "# 程度副词处理，对不同的程度副词给予不同的权重\n",
    "def match_adverb(word, sentiment_value):\n",
    "    # 最高级权重为\n",
    "    if word in most_dict:\n",
    "        sentiment_value *= 2\n",
    "    # 比较级权重\n",
    "    elif word in very_dict:\n",
    "        sentiment_value *= 1.75\n",
    "    # 比较级权重\n",
    "    elif word in more_dict:\n",
    "        sentiment_value *= 1.5\n",
    "    # 轻微程度词权重\n",
    "    elif word in ish_dict:\n",
    "        sentiment_value *= 1.25\n",
    "    # 相对程度词权重\n",
    "    elif word in insufficient_dict:\n",
    "        sentiment_value *= 0.25\n",
    "    # 否定词权重\n",
    "    elif word in inverse_dict:\n",
    "        sentiment_value *= -1\n",
    "    else:\n",
    "        sentiment_value *= 1\n",
    "    return sentiment_value\n",
    "\n",
    "\n",
    "# 每个句子打分\n",
    "def single_sentiment_score(sent):\n",
    "    if pd.isna(sent):\n",
    "        return -2\n",
    "    # 预处理\n",
    "    words = list(jieba.cut(sent))\n",
    "    seg_words = del_stopwords(words)\n",
    "    senti_pos = []\n",
    "    score = []\n",
    "    # 记录情感词位置\n",
    "    for i, word in enumerate(seg_words):\n",
    "        if word in senti_dict.keys():\n",
    "            senti_pos.append(i)\n",
    "\n",
    "    # 计算情感分数\n",
    "    for i in range(len(senti_pos)):\n",
    "        pos = senti_pos[i]\n",
    "        senti_word = seg_words[pos]\n",
    "        word_score = senti_dict.get(senti_word)\n",
    "        # 每个情感词的程度词范围为此情感词与上个情感词之间\n",
    "        if i == 0:\n",
    "            last_pos = 0\n",
    "        else:\n",
    "            last_pos = senti_pos[i - 1]\n",
    "\n",
    "        # 程度词范围\n",
    "        degree_range = seg_words[last_pos + 1: pos]\n",
    "        # 对程度词范围去重，出现多个相同程度词时只计算一次\n",
    "        degree_range = set(degree_range)\n",
    "        for w in degree_range:\n",
    "            word_score = match_adverb(w, word_score)\n",
    "        score.append(word_score)\n",
    "\n",
    "    sentiment_score = sum(score)\n",
    "    return sentiment_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/957357 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\62774\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.747 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 957357/957357 [00:54<00:00, 17703.19it/s]\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_6288\\1010466383.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_zero['sentiment'] = sentences_zero['sentence'].progress_apply(single_sentiment_score)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(31203, 2)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "sentences_zero['sentiment'] = sentences_zero['sentence'].progress_apply(single_sentiment_score)\n",
    "sentences_zero[sentences_zero['sentiment'] == 0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((31203, 2), (926154, 2))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boson_zero = sentences_zero[sentences_zero['sentiment'] == 0]\n",
    "boson_not_zero = sentences_zero[sentences_zero['sentiment'] != 0]\n",
    "boson_zero.shape, boson_not_zero.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_6288\\2283969600.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_not_zero['dict'] = 'kansei'\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_6288\\2283969600.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson_not_zero['dict'] = 'boson'\n"
     ]
    },
    {
     "data": {
      "text/plain": "            sentence  sentiment    dict\n0                很不错   1.000000  kansei\n3                很方便   0.913670  kansei\n4              交通很方便   1.598922  kansei\n5              房间很干净   1.750000  kansei\n6        虽然房间面积普遍都不大  -0.818779  kansei\n...              ...        ...     ...\n1396543         适合孩子   0.233304   boson\n1396544       就是房间漏水  -0.264336   boson\n1396545         没有热水  -0.113943   boson\n1396546         巴适的板   0.450991   boson\n1396550         适合商务   0.239832   boson\n\n[1365348 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n      <th>dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n      <td>1.000000</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>很方便</td>\n      <td>0.913670</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>交通很方便</td>\n      <td>1.598922</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>房间很干净</td>\n      <td>1.750000</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>虽然房间面积普遍都不大</td>\n      <td>-0.818779</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1396543</th>\n      <td>适合孩子</td>\n      <td>0.233304</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1396544</th>\n      <td>就是房间漏水</td>\n      <td>-0.264336</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1396545</th>\n      <td>没有热水</td>\n      <td>-0.113943</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1396546</th>\n      <td>巴适的板</td>\n      <td>0.450991</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1396550</th>\n      <td>适合商务</td>\n      <td>0.239832</td>\n      <td>boson</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365348 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_not_zero['dict'] = 'kansei'\n",
    "boson_not_zero['dict'] = 'boson'\n",
    "sentence_score = pd.concat([sentences_not_zero, boson_not_zero])\n",
    "sentence_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sentence_score.to_csv('../data/sentiment_score_2.csv', sep='\\t', index=False)\n",
    "boson_zero.to_csv('../data/sentiment_score_zero_2.csv', sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
