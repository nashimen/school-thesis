{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((880239, 2), (424545, 2))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算情感得分，基于boson词典。\n",
    "'''\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "sentences = pd.read_csv('../data/sentence_sentiment.csv', sep='\\t')\n",
    "sentences_zero = sentences[sentences['sentiment'] == 0]\n",
    "sentences_not_zero = sentences[sentences['sentiment'] != 0]\n",
    "sentences_zero.shape, sentences_not_zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading sentiment dict .......\n"
     ]
    }
   ],
   "source": [
    "# 读取文件，文件读取函数\n",
    "def read_file(filename):\n",
    "    # with open(filename, 'rb')as f:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # 返回list类型数据\n",
    "        text = text.split('\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "# 读取所需文件\n",
    "# 读取停用词表\n",
    "stop_words = read_file(r\"../data/baidu_stopwords.txt\")\n",
    "# 去掉停用词中的情感词 Boson\n",
    "# 情感词与停用词有重合导致一些文本分数为0\n",
    "stop_df = pd.DataFrame(stop_words)\n",
    "boson_df = pd.read_excel('../data/8_BosonNLP_sentiment_lexicon.xlsx')\n",
    "stop_df.columns = ['word']\n",
    "duplicated = pd.merge(stop_df, boson_df, on='word')['word'].tolist()\n",
    "stop_words = list(filter(lambda x: x not in duplicated, stop_words))\n",
    "\n",
    "most = read_file(\"../data/lexicons/most.txt\")\n",
    "very = read_file(\"../data/lexicons/very.txt\")\n",
    "more = read_file(\"../data/lexicons/more.txt\")\n",
    "ish = read_file(\"../data/lexicons/ish.txt\")\n",
    "insufficiently = read_file(\"../data/lexicons/insufficiently.txt\")\n",
    "inverse = read_file(\"../data/lexicons/inverse.txt\")\n",
    "\n",
    "\n",
    "# 读取情感词及分数\n",
    "def get_senti_word(polar):\n",
    "    \"\"\"\n",
    "    读取情感词，Boson或Kansei\n",
    "    :param polar: pos or neg\n",
    "    :return: {sentiment word: score}\n",
    "    \"\"\"\n",
    "\n",
    "    if polar == 'pos':\n",
    "        pos_senti = boson_df[boson_df['sentiment'] > 0]\n",
    "        senti_dict = pos_senti.set_index(keys='word')['sentiment'].to_dict()\n",
    "        return senti_dict\n",
    "    elif polar == 'neg':\n",
    "        neg_senti = boson_df[boson_df['sentiment'] < 0]\n",
    "        senti_dict = neg_senti.set_index(keys='word')['sentiment'].to_dict()\n",
    "        return senti_dict\n",
    "\n",
    "\n",
    "# 去停用词函数\n",
    "def del_stopwords(words):\n",
    "    # 去除停用词后的句子\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "# 获取六种权值的词，根据要求返回list，这个函数是为了配合Django的views下的函数使用\n",
    "def weighted_value(request):\n",
    "    result_dict = []\n",
    "    if request == \"most\":\n",
    "        result_dict = most\n",
    "    elif request == \"very\":\n",
    "        result_dict = very\n",
    "    elif request == \"more\":\n",
    "        result_dict = more\n",
    "    elif request == \"ish\":\n",
    "        result_dict = ish\n",
    "    elif request == \"insufficiently\":\n",
    "        result_dict = insufficiently\n",
    "    elif request == \"inverse\":\n",
    "        result_dict = inverse\n",
    "    elif request == 'pos_dict':\n",
    "        result_dict = get_senti_word(polar='pos')\n",
    "    elif request == 'neg_dict':\n",
    "        result_dict = get_senti_word(polar='neg')\n",
    "    else:\n",
    "        pass\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "print(\"reading sentiment dict .......\")\n",
    "# 读取情感词典\n",
    "pos_dict = weighted_value('pos_dict')\n",
    "neg_dict = weighted_value('neg_dict')\n",
    "# 读取程度副词词典\n",
    "# 权值为2\n",
    "most_dict = weighted_value('most')\n",
    "# 权值为1.75\n",
    "very_dict = weighted_value('very')\n",
    "# 权值为1.50\n",
    "more_dict = weighted_value('more')\n",
    "# 权值为1.25\n",
    "ish_dict = weighted_value('ish')\n",
    "# 权值为0.25\n",
    "insufficient_dict = weighted_value('insufficiently')\n",
    "# 权值为-1\n",
    "inverse_dict = weighted_value('inverse')\n",
    "\n",
    "\n",
    "# 程度副词处理，对不同的程度副词给予不同的权重\n",
    "def match_adverb(word, sentiment_value):\n",
    "    # 最高级权重为\n",
    "    if word in most_dict:\n",
    "        sentiment_value *= 8\n",
    "    # 比较级权重\n",
    "    elif word in very_dict:\n",
    "        sentiment_value *= 6\n",
    "    # 比较级权重\n",
    "    elif word in more_dict:\n",
    "        sentiment_value *= 4\n",
    "    # 轻微程度词权重\n",
    "    elif word in ish_dict:\n",
    "        sentiment_value *= 2\n",
    "    # 相对程度词权重\n",
    "    elif word in insufficient_dict:\n",
    "        sentiment_value *= 0.5\n",
    "    # 否定词权重\n",
    "    elif word in inverse_dict:\n",
    "        sentiment_value *= -1\n",
    "    else:\n",
    "        sentiment_value *= 1\n",
    "    return sentiment_value\n",
    "\n",
    "\n",
    "# 对每一条微博打分\n",
    "def single_sentiment_score(sent):\n",
    "    if pd.isna(sent):\n",
    "        return -2\n",
    "    # 分词\n",
    "    words = list(jieba.cut(sent))\n",
    "    seg_words = del_stopwords(words)\n",
    "    # i，s 记录情感词和程度词出现的位置\n",
    "    i = 0  # 记录扫描到的词位置\n",
    "    s = 0  # 记录情感词的位置\n",
    "    pos_score = []  # 记录正向情感分数\n",
    "    neg_score = []  # 记录负向情感分数\n",
    "\n",
    "    # 逐个查找情感词\n",
    "    for word in seg_words:\n",
    "        # 如果为积极词汇\n",
    "        if word in pos_dict.keys():\n",
    "            pos_word_score = pos_dict.get(word)\n",
    "            # 在情感词前面寻找程度副词\n",
    "            for w in seg_words[s:i]:\n",
    "                pos_word_score = match_adverb(w, pos_word_score)\n",
    "            pos_score.append(pos_word_score)\n",
    "            s = i + 1  # 记录情感词位置\n",
    "            # 如果是消极情感词\n",
    "        elif word in neg_dict.keys():\n",
    "            neg_word_score = neg_dict.get(word)\n",
    "            for w in seg_words[s:i]:\n",
    "                neg_word_score = match_adverb(w, neg_word_score)\n",
    "            neg_score.append(neg_word_score)\n",
    "            s = i + 1\n",
    "        i += 1  # 定位情感词的位置\n",
    "    # 计算情感值\n",
    "    sentiment_score = sum(pos_score) + sum(neg_score)\n",
    "\n",
    "    return sentiment_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\62774\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.662 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_10828\\358592886.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_zero['sentiment'] = sentences_zero['sentence'].apply(single_sentiment_score)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(27902, 2)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_zero['sentiment'] = sentences_zero['sentence'].apply(single_sentiment_score)\n",
    "sentences_zero[sentences_zero['sentiment'] == 0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((27902, 2), (852337, 2))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boson_zero = sentences_zero[sentences_zero['sentiment'] == 0]\n",
    "boson_not_zero = sentences_zero[sentences_zero['sentiment'] != 0]\n",
    "boson_zero.shape, boson_not_zero.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_10828\\2283969600.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_not_zero['dict'] = 'kansei'\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_10828\\2283969600.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson_not_zero['dict'] = 'boson'\n"
     ]
    },
    {
     "data": {
      "text/plain": "            sentence  sentiment    dict\n0                很不错   3.273251  kansei\n2              很好很方便  53.832072  kansei\n3              交通很方便   1.495335  kansei\n4              房间很干净   4.909877  kansei\n5        虽然房间面积普遍都不大  -0.220582  kansei\n...              ...        ...     ...\n1304777         适合孩子   0.233304   boson\n1304778       就是房间漏水  -0.264336   boson\n1304779         没有热水  -0.113943   boson\n1304780         巴适的板   0.450991   boson\n1304783         适合商务   0.239832   boson\n\n[1276882 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>sentiment</th>\n      <th>dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>很不错</td>\n      <td>3.273251</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>很好很方便</td>\n      <td>53.832072</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>交通很方便</td>\n      <td>1.495335</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>房间很干净</td>\n      <td>4.909877</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>虽然房间面积普遍都不大</td>\n      <td>-0.220582</td>\n      <td>kansei</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1304777</th>\n      <td>适合孩子</td>\n      <td>0.233304</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1304778</th>\n      <td>就是房间漏水</td>\n      <td>-0.264336</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1304779</th>\n      <td>没有热水</td>\n      <td>-0.113943</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1304780</th>\n      <td>巴适的板</td>\n      <td>0.450991</td>\n      <td>boson</td>\n    </tr>\n    <tr>\n      <th>1304783</th>\n      <td>适合商务</td>\n      <td>0.239832</td>\n      <td>boson</td>\n    </tr>\n  </tbody>\n</table>\n<p>1276882 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_not_zero['dict'] = 'kansei'\n",
    "boson_not_zero['dict'] = 'boson'\n",
    "sentence_score = pd.concat([sentences_not_zero, boson_not_zero])\n",
    "sentence_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sentence_score.to_csv('../data/sentiment_score.csv', sep='\\t')\n",
    "boson_zero.to_csv('../data/sentiment_score_zero.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
