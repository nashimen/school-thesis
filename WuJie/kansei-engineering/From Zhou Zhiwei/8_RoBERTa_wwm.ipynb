{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "生成BERT词向量，模型为 hfl/chinese-roberta-wwm-ext\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n0        交通  0.73554146 -1.6018428 -1.2404506 -1.291739 -1....   \n1        房间  0.21021058 -0.59635323 0.47715834 -0.6365312 -...   \n2        面积  0.55572355 -0.5323286 0.91498137 -2.0663414 -1...   \n3        布局  0.25501794 -0.3466378 -0.47401792 -0.14116076 ...   \n4        感觉  -0.19078201 1.6415222 -0.8261466 -0.15210226 -...   \n...     ...                                                ...   \n8225  youmi  0.11155239 0.030835023 -0.14554875 0.22515017 ...   \n8226     自助  -0.11359952 1.1666644 0.92102784 -0.43185535 -...   \n8227    超级美  -0.033927176 -0.07938691 -0.026228638 0.083482...   \n8228  jimmy  0.22390273 0.022045871 -0.037152126 0.11712757...   \n8229     不错  0.18829997 -0.38158596 0.07351275 -1.3079574 0...   \n\n                                                CBOW300  \\\n0     0.13702658 0.68759453 -0.50076807 -1.182281 1....   \n1     -0.18851501 -1.4922299 0.020221746 0.1184214 0...   \n2     0.077284776 -0.6162267 -0.19647479 0.8795282 0...   \n3     -1.1475303 0.17562264 -0.1984455 0.11604657 -0...   \n4     0.39326325 -0.04872533 -1.0128112 -0.79138595 ...   \n...                                                 ...   \n8225  0.042582456 0.14201643 -0.031047368 0.02465054...   \n8226  -0.86022395 0.4241296 -0.049184985 0.77648425 ...   \n8227  -0.005877178 0.057249628 -0.0040396433 0.04478...   \n8228  0.038666192 0.08383971 -0.032438036 0.05806949...   \n8229  0.19843362 -1.4397069 0.07930169 0.19484816 0....   \n\n                                                  SG200  \\\n0     0.13643661 -0.65482014 -0.2879653 -0.058837112...   \n1     0.15201452 -0.08642149 -0.24797179 0.12972212 ...   \n2     0.13158712 -0.17670391 0.082463704 -0.11915377...   \n3     0.032230377 -0.116721846 0.11293944 0.17366236...   \n4     0.17164549 -0.051305518 -0.48092037 0.11932772...   \n...                                                 ...   \n8225  0.35421535 -0.03280168 -0.115409225 0.233267 0...   \n8226  -0.36667868 0.28605986 0.23633607 0.097034104 ...   \n8227  -0.0026171335 -0.12006193 -0.07763223 0.206397...   \n8228  0.29591686 0.042219613 -0.02176083 0.21639612 ...   \n8229  0.035469998 -0.13442698 0.09657107 0.1424809 0...   \n\n                                                  SG300  \n0     0.25992107 0.26327625 -0.2779082 -0.03137875 -...  \n1     0.039339744 0.18192534 -0.12488792 0.016881194...  \n2     0.21622764 0.17590806 -0.30573595 0.07738382 -...  \n3     0.1252207 0.20172052 -0.04379249 0.016338833 -...  \n4     0.01354998 0.41260666 -0.2904518 -0.20739338 0...  \n...                                                 ...  \n8225  0.053210694 0.36708027 -0.009002105 0.15433264...  \n8226  0.0005533775 0.11464605 0.08450587 0.31537756 ...  \n8227  -0.012537354 0.18040492 -0.04299096 0.15100805...  \n8228  -0.026328592 0.33016804 0.014991377 0.12775822...  \n8229  0.13261823 0.15578552 -0.17663759 -0.003915232...  \n\n[8230 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.73554146 -1.6018428 -1.2404506 -1.291739 -1....</td>\n      <td>0.13702658 0.68759453 -0.50076807 -1.182281 1....</td>\n      <td>0.13643661 -0.65482014 -0.2879653 -0.058837112...</td>\n      <td>0.25992107 0.26327625 -0.2779082 -0.03137875 -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>0.21021058 -0.59635323 0.47715834 -0.6365312 -...</td>\n      <td>-0.18851501 -1.4922299 0.020221746 0.1184214 0...</td>\n      <td>0.15201452 -0.08642149 -0.24797179 0.12972212 ...</td>\n      <td>0.039339744 0.18192534 -0.12488792 0.016881194...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>0.55572355 -0.5323286 0.91498137 -2.0663414 -1...</td>\n      <td>0.077284776 -0.6162267 -0.19647479 0.8795282 0...</td>\n      <td>0.13158712 -0.17670391 0.082463704 -0.11915377...</td>\n      <td>0.21622764 0.17590806 -0.30573595 0.07738382 -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.25501794 -0.3466378 -0.47401792 -0.14116076 ...</td>\n      <td>-1.1475303 0.17562264 -0.1984455 0.11604657 -0...</td>\n      <td>0.032230377 -0.116721846 0.11293944 0.17366236...</td>\n      <td>0.1252207 0.20172052 -0.04379249 0.016338833 -...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>感觉</td>\n      <td>-0.19078201 1.6415222 -0.8261466 -0.15210226 -...</td>\n      <td>0.39326325 -0.04872533 -1.0128112 -0.79138595 ...</td>\n      <td>0.17164549 -0.051305518 -0.48092037 0.11932772...</td>\n      <td>0.01354998 0.41260666 -0.2904518 -0.20739338 0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8225</th>\n      <td>youmi</td>\n      <td>0.11155239 0.030835023 -0.14554875 0.22515017 ...</td>\n      <td>0.042582456 0.14201643 -0.031047368 0.02465054...</td>\n      <td>0.35421535 -0.03280168 -0.115409225 0.233267 0...</td>\n      <td>0.053210694 0.36708027 -0.009002105 0.15433264...</td>\n    </tr>\n    <tr>\n      <th>8226</th>\n      <td>自助</td>\n      <td>-0.11359952 1.1666644 0.92102784 -0.43185535 -...</td>\n      <td>-0.86022395 0.4241296 -0.049184985 0.77648425 ...</td>\n      <td>-0.36667868 0.28605986 0.23633607 0.097034104 ...</td>\n      <td>0.0005533775 0.11464605 0.08450587 0.31537756 ...</td>\n    </tr>\n    <tr>\n      <th>8227</th>\n      <td>超级美</td>\n      <td>-0.033927176 -0.07938691 -0.026228638 0.083482...</td>\n      <td>-0.005877178 0.057249628 -0.0040396433 0.04478...</td>\n      <td>-0.0026171335 -0.12006193 -0.07763223 0.206397...</td>\n      <td>-0.012537354 0.18040492 -0.04299096 0.15100805...</td>\n    </tr>\n    <tr>\n      <th>8228</th>\n      <td>jimmy</td>\n      <td>0.22390273 0.022045871 -0.037152126 0.11712757...</td>\n      <td>0.038666192 0.08383971 -0.032438036 0.05806949...</td>\n      <td>0.29591686 0.042219613 -0.02176083 0.21639612 ...</td>\n      <td>-0.026328592 0.33016804 0.014991377 0.12775822...</td>\n    </tr>\n    <tr>\n      <th>8229</th>\n      <td>不错</td>\n      <td>0.18829997 -0.38158596 0.07351275 -1.3079574 0...</td>\n      <td>0.19843362 -1.4397069 0.07930169 0.19484816 0....</td>\n      <td>0.035469998 -0.13442698 0.09657107 0.1424809 0...</td>\n      <td>0.13261823 0.15578552 -0.17663759 -0.003915232...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8230 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count5 = pd.read_excel('../data/word2vec_min_count_5.xlsx')\n",
    "count5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "bert_model = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "\n",
    "\n",
    "def get_word_vector(text, tokenizer, model):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    # 取出tensor中的值\n",
    "    return ' '.join([str(number) for number in output.last_hidden_state.tolist()[0][0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n0        交通  0.73554146 -1.6018428 -1.2404506 -1.291739 -1....   \n1        房间  0.21021058 -0.59635323 0.47715834 -0.6365312 -...   \n2        面积  0.55572355 -0.5323286 0.91498137 -2.0663414 -1...   \n3        布局  0.25501794 -0.3466378 -0.47401792 -0.14116076 ...   \n4        感觉  -0.19078201 1.6415222 -0.8261466 -0.15210226 -...   \n...     ...                                                ...   \n8225  youmi  0.11155239 0.030835023 -0.14554875 0.22515017 ...   \n8226     自助  -0.11359952 1.1666644 0.92102784 -0.43185535 -...   \n8227    超级美  -0.033927176 -0.07938691 -0.026228638 0.083482...   \n8228  jimmy  0.22390273 0.022045871 -0.037152126 0.11712757...   \n8229     不错  0.18829997 -0.38158596 0.07351275 -1.3079574 0...   \n\n                                                CBOW300  \\\n0     0.13702658 0.68759453 -0.50076807 -1.182281 1....   \n1     -0.18851501 -1.4922299 0.020221746 0.1184214 0...   \n2     0.077284776 -0.6162267 -0.19647479 0.8795282 0...   \n3     -1.1475303 0.17562264 -0.1984455 0.11604657 -0...   \n4     0.39326325 -0.04872533 -1.0128112 -0.79138595 ...   \n...                                                 ...   \n8225  0.042582456 0.14201643 -0.031047368 0.02465054...   \n8226  -0.86022395 0.4241296 -0.049184985 0.77648425 ...   \n8227  -0.005877178 0.057249628 -0.0040396433 0.04478...   \n8228  0.038666192 0.08383971 -0.032438036 0.05806949...   \n8229  0.19843362 -1.4397069 0.07930169 0.19484816 0....   \n\n                                                  SG200  \\\n0     0.13643661 -0.65482014 -0.2879653 -0.058837112...   \n1     0.15201452 -0.08642149 -0.24797179 0.12972212 ...   \n2     0.13158712 -0.17670391 0.082463704 -0.11915377...   \n3     0.032230377 -0.116721846 0.11293944 0.17366236...   \n4     0.17164549 -0.051305518 -0.48092037 0.11932772...   \n...                                                 ...   \n8225  0.35421535 -0.03280168 -0.115409225 0.233267 0...   \n8226  -0.36667868 0.28605986 0.23633607 0.097034104 ...   \n8227  -0.0026171335 -0.12006193 -0.07763223 0.206397...   \n8228  0.29591686 0.042219613 -0.02176083 0.21639612 ...   \n8229  0.035469998 -0.13442698 0.09657107 0.1424809 0...   \n\n                                                  SG300  \\\n0     0.25992107 0.26327625 -0.2779082 -0.03137875 -...   \n1     0.039339744 0.18192534 -0.12488792 0.016881194...   \n2     0.21622764 0.17590806 -0.30573595 0.07738382 -...   \n3     0.1252207 0.20172052 -0.04379249 0.016338833 -...   \n4     0.01354998 0.41260666 -0.2904518 -0.20739338 0...   \n...                                                 ...   \n8225  0.053210694 0.36708027 -0.009002105 0.15433264...   \n8226  0.0005533775 0.11464605 0.08450587 0.31537756 ...   \n8227  -0.012537354 0.18040492 -0.04299096 0.15100805...   \n8228  -0.026328592 0.33016804 0.014991377 0.12775822...   \n8229  0.13261823 0.15578552 -0.17663759 -0.003915232...   \n\n                                            roberta_wwm  \n0     -0.08571069687604904 0.05334413796663284 0.758...  \n1     -0.26072731614112854 0.6660227179527283 0.2643...  \n2     -0.4051162004470825 0.6650103330612183 0.01912...  \n3     0.0831306055188179 0.5076727867126465 0.217217...  \n4     0.11999122053384781 0.7110195755958557 0.17896...  \n...                                                 ...  \n8225  -0.21229173243045807 0.46409615874290466 0.693...  \n8226  -0.008615642786026001 0.47842586040496826 0.27...  \n8227  0.03943704813718796 0.38220489025115967 0.5782...  \n8228  -0.27716222405433655 0.06671187281608582 0.199...  \n8229  -0.1638607680797577 0.33768710494041443 -0.025...  \n\n[8230 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n      <th>roberta_wwm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.73554146 -1.6018428 -1.2404506 -1.291739 -1....</td>\n      <td>0.13702658 0.68759453 -0.50076807 -1.182281 1....</td>\n      <td>0.13643661 -0.65482014 -0.2879653 -0.058837112...</td>\n      <td>0.25992107 0.26327625 -0.2779082 -0.03137875 -...</td>\n      <td>-0.08571069687604904 0.05334413796663284 0.758...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>0.21021058 -0.59635323 0.47715834 -0.6365312 -...</td>\n      <td>-0.18851501 -1.4922299 0.020221746 0.1184214 0...</td>\n      <td>0.15201452 -0.08642149 -0.24797179 0.12972212 ...</td>\n      <td>0.039339744 0.18192534 -0.12488792 0.016881194...</td>\n      <td>-0.26072731614112854 0.6660227179527283 0.2643...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>0.55572355 -0.5323286 0.91498137 -2.0663414 -1...</td>\n      <td>0.077284776 -0.6162267 -0.19647479 0.8795282 0...</td>\n      <td>0.13158712 -0.17670391 0.082463704 -0.11915377...</td>\n      <td>0.21622764 0.17590806 -0.30573595 0.07738382 -...</td>\n      <td>-0.4051162004470825 0.6650103330612183 0.01912...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.25501794 -0.3466378 -0.47401792 -0.14116076 ...</td>\n      <td>-1.1475303 0.17562264 -0.1984455 0.11604657 -0...</td>\n      <td>0.032230377 -0.116721846 0.11293944 0.17366236...</td>\n      <td>0.1252207 0.20172052 -0.04379249 0.016338833 -...</td>\n      <td>0.0831306055188179 0.5076727867126465 0.217217...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>感觉</td>\n      <td>-0.19078201 1.6415222 -0.8261466 -0.15210226 -...</td>\n      <td>0.39326325 -0.04872533 -1.0128112 -0.79138595 ...</td>\n      <td>0.17164549 -0.051305518 -0.48092037 0.11932772...</td>\n      <td>0.01354998 0.41260666 -0.2904518 -0.20739338 0...</td>\n      <td>0.11999122053384781 0.7110195755958557 0.17896...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8225</th>\n      <td>youmi</td>\n      <td>0.11155239 0.030835023 -0.14554875 0.22515017 ...</td>\n      <td>0.042582456 0.14201643 -0.031047368 0.02465054...</td>\n      <td>0.35421535 -0.03280168 -0.115409225 0.233267 0...</td>\n      <td>0.053210694 0.36708027 -0.009002105 0.15433264...</td>\n      <td>-0.21229173243045807 0.46409615874290466 0.693...</td>\n    </tr>\n    <tr>\n      <th>8226</th>\n      <td>自助</td>\n      <td>-0.11359952 1.1666644 0.92102784 -0.43185535 -...</td>\n      <td>-0.86022395 0.4241296 -0.049184985 0.77648425 ...</td>\n      <td>-0.36667868 0.28605986 0.23633607 0.097034104 ...</td>\n      <td>0.0005533775 0.11464605 0.08450587 0.31537756 ...</td>\n      <td>-0.008615642786026001 0.47842586040496826 0.27...</td>\n    </tr>\n    <tr>\n      <th>8227</th>\n      <td>超级美</td>\n      <td>-0.033927176 -0.07938691 -0.026228638 0.083482...</td>\n      <td>-0.005877178 0.057249628 -0.0040396433 0.04478...</td>\n      <td>-0.0026171335 -0.12006193 -0.07763223 0.206397...</td>\n      <td>-0.012537354 0.18040492 -0.04299096 0.15100805...</td>\n      <td>0.03943704813718796 0.38220489025115967 0.5782...</td>\n    </tr>\n    <tr>\n      <th>8228</th>\n      <td>jimmy</td>\n      <td>0.22390273 0.022045871 -0.037152126 0.11712757...</td>\n      <td>0.038666192 0.08383971 -0.032438036 0.05806949...</td>\n      <td>0.29591686 0.042219613 -0.02176083 0.21639612 ...</td>\n      <td>-0.026328592 0.33016804 0.014991377 0.12775822...</td>\n      <td>-0.27716222405433655 0.06671187281608582 0.199...</td>\n    </tr>\n    <tr>\n      <th>8229</th>\n      <td>不错</td>\n      <td>0.18829997 -0.38158596 0.07351275 -1.3079574 0...</td>\n      <td>0.19843362 -1.4397069 0.07930169 0.19484816 0....</td>\n      <td>0.035469998 -0.13442698 0.09657107 0.1424809 0...</td>\n      <td>0.13261823 0.15578552 -0.17663759 -0.003915232...</td>\n      <td>-0.1638607680797577 0.33768710494041443 -0.025...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8230 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count5['roberta_wwm'] = count5['noun'].apply(\n",
    "    lambda x: get_word_vector(text=x, tokenizer=bert_tokenizer, model=bert_model))\n",
    "count5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "count5.to_excel('../data/word2vec_bert_count5.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m count1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/word2vec_min_count_1.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m count1[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroberta_wwm\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mcount1\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnoun\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_word_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbert_tokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbert_model\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m count1\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/word2vec_bert_count1.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m count1\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\kansei\\lib\\site-packages\\pandas\\core\\series.py:4433\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4324\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4325\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4328\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4329\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4331\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4332\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4431\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\kansei\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1085\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\kansei\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1137\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m         \u001B[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001B[39;00m\n\u001B[0;32m   1140\u001B[0m         \u001B[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001B[39;00m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[39;00m\n\u001B[0;32m   1142\u001B[0m         \u001B[38;5;66;03m# \"Callable[[Any], Any]\"\u001B[39;00m\n\u001B[1;32m-> 1143\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1146\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1150\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1151\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\kansei\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Input \u001B[1;32mIn [22]\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m count1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/word2vec_min_count_1.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m count1[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroberta_wwm\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m count1[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnoun\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mget_word_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbert_tokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbert_model\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      4\u001B[0m count1\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/word2vec_bert_count1.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m count1\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36mget_word_vector\u001B[1;34m(text, tokenizer, model)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_word_vector\u001B[39m(text, tokenizer, model):\n\u001B[1;32m----> 6\u001B[0m     encoded_input \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mencoded_input)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# 取出tensor中的值\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\kansei\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2260\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   2262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text):\n\u001B[1;32m-> 2263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2264\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2265\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2266\u001B[0m     )\n\u001B[0;32m   2268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text_pair):\n\u001B[0;32m   2269\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2270\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2271\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2272\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "count1 = pd.read_excel('../data/word2vec_min_count_1.xlsx')\n",
    "count1['roberta_wwm'] = count1['noun'].apply(\n",
    "    lambda x: get_word_vector(text=x, tokenizer=bert_tokenizer, model=bert_model))\n",
    "count1.to_excel('../data/word2vec_bert_count1.xlsx', index=False)\n",
    "count1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "      noun                                            CBOW200  \\\n0       交通  0.034047008 -0.18783545 -1.299804 -1.0122857 -...   \n1       房间  -0.4652253 0.3168016 1.064918 -1.3622832 -0.74...   \n2       面积  0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...   \n3       布局  0.7596806 -0.19431868 -1.7565122 0.34918287 0....   \n4       感觉  0.48554716 2.2194777 -1.6681529 0.13167356 -0....   \n...    ...                                                ...   \n32780   脸棉  -0.0021949394 -0.025893047 -0.010230103 -0.020...   \n32781  大方面  0.022226945 -0.0027089983 0.014855035 -0.00197...   \n32782  热水浴  -0.0024113338 -0.021003751 -0.012401056 0.0074...   \n32783  布草篓  0.009087267 -0.0153637715 -0.0028156568 -0.031...   \n32784   草篓  -0.0016478475 -0.020653851 -0.01576617 0.01469...   \n\n                                                 CBOW300  \\\n0      0.55288345 -0.54360896 -0.4363345 -1.3238047 0...   \n1      0.6416968 -0.2940462 -0.18148856 0.90862834 0....   \n2      0.7143586 -0.38870448 -0.018796831 -0.61379194...   \n3      -0.7559704 -0.21642762 -0.43315032 -0.7994614 ...   \n4      0.83209974 0.3728747 -0.8813452 -0.8432752 -0....   \n...                                                  ...   \n32780  0.005617186 0.007840116 -0.023488628 -0.011419...   \n32781  0.004840152 -0.0011603213 -0.00014366244 0.005...   \n32782  0.0033970366 0.011517185 -0.0016587514 0.00995...   \n32783  -0.00023642268 -0.0043262797 0.01670745 0.0031...   \n32784  -0.012592543 0.005403701 0.01280823 0.00213704...   \n\n                                                   SG200  \\\n0      0.1442148 -0.5922812 -0.47248042 0.11138987 0....   \n1      0.018209785 -0.055876106 -0.19834118 0.2606311...   \n2      0.27370095 -0.16511375 0.0072287326 0.18619563...   \n3      0.3150586 -0.3247498 -0.45332047 0.33613428 0....   \n4      0.17310351 -0.08235176 -0.3628139 0.14791599 0...   \n...                                                  ...   \n32780  -0.0018652065 -0.042670168 -0.008392116 0.0578...   \n32781  0.0055906223 -0.055725712 -0.009346191 0.03960...   \n32782  0.00067073083 -0.06620073 -0.026140908 0.06589...   \n32783  0.014281251 -0.04282407 -0.009907236 0.0466108...   \n32784  0.008987084 -0.03468274 -0.01189743 0.0593813 ...   \n\n                                                   SG300  \n0      0.28486893 0.16787495 -0.42498508 0.002507531 ...  \n1      -0.04350431 0.19495256 -0.26816666 0.116979055...  \n2      0.044400457 0.14890768 -0.2680451 0.08330627 -...  \n3      0.012324654 0.12704839 -0.13137612 0.014105521...  \n4      -0.10007713 0.41509488 -0.4150747 -0.21696614 ...  \n...                                                  ...  \n32780  0.028019082 0.09049404 -0.04824947 0.027139384...  \n32781  0.004127539 0.053255107 -0.03380062 0.02797945...  \n32782  0.023912445 0.09469688 -0.022893606 0.04118145...  \n32783  0.019315615 0.08770191 -0.026366714 0.03490781...  \n32784  0.012447481 0.07593932 -0.031280488 0.04549775...  \n\n[32785 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.034047008 -0.18783545 -1.299804 -1.0122857 -...</td>\n      <td>0.55288345 -0.54360896 -0.4363345 -1.3238047 0...</td>\n      <td>0.1442148 -0.5922812 -0.47248042 0.11138987 0....</td>\n      <td>0.28486893 0.16787495 -0.42498508 0.002507531 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>-0.4652253 0.3168016 1.064918 -1.3622832 -0.74...</td>\n      <td>0.6416968 -0.2940462 -0.18148856 0.90862834 0....</td>\n      <td>0.018209785 -0.055876106 -0.19834118 0.2606311...</td>\n      <td>-0.04350431 0.19495256 -0.26816666 0.116979055...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...</td>\n      <td>0.7143586 -0.38870448 -0.018796831 -0.61379194...</td>\n      <td>0.27370095 -0.16511375 0.0072287326 0.18619563...</td>\n      <td>0.044400457 0.14890768 -0.2680451 0.08330627 -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.7596806 -0.19431868 -1.7565122 0.34918287 0....</td>\n      <td>-0.7559704 -0.21642762 -0.43315032 -0.7994614 ...</td>\n      <td>0.3150586 -0.3247498 -0.45332047 0.33613428 0....</td>\n      <td>0.012324654 0.12704839 -0.13137612 0.014105521...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>感觉</td>\n      <td>0.48554716 2.2194777 -1.6681529 0.13167356 -0....</td>\n      <td>0.83209974 0.3728747 -0.8813452 -0.8432752 -0....</td>\n      <td>0.17310351 -0.08235176 -0.3628139 0.14791599 0...</td>\n      <td>-0.10007713 0.41509488 -0.4150747 -0.21696614 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32780</th>\n      <td>脸棉</td>\n      <td>-0.0021949394 -0.025893047 -0.010230103 -0.020...</td>\n      <td>0.005617186 0.007840116 -0.023488628 -0.011419...</td>\n      <td>-0.0018652065 -0.042670168 -0.008392116 0.0578...</td>\n      <td>0.028019082 0.09049404 -0.04824947 0.027139384...</td>\n    </tr>\n    <tr>\n      <th>32781</th>\n      <td>大方面</td>\n      <td>0.022226945 -0.0027089983 0.014855035 -0.00197...</td>\n      <td>0.004840152 -0.0011603213 -0.00014366244 0.005...</td>\n      <td>0.0055906223 -0.055725712 -0.009346191 0.03960...</td>\n      <td>0.004127539 0.053255107 -0.03380062 0.02797945...</td>\n    </tr>\n    <tr>\n      <th>32782</th>\n      <td>热水浴</td>\n      <td>-0.0024113338 -0.021003751 -0.012401056 0.0074...</td>\n      <td>0.0033970366 0.011517185 -0.0016587514 0.00995...</td>\n      <td>0.00067073083 -0.06620073 -0.026140908 0.06589...</td>\n      <td>0.023912445 0.09469688 -0.022893606 0.04118145...</td>\n    </tr>\n    <tr>\n      <th>32783</th>\n      <td>布草篓</td>\n      <td>0.009087267 -0.0153637715 -0.0028156568 -0.031...</td>\n      <td>-0.00023642268 -0.0043262797 0.01670745 0.0031...</td>\n      <td>0.014281251 -0.04282407 -0.009907236 0.0466108...</td>\n      <td>0.019315615 0.08770191 -0.026366714 0.03490781...</td>\n    </tr>\n    <tr>\n      <th>32784</th>\n      <td>草篓</td>\n      <td>-0.0016478475 -0.020653851 -0.01576617 0.01469...</td>\n      <td>-0.012592543 0.005403701 0.01280823 0.00213704...</td>\n      <td>0.008987084 -0.03468274 -0.01189743 0.0593813 ...</td>\n      <td>0.012447481 0.07593932 -0.031280488 0.04549775...</td>\n    </tr>\n  </tbody>\n</table>\n<p>32785 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(32784, 5)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1 = count1[~count1['noun'].isna()]\n",
    "count1.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_115904\\806387565.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  count1['roberta_wwm'] = count1['noun'].apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": "      noun                                            CBOW200  \\\n0       交通  0.034047008 -0.18783545 -1.299804 -1.0122857 -...   \n1       房间  -0.4652253 0.3168016 1.064918 -1.3622832 -0.74...   \n2       面积  0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...   \n3       布局  0.7596806 -0.19431868 -1.7565122 0.34918287 0....   \n4       感觉  0.48554716 2.2194777 -1.6681529 0.13167356 -0....   \n...    ...                                                ...   \n32780   脸棉  -0.0021949394 -0.025893047 -0.010230103 -0.020...   \n32781  大方面  0.022226945 -0.0027089983 0.014855035 -0.00197...   \n32782  热水浴  -0.0024113338 -0.021003751 -0.012401056 0.0074...   \n32783  布草篓  0.009087267 -0.0153637715 -0.0028156568 -0.031...   \n32784   草篓  -0.0016478475 -0.020653851 -0.01576617 0.01469...   \n\n                                                 CBOW300  \\\n0      0.55288345 -0.54360896 -0.4363345 -1.3238047 0...   \n1      0.6416968 -0.2940462 -0.18148856 0.90862834 0....   \n2      0.7143586 -0.38870448 -0.018796831 -0.61379194...   \n3      -0.7559704 -0.21642762 -0.43315032 -0.7994614 ...   \n4      0.83209974 0.3728747 -0.8813452 -0.8432752 -0....   \n...                                                  ...   \n32780  0.005617186 0.007840116 -0.023488628 -0.011419...   \n32781  0.004840152 -0.0011603213 -0.00014366244 0.005...   \n32782  0.0033970366 0.011517185 -0.0016587514 0.00995...   \n32783  -0.00023642268 -0.0043262797 0.01670745 0.0031...   \n32784  -0.012592543 0.005403701 0.01280823 0.00213704...   \n\n                                                   SG200  \\\n0      0.1442148 -0.5922812 -0.47248042 0.11138987 0....   \n1      0.018209785 -0.055876106 -0.19834118 0.2606311...   \n2      0.27370095 -0.16511375 0.0072287326 0.18619563...   \n3      0.3150586 -0.3247498 -0.45332047 0.33613428 0....   \n4      0.17310351 -0.08235176 -0.3628139 0.14791599 0...   \n...                                                  ...   \n32780  -0.0018652065 -0.042670168 -0.008392116 0.0578...   \n32781  0.0055906223 -0.055725712 -0.009346191 0.03960...   \n32782  0.00067073083 -0.06620073 -0.026140908 0.06589...   \n32783  0.014281251 -0.04282407 -0.009907236 0.0466108...   \n32784  0.008987084 -0.03468274 -0.01189743 0.0593813 ...   \n\n                                                   SG300  \\\n0      0.28486893 0.16787495 -0.42498508 0.002507531 ...   \n1      -0.04350431 0.19495256 -0.26816666 0.116979055...   \n2      0.044400457 0.14890768 -0.2680451 0.08330627 -...   \n3      0.012324654 0.12704839 -0.13137612 0.014105521...   \n4      -0.10007713 0.41509488 -0.4150747 -0.21696614 ...   \n...                                                  ...   \n32780  0.028019082 0.09049404 -0.04824947 0.027139384...   \n32781  0.004127539 0.053255107 -0.03380062 0.02797945...   \n32782  0.023912445 0.09469688 -0.022893606 0.04118145...   \n32783  0.019315615 0.08770191 -0.026366714 0.03490781...   \n32784  0.012447481 0.07593932 -0.031280488 0.04549775...   \n\n                                             roberta_wwm  \n0      -0.08571069687604904 0.05334413796663284 0.758...  \n1      -0.26072731614112854 0.6660227179527283 0.2643...  \n2      -0.4051162004470825 0.6650103330612183 0.01912...  \n3      0.0831306055188179 0.5076727867126465 0.217217...  \n4      0.11999122053384781 0.7110195755958557 0.17896...  \n...                                                  ...  \n32780  -0.7929776310920715 0.3352479636669159 0.76006...  \n32781  -0.28634223341941833 0.016626158729195595 0.18...  \n32782  -0.38922664523124695 0.9833744168281555 0.3913...  \n32783  -0.2621530592441559 0.5319876670837402 0.23312...  \n32784  -0.23708519339561462 0.3120640814304352 0.3109...  \n\n[32784 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n      <th>roberta_wwm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交通</td>\n      <td>0.034047008 -0.18783545 -1.299804 -1.0122857 -...</td>\n      <td>0.55288345 -0.54360896 -0.4363345 -1.3238047 0...</td>\n      <td>0.1442148 -0.5922812 -0.47248042 0.11138987 0....</td>\n      <td>0.28486893 0.16787495 -0.42498508 0.002507531 ...</td>\n      <td>-0.08571069687604904 0.05334413796663284 0.758...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>-0.4652253 0.3168016 1.064918 -1.3622832 -0.74...</td>\n      <td>0.6416968 -0.2940462 -0.18148856 0.90862834 0....</td>\n      <td>0.018209785 -0.055876106 -0.19834118 0.2606311...</td>\n      <td>-0.04350431 0.19495256 -0.26816666 0.116979055...</td>\n      <td>-0.26072731614112854 0.6660227179527283 0.2643...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>面积</td>\n      <td>0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...</td>\n      <td>0.7143586 -0.38870448 -0.018796831 -0.61379194...</td>\n      <td>0.27370095 -0.16511375 0.0072287326 0.18619563...</td>\n      <td>0.044400457 0.14890768 -0.2680451 0.08330627 -...</td>\n      <td>-0.4051162004470825 0.6650103330612183 0.01912...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>布局</td>\n      <td>0.7596806 -0.19431868 -1.7565122 0.34918287 0....</td>\n      <td>-0.7559704 -0.21642762 -0.43315032 -0.7994614 ...</td>\n      <td>0.3150586 -0.3247498 -0.45332047 0.33613428 0....</td>\n      <td>0.012324654 0.12704839 -0.13137612 0.014105521...</td>\n      <td>0.0831306055188179 0.5076727867126465 0.217217...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>感觉</td>\n      <td>0.48554716 2.2194777 -1.6681529 0.13167356 -0....</td>\n      <td>0.83209974 0.3728747 -0.8813452 -0.8432752 -0....</td>\n      <td>0.17310351 -0.08235176 -0.3628139 0.14791599 0...</td>\n      <td>-0.10007713 0.41509488 -0.4150747 -0.21696614 ...</td>\n      <td>0.11999122053384781 0.7110195755958557 0.17896...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32780</th>\n      <td>脸棉</td>\n      <td>-0.0021949394 -0.025893047 -0.010230103 -0.020...</td>\n      <td>0.005617186 0.007840116 -0.023488628 -0.011419...</td>\n      <td>-0.0018652065 -0.042670168 -0.008392116 0.0578...</td>\n      <td>0.028019082 0.09049404 -0.04824947 0.027139384...</td>\n      <td>-0.7929776310920715 0.3352479636669159 0.76006...</td>\n    </tr>\n    <tr>\n      <th>32781</th>\n      <td>大方面</td>\n      <td>0.022226945 -0.0027089983 0.014855035 -0.00197...</td>\n      <td>0.004840152 -0.0011603213 -0.00014366244 0.005...</td>\n      <td>0.0055906223 -0.055725712 -0.009346191 0.03960...</td>\n      <td>0.004127539 0.053255107 -0.03380062 0.02797945...</td>\n      <td>-0.28634223341941833 0.016626158729195595 0.18...</td>\n    </tr>\n    <tr>\n      <th>32782</th>\n      <td>热水浴</td>\n      <td>-0.0024113338 -0.021003751 -0.012401056 0.0074...</td>\n      <td>0.0033970366 0.011517185 -0.0016587514 0.00995...</td>\n      <td>0.00067073083 -0.06620073 -0.026140908 0.06589...</td>\n      <td>0.023912445 0.09469688 -0.022893606 0.04118145...</td>\n      <td>-0.38922664523124695 0.9833744168281555 0.3913...</td>\n    </tr>\n    <tr>\n      <th>32783</th>\n      <td>布草篓</td>\n      <td>0.009087267 -0.0153637715 -0.0028156568 -0.031...</td>\n      <td>-0.00023642268 -0.0043262797 0.01670745 0.0031...</td>\n      <td>0.014281251 -0.04282407 -0.009907236 0.0466108...</td>\n      <td>0.019315615 0.08770191 -0.026366714 0.03490781...</td>\n      <td>-0.2621530592441559 0.5319876670837402 0.23312...</td>\n    </tr>\n    <tr>\n      <th>32784</th>\n      <td>草篓</td>\n      <td>-0.0016478475 -0.020653851 -0.01576617 0.01469...</td>\n      <td>-0.012592543 0.005403701 0.01280823 0.00213704...</td>\n      <td>0.008987084 -0.03468274 -0.01189743 0.0593813 ...</td>\n      <td>0.012447481 0.07593932 -0.031280488 0.04549775...</td>\n      <td>-0.23708519339561462 0.3120640814304352 0.3109...</td>\n    </tr>\n  </tbody>\n</table>\n<p>32784 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1['roberta_wwm'] = count1['noun'].apply(\n",
    "    lambda x: get_word_vector(text=x, tokenizer=bert_tokenizer, model=bert_model))\n",
    "count1.to_excel('../data/word2vec_bert_count1.xlsx', index=False)\n",
    "count1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
