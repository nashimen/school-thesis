{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "生成word2vec词向量，min_count=1\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        corpus_path = '../data/word2vec_corpus_with_stoped_punctuation.txt'\n",
    "        for line in open(corpus_path, encoding='utf-8'):\n",
    "            yield utils.simple_preprocess(line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:08:17,873 : INFO : collecting all words and their counts\n",
      "2022-08-18 17:08:17,880 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-18 17:08:18,132 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-18 17:08:18,334 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-18 17:08:18,494 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-18 17:08:18,675 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-18 17:08:19,029 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-18 17:08:19,239 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-18 17:08:19,491 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-18 17:08:19,726 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-18 17:08:19,958 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-18 17:08:20,169 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-18 17:08:20,351 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-18 17:08:20,550 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-18 17:08:20,754 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-18 17:08:20,946 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-18 17:08:21,107 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-18 17:08:21,292 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-18 17:08:21,460 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-18 17:08:21,630 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-18 17:08:21,801 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-18 17:08:21,973 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-18 17:08:22,165 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-18 17:08:22,347 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-18 17:08:22,561 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-18 17:08:22,773 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-18 17:08:22,944 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-18 17:08:23,192 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-18 17:08:23,393 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-18 17:08:23,586 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-18 17:08:23,808 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-18 17:08:24,154 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-18 17:08:24,378 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-18 17:08:24,548 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-18 17:08:24,548 : INFO : Creating a fresh vocabulary\n",
      "2022-08-18 17:08:24,823 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 85482 unique words (100.00% of original 85482, drops 0)', 'datetime': '2022-08-18T17:08:24.823965', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:08:24,824 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3802827 word corpus (100.00% of original 3802827, drops 0)', 'datetime': '2022-08-18T17:08:24.824967', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:08:25,272 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-18 17:08:25,277 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2022-08-18 17:08:25,278 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3047573.0617451333 word corpus (80.1%% of prior 3802827)', 'datetime': '2022-08-18T17:08:25.278967', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:08:25,950 : INFO : estimated required memory for 85482 words and 200 dimensions: 179512200 bytes\n",
      "2022-08-18 17:08:25,951 : INFO : resetting layer weights\n",
      "2022-08-18 17:08:26,020 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-18T17:08:26.020974', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-18 17:08:26,021 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 85482 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-18T17:08:26.021970', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:08:27,044 : INFO : EPOCH 0 - PROGRESS: at 12.95% examples, 365135 words/s, in_qsize 1, out_qsize 1\n",
      "2022-08-18 17:08:28,079 : INFO : EPOCH 0 - PROGRESS: at 24.33% examples, 395047 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:29,082 : INFO : EPOCH 0 - PROGRESS: at 35.77% examples, 385940 words/s, in_qsize 4, out_qsize 2\n",
      "2022-08-18 17:08:30,090 : INFO : EPOCH 0 - PROGRESS: at 50.74% examples, 389470 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:08:31,093 : INFO : EPOCH 0 - PROGRESS: at 67.41% examples, 398270 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:32,094 : INFO : EPOCH 0 - PROGRESS: at 81.50% examples, 399864 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:33,106 : INFO : EPOCH 0 - PROGRESS: at 93.85% examples, 401620 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:33,582 : INFO : EPOCH 0: training on 3802827 raw words (3047032 effective words) took 7.6s, 403180 effective words/s\n",
      "2022-08-18 17:08:34,589 : INFO : EPOCH 1 - PROGRESS: at 13.08% examples, 387192 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:35,601 : INFO : EPOCH 1 - PROGRESS: at 23.55% examples, 385984 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:08:36,602 : INFO : EPOCH 1 - PROGRESS: at 37.81% examples, 409360 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:37,620 : INFO : EPOCH 1 - PROGRESS: at 52.58% examples, 404206 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:08:38,637 : INFO : EPOCH 1 - PROGRESS: at 68.57% examples, 405906 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:39,695 : INFO : EPOCH 1 - PROGRESS: at 82.60% examples, 403826 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-18 17:08:40,698 : INFO : EPOCH 1 - PROGRESS: at 95.71% examples, 409258 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:40,986 : INFO : EPOCH 1: training on 3802827 raw words (3047475 effective words) took 7.4s, 411805 effective words/s\n",
      "2022-08-18 17:08:41,995 : INFO : EPOCH 2 - PROGRESS: at 13.08% examples, 386763 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:42,997 : INFO : EPOCH 2 - PROGRESS: at 24.22% examples, 404293 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:43,998 : INFO : EPOCH 2 - PROGRESS: at 37.18% examples, 405312 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:45,012 : INFO : EPOCH 2 - PROGRESS: at 52.58% examples, 405441 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:46,045 : INFO : EPOCH 2 - PROGRESS: at 67.59% examples, 400989 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:47,049 : INFO : EPOCH 2 - PROGRESS: at 82.34% examples, 405920 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:48,058 : INFO : EPOCH 2 - PROGRESS: at 94.24% examples, 406107 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:08:48,488 : INFO : EPOCH 2: training on 3802827 raw words (3047704 effective words) took 7.5s, 406429 effective words/s\n",
      "2022-08-18 17:08:49,508 : INFO : EPOCH 3 - PROGRESS: at 13.37% examples, 414460 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:50,516 : INFO : EPOCH 3 - PROGRESS: at 25.31% examples, 421246 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:51,521 : INFO : EPOCH 3 - PROGRESS: at 38.86% examples, 418031 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:52,537 : INFO : EPOCH 3 - PROGRESS: at 53.63% examples, 408792 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:53,547 : INFO : EPOCH 3 - PROGRESS: at 69.31% examples, 408668 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:54,553 : INFO : EPOCH 3 - PROGRESS: at 83.13% examples, 409594 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:55,577 : INFO : EPOCH 3 - PROGRESS: at 93.97% examples, 402632 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:08:55,911 : INFO : EPOCH 3: training on 3802827 raw words (3047917 effective words) took 7.4s, 410736 effective words/s\n",
      "2022-08-18 17:08:56,916 : INFO : EPOCH 4 - PROGRESS: at 12.88% examples, 363261 words/s, in_qsize 5, out_qsize 1\n",
      "2022-08-18 17:08:57,933 : INFO : EPOCH 4 - PROGRESS: at 25.31% examples, 422358 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:08:58,971 : INFO : EPOCH 4 - PROGRESS: at 39.44% examples, 416763 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-18 17:08:59,980 : INFO : EPOCH 4 - PROGRESS: at 53.37% examples, 404839 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:00,983 : INFO : EPOCH 4 - PROGRESS: at 68.57% examples, 404494 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:02,044 : INFO : EPOCH 4 - PROGRESS: at 81.82% examples, 398632 words/s, in_qsize 5, out_qsize 1\n",
      "2022-08-18 17:09:03,073 : INFO : EPOCH 4 - PROGRESS: at 94.78% examples, 403253 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:09:03,343 : INFO : EPOCH 4: training on 3802827 raw words (3047828 effective words) took 7.4s, 410275 effective words/s\n",
      "2022-08-18 17:09:03,344 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (15237956 effective words) took 37.3s, 408299 effective words/s', 'datetime': '2022-08-18T17:09:03.344113', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:09:03,344 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=85482, vector_size=200, alpha=0.025>', 'datetime': '2022-08-18T17:09:03.344113', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "# CBOW 200\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=200, min_count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:09:03,361 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-ujgayi_g', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-18T17:09:03.361116', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-18 17:09:03,362 : INFO : storing np array 'vectors' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-ujgayi_g.wv.vectors.npy\n",
      "2022-08-18 17:09:03,424 : INFO : storing np array 'syn1neg' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-ujgayi_g.syn1neg.npy\n",
      "2022-08-18 17:09:03,481 : INFO : not storing attribute cum_table\n",
      "2022-08-18 17:09:03,513 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-ujgayi_g\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:09:03,533 : INFO : collecting all words and their counts\n",
      "2022-08-18 17:09:03,534 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-18 17:09:03,731 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-18 17:09:03,919 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-18 17:09:04,071 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-18 17:09:04,246 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-18 17:09:04,573 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-18 17:09:04,771 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-18 17:09:05,001 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-18 17:09:05,227 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-18 17:09:05,445 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-18 17:09:05,642 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-18 17:09:05,816 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-18 17:09:06,013 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-18 17:09:06,195 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-18 17:09:06,385 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-18 17:09:06,552 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-18 17:09:06,720 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-18 17:09:06,879 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-18 17:09:07,042 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-18 17:09:07,226 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-18 17:09:07,410 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-18 17:09:07,607 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-18 17:09:07,794 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-18 17:09:08,003 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-18 17:09:08,201 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-18 17:09:08,381 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-18 17:09:08,625 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-18 17:09:08,812 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-18 17:09:08,983 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-18 17:09:09,173 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-18 17:09:09,537 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-18 17:09:09,748 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-18 17:09:09,912 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-18 17:09:09,913 : INFO : Creating a fresh vocabulary\n",
      "2022-08-18 17:09:10,185 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 85482 unique words (100.00% of original 85482, drops 0)', 'datetime': '2022-08-18T17:09:10.185330', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:10,186 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3802827 word corpus (100.00% of original 3802827, drops 0)', 'datetime': '2022-08-18T17:09:10.186330', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:10,605 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-18 17:09:10,607 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2022-08-18 17:09:10,608 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3047573.0617451333 word corpus (80.1%% of prior 3802827)', 'datetime': '2022-08-18T17:09:10.608324', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:11,235 : INFO : estimated required memory for 85482 words and 300 dimensions: 247897800 bytes\n",
      "2022-08-18 17:09:11,236 : INFO : resetting layer weights\n",
      "2022-08-18 17:09:11,343 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-18T17:09:11.343333', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-18 17:09:11,345 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 85482 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-18T17:09:11.345326', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:09:12,381 : INFO : EPOCH 0 - PROGRESS: at 13.30% examples, 400356 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:13,404 : INFO : EPOCH 0 - PROGRESS: at 25.31% examples, 414974 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:14,433 : INFO : EPOCH 0 - PROGRESS: at 36.76% examples, 389963 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:09:15,444 : INFO : EPOCH 0 - PROGRESS: at 51.66% examples, 392368 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:09:16,461 : INFO : EPOCH 0 - PROGRESS: at 68.06% examples, 397855 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:17,471 : INFO : EPOCH 0 - PROGRESS: at 81.66% examples, 397726 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:18,476 : INFO : EPOCH 0 - PROGRESS: at 93.66% examples, 396709 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:09:18,972 : INFO : EPOCH 0: training on 3802827 raw words (3047001 effective words) took 7.6s, 399744 effective words/s\n",
      "2022-08-18 17:09:20,029 : INFO : EPOCH 1 - PROGRESS: at 12.75% examples, 329066 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:09:21,041 : INFO : EPOCH 1 - PROGRESS: at 24.22% examples, 392328 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-18 17:09:22,092 : INFO : EPOCH 1 - PROGRESS: at 37.00% examples, 388196 words/s, in_qsize 2, out_qsize 2\n",
      "2022-08-18 17:09:23,106 : INFO : EPOCH 1 - PROGRESS: at 52.58% examples, 394538 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:24,111 : INFO : EPOCH 1 - PROGRESS: at 68.06% examples, 396018 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:25,119 : INFO : EPOCH 1 - PROGRESS: at 81.82% examples, 397588 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:26,120 : INFO : EPOCH 1 - PROGRESS: at 93.97% examples, 399250 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:26,566 : INFO : EPOCH 1: training on 3802827 raw words (3047093 effective words) took 7.6s, 401413 effective words/s\n",
      "2022-08-18 17:09:27,592 : INFO : EPOCH 2 - PROGRESS: at 13.02% examples, 371524 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:28,602 : INFO : EPOCH 2 - PROGRESS: at 24.22% examples, 399202 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:29,624 : INFO : EPOCH 2 - PROGRESS: at 37.18% examples, 399018 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:30,642 : INFO : EPOCH 2 - PROGRESS: at 51.46% examples, 394825 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-18 17:09:31,660 : INFO : EPOCH 2 - PROGRESS: at 68.06% examples, 399699 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:32,679 : INFO : EPOCH 2 - PROGRESS: at 81.82% examples, 399956 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-18 17:09:33,693 : INFO : EPOCH 2 - PROGRESS: at 94.68% examples, 405191 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:34,120 : INFO : EPOCH 2: training on 3802827 raw words (3047221 effective words) took 7.6s, 403514 effective words/s\n",
      "2022-08-18 17:09:35,132 : INFO : EPOCH 3 - PROGRESS: at 13.22% examples, 401436 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:36,139 : INFO : EPOCH 3 - PROGRESS: at 24.45% examples, 406957 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:37,154 : INFO : EPOCH 3 - PROGRESS: at 37.81% examples, 407437 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:38,161 : INFO : EPOCH 3 - PROGRESS: at 51.66% examples, 398104 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:39,202 : INFO : EPOCH 3 - PROGRESS: at 67.26% examples, 395874 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:09:40,267 : INFO : EPOCH 3 - PROGRESS: at 81.66% examples, 396500 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-18 17:09:41,276 : INFO : EPOCH 3 - PROGRESS: at 93.66% examples, 395398 words/s, in_qsize 2, out_qsize 0\n",
      "2022-08-18 17:09:41,751 : INFO : EPOCH 3: training on 3802827 raw words (3048565 effective words) took 7.6s, 399670 effective words/s\n",
      "2022-08-18 17:09:42,766 : INFO : EPOCH 4 - PROGRESS: at 13.22% examples, 400392 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:43,771 : INFO : EPOCH 4 - PROGRESS: at 24.64% examples, 410775 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:44,775 : INFO : EPOCH 4 - PROGRESS: at 38.04% examples, 411506 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:45,809 : INFO : EPOCH 4 - PROGRESS: at 51.96% examples, 398278 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-18 17:09:46,833 : INFO : EPOCH 4 - PROGRESS: at 67.41% examples, 397443 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-18 17:09:47,864 : INFO : EPOCH 4 - PROGRESS: at 82.17% examples, 401228 words/s, in_qsize 1, out_qsize 0\n",
      "2022-08-18 17:09:48,875 : INFO : EPOCH 4 - PROGRESS: at 94.68% examples, 405371 words/s, in_qsize 0, out_qsize 0\n",
      "2022-08-18 17:09:49,259 : INFO : EPOCH 4: training on 3802827 raw words (3046839 effective words) took 7.5s, 406007 effective words/s\n",
      "2022-08-18 17:09:49,260 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (15236719 effective words) took 37.9s, 401873 effective words/s', 'datetime': '2022-08-18T17:09:49.260524', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:09:49,261 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=85482, vector_size=300, alpha=0.025>', 'datetime': '2022-08-18T17:09:49.261424', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# CBOW 300\n",
    "cbow300 = gensim.models.Word2Vec(sentences=sentences, vector_size=300, min_count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:09:49,277 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-5zpjpm3b', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-18T17:09:49.277432', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-18 17:09:49,278 : INFO : storing np array 'vectors' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-5zpjpm3b.wv.vectors.npy\n",
      "2022-08-18 17:09:49,367 : INFO : storing np array 'syn1neg' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-5zpjpm3b.syn1neg.npy\n",
      "2022-08-18 17:09:49,454 : INFO : not storing attribute cum_table\n",
      "2022-08-18 17:09:49,486 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-5zpjpm3b\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    cbow300.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:09:49,493 : INFO : collecting all words and their counts\n",
      "2022-08-18 17:09:49,495 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-18 17:09:49,681 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-18 17:09:49,870 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-18 17:09:50,020 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-18 17:09:50,195 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-18 17:09:50,525 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-18 17:09:50,728 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-18 17:09:50,963 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-18 17:09:51,190 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-18 17:09:51,409 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-18 17:09:51,607 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-18 17:09:51,808 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-18 17:09:52,013 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-18 17:09:52,216 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-18 17:09:52,413 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-18 17:09:52,586 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-18 17:09:52,762 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-18 17:09:52,925 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-18 17:09:53,097 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-18 17:09:53,281 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-18 17:09:53,460 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-18 17:09:53,654 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-18 17:09:53,838 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-18 17:09:54,035 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-18 17:09:54,254 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-18 17:09:54,427 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-18 17:09:54,662 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-18 17:09:54,846 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-18 17:09:55,012 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-18 17:09:55,199 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-18 17:09:55,522 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-18 17:09:55,721 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-18 17:09:55,884 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-18 17:09:55,885 : INFO : Creating a fresh vocabulary\n",
      "2022-08-18 17:09:56,147 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 85482 unique words (100.00% of original 85482, drops 0)', 'datetime': '2022-08-18T17:09:56.147034', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:56,148 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3802827 word corpus (100.00% of original 3802827, drops 0)', 'datetime': '2022-08-18T17:09:56.148035', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:56,570 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-18 17:09:56,573 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2022-08-18 17:09:56,573 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3047573.0617451333 word corpus (80.1%% of prior 3802827)', 'datetime': '2022-08-18T17:09:56.573045', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:09:57,222 : INFO : estimated required memory for 85482 words and 200 dimensions: 179512200 bytes\n",
      "2022-08-18 17:09:57,224 : INFO : resetting layer weights\n",
      "2022-08-18 17:09:57,294 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-18T17:09:57.294394', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-18 17:09:57,295 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 85482 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-18T17:09:57.295395', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:09:58,347 : INFO : EPOCH 0 - PROGRESS: at 12.07% examples, 307719 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:09:59,350 : INFO : EPOCH 0 - PROGRESS: at 20.10% examples, 323492 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:10:00,359 : INFO : EPOCH 0 - PROGRESS: at 30.33% examples, 331074 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:01,398 : INFO : EPOCH 0 - PROGRESS: at 40.65% examples, 320484 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:02,413 : INFO : EPOCH 0 - PROGRESS: at 50.97% examples, 310998 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:03,420 : INFO : EPOCH 0 - PROGRESS: at 63.31% examples, 310296 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:04,425 : INFO : EPOCH 0 - PROGRESS: at 74.51% examples, 311351 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:05,446 : INFO : EPOCH 0 - PROGRESS: at 83.77% examples, 307637 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:06,460 : INFO : EPOCH 0 - PROGRESS: at 93.74% examples, 309501 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:07,062 : INFO : EPOCH 0: training on 3802827 raw words (3047041 effective words) took 9.8s, 312050 effective words/s\n",
      "2022-08-18 17:10:08,087 : INFO : EPOCH 1 - PROGRESS: at 11.87% examples, 308112 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:10:09,118 : INFO : EPOCH 1 - PROGRESS: at 20.02% examples, 319071 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:10,156 : INFO : EPOCH 1 - PROGRESS: at 30.14% examples, 325156 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:11,167 : INFO : EPOCH 1 - PROGRESS: at 42.06% examples, 330142 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:10:12,175 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 325057 words/s, in_qsize 4, out_qsize 1\n",
      "2022-08-18 17:10:13,190 : INFO : EPOCH 1 - PROGRESS: at 63.69% examples, 311411 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:14,215 : INFO : EPOCH 1 - PROGRESS: at 74.28% examples, 309262 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:10:15,240 : INFO : EPOCH 1 - PROGRESS: at 85.16% examples, 310415 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:16,246 : INFO : EPOCH 1 - PROGRESS: at 94.24% examples, 312559 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:16,769 : INFO : EPOCH 1: training on 3802827 raw words (3046739 effective words) took 9.7s, 313973 effective words/s\n",
      "2022-08-18 17:10:17,783 : INFO : EPOCH 2 - PROGRESS: at 11.16% examples, 295633 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:18,819 : INFO : EPOCH 2 - PROGRESS: at 19.11% examples, 304241 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:19,826 : INFO : EPOCH 2 - PROGRESS: at 29.03% examples, 318695 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:20,827 : INFO : EPOCH 2 - PROGRESS: at 41.18% examples, 327981 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:21,834 : INFO : EPOCH 2 - PROGRESS: at 54.72% examples, 331148 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:22,841 : INFO : EPOCH 2 - PROGRESS: at 66.79% examples, 328361 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:10:23,846 : INFO : EPOCH 2 - PROGRESS: at 78.44% examples, 328258 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:24,849 : INFO : EPOCH 2 - PROGRESS: at 89.18% examples, 326724 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:10:25,865 : INFO : EPOCH 2 - PROGRESS: at 97.14% examples, 325419 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:26,102 : INFO : EPOCH 2: training on 3802827 raw words (3046613 effective words) took 9.3s, 326557 effective words/s\n",
      "2022-08-18 17:10:27,128 : INFO : EPOCH 3 - PROGRESS: at 12.51% examples, 331971 words/s, in_qsize 3, out_qsize 0\n",
      "2022-08-18 17:10:28,154 : INFO : EPOCH 3 - PROGRESS: at 20.69% examples, 336645 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:29,162 : INFO : EPOCH 3 - PROGRESS: at 31.87% examples, 347117 words/s, in_qsize 4, out_qsize 1\n",
      "2022-08-18 17:10:30,172 : INFO : EPOCH 3 - PROGRESS: at 45.24% examples, 354314 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:31,172 : INFO : EPOCH 3 - PROGRESS: at 59.14% examples, 354617 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:32,194 : INFO : EPOCH 3 - PROGRESS: at 72.43% examples, 355348 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:33,224 : INFO : EPOCH 3 - PROGRESS: at 83.77% examples, 352195 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:34,244 : INFO : EPOCH 3 - PROGRESS: at 94.09% examples, 351614 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:10:34,753 : INFO : EPOCH 3: training on 3802827 raw words (3047829 effective words) took 8.6s, 352421 effective words/s\n",
      "2022-08-18 17:10:35,764 : INFO : EPOCH 4 - PROGRESS: at 10.99% examples, 288736 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:36,773 : INFO : EPOCH 4 - PROGRESS: at 20.02% examples, 325045 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:37,803 : INFO : EPOCH 4 - PROGRESS: at 30.73% examples, 337979 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:38,814 : INFO : EPOCH 4 - PROGRESS: at 43.71% examples, 345467 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:39,843 : INFO : EPOCH 4 - PROGRESS: at 57.85% examples, 345166 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:40,865 : INFO : EPOCH 4 - PROGRESS: at 71.17% examples, 346037 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:41,870 : INFO : EPOCH 4 - PROGRESS: at 81.82% examples, 343459 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:42,885 : INFO : EPOCH 4 - PROGRESS: at 90.42% examples, 329730 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:10:43,908 : INFO : EPOCH 4 - PROGRESS: at 97.73% examples, 325150 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:44,116 : INFO : EPOCH 4: training on 3802827 raw words (3047432 effective words) took 9.4s, 325564 effective words/s\n",
      "2022-08-18 17:10:44,117 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (15235654 effective words) took 46.8s, 325394 effective words/s', 'datetime': '2022-08-18T17:10:44.117860', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:10:44,118 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=85482, vector_size=200, alpha=0.025>', 'datetime': '2022-08-18T17:10:44.118871', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# SG 200\n",
    "sg = gensim.models.Word2Vec(sentences=sentences, vector_size=200, sg=1, min_count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:10:44,139 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-26e860u4', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-18T17:10:44.139867', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-18 17:10:44,140 : INFO : storing np array 'vectors' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-26e860u4.wv.vectors.npy\n",
      "2022-08-18 17:10:44,202 : INFO : storing np array 'syn1neg' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-26e860u4.syn1neg.npy\n",
      "2022-08-18 17:10:44,260 : INFO : not storing attribute cum_table\n",
      "2022-08-18 17:10:44,293 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-26e860u4\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    sg.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:10:44,309 : INFO : collecting all words and their counts\n",
      "2022-08-18 17:10:44,311 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-08-18 17:10:44,519 : INFO : PROGRESS: at sentence #10000, processed 116734 words, keeping 9693 word types\n",
      "2022-08-18 17:10:44,730 : INFO : PROGRESS: at sentence #20000, processed 232533 words, keeping 14815 word types\n",
      "2022-08-18 17:10:44,892 : INFO : PROGRESS: at sentence #30000, processed 323830 words, keeping 17625 word types\n",
      "2022-08-18 17:10:45,077 : INFO : PROGRESS: at sentence #40000, processed 430437 words, keeping 20890 word types\n",
      "2022-08-18 17:10:45,436 : INFO : PROGRESS: at sentence #50000, processed 645721 words, keeping 25445 word types\n",
      "2022-08-18 17:10:45,668 : INFO : PROGRESS: at sentence #60000, processed 766681 words, keeping 29457 word types\n",
      "2022-08-18 17:10:45,916 : INFO : PROGRESS: at sentence #70000, processed 913534 words, keeping 33864 word types\n",
      "2022-08-18 17:10:46,157 : INFO : PROGRESS: at sentence #80000, processed 1052967 words, keeping 37811 word types\n",
      "2022-08-18 17:10:46,400 : INFO : PROGRESS: at sentence #90000, processed 1188138 words, keeping 40991 word types\n",
      "2022-08-18 17:10:46,601 : INFO : PROGRESS: at sentence #100000, processed 1306187 words, keeping 43415 word types\n",
      "2022-08-18 17:10:46,790 : INFO : PROGRESS: at sentence #110000, processed 1416226 words, keeping 45552 word types\n",
      "2022-08-18 17:10:47,012 : INFO : PROGRESS: at sentence #120000, processed 1537330 words, keeping 47421 word types\n",
      "2022-08-18 17:10:47,206 : INFO : PROGRESS: at sentence #130000, processed 1648222 words, keeping 49615 word types\n",
      "2022-08-18 17:10:47,411 : INFO : PROGRESS: at sentence #140000, processed 1764326 words, keeping 51719 word types\n",
      "2022-08-18 17:10:47,586 : INFO : PROGRESS: at sentence #150000, processed 1862714 words, keeping 53403 word types\n",
      "2022-08-18 17:10:47,769 : INFO : PROGRESS: at sentence #160000, processed 1965695 words, keeping 55494 word types\n",
      "2022-08-18 17:10:47,944 : INFO : PROGRESS: at sentence #170000, processed 2063439 words, keeping 57219 word types\n",
      "2022-08-18 17:10:48,110 : INFO : PROGRESS: at sentence #180000, processed 2163553 words, keeping 58856 word types\n",
      "2022-08-18 17:10:48,291 : INFO : PROGRESS: at sentence #190000, processed 2267156 words, keeping 60704 word types\n",
      "2022-08-18 17:10:48,484 : INFO : PROGRESS: at sentence #200000, processed 2368385 words, keeping 62540 word types\n",
      "2022-08-18 17:10:48,686 : INFO : PROGRESS: at sentence #210000, processed 2478304 words, keeping 64177 word types\n",
      "2022-08-18 17:10:48,892 : INFO : PROGRESS: at sentence #220000, processed 2584787 words, keeping 65807 word types\n",
      "2022-08-18 17:10:49,097 : INFO : PROGRESS: at sentence #230000, processed 2705497 words, keeping 68013 word types\n",
      "2022-08-18 17:10:49,318 : INFO : PROGRESS: at sentence #240000, processed 2820810 words, keeping 70211 word types\n",
      "2022-08-18 17:10:49,540 : INFO : PROGRESS: at sentence #250000, processed 2919640 words, keeping 71577 word types\n",
      "2022-08-18 17:10:49,780 : INFO : PROGRESS: at sentence #260000, processed 3059245 words, keeping 73704 word types\n",
      "2022-08-18 17:10:49,977 : INFO : PROGRESS: at sentence #270000, processed 3170562 words, keeping 75077 word types\n",
      "2022-08-18 17:10:50,157 : INFO : PROGRESS: at sentence #280000, processed 3271041 words, keeping 76469 word types\n",
      "2022-08-18 17:10:50,350 : INFO : PROGRESS: at sentence #290000, processed 3385159 words, keeping 78320 word types\n",
      "2022-08-18 17:10:50,773 : INFO : PROGRESS: at sentence #300000, processed 3592209 words, keeping 81866 word types\n",
      "2022-08-18 17:10:50,979 : INFO : PROGRESS: at sentence #310000, processed 3706740 words, keeping 83917 word types\n",
      "2022-08-18 17:10:51,135 : INFO : collected 85482 word types from a corpus of 3802827 raw words and 317418 sentences\n",
      "2022-08-18 17:10:51,136 : INFO : Creating a fresh vocabulary\n",
      "2022-08-18 17:10:51,406 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 85482 unique words (100.00% of original 85482, drops 0)', 'datetime': '2022-08-18T17:10:51.406938', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:10:51,407 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3802827 word corpus (100.00% of original 3802827, drops 0)', 'datetime': '2022-08-18T17:10:51.407941', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:10:51,823 : INFO : deleting the raw counts dictionary of 85482 items\n",
      "2022-08-18 17:10:51,825 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2022-08-18 17:10:51,825 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3047573.0617451333 word corpus (80.1%% of prior 3802827)', 'datetime': '2022-08-18T17:10:51.825960', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-08-18 17:10:52,482 : INFO : estimated required memory for 85482 words and 300 dimensions: 247897800 bytes\n",
      "2022-08-18 17:10:52,483 : INFO : resetting layer weights\n",
      "2022-08-18 17:10:52,609 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-18T17:10:52.609243', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-08-18 17:10:52,609 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 85482 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-18T17:10:52.609243', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:10:53,614 : INFO : EPOCH 0 - PROGRESS: at 9.42% examples, 251456 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:54,615 : INFO : EPOCH 0 - PROGRESS: at 15.56% examples, 254318 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:55,644 : INFO : EPOCH 0 - PROGRESS: at 23.71% examples, 259263 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:56,649 : INFO : EPOCH 0 - PROGRESS: at 31.87% examples, 262838 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:57,652 : INFO : EPOCH 0 - PROGRESS: at 41.88% examples, 267154 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:58,690 : INFO : EPOCH 0 - PROGRESS: at 53.01% examples, 269582 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:10:59,706 : INFO : EPOCH 0 - PROGRESS: at 64.82% examples, 273374 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:00,732 : INFO : EPOCH 0 - PROGRESS: at 74.51% examples, 273368 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:01,738 : INFO : EPOCH 0 - PROGRESS: at 83.50% examples, 273851 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:02,812 : INFO : EPOCH 0 - PROGRESS: at 93.27% examples, 272024 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:03,824 : INFO : EPOCH 0 - PROGRESS: at 100.00% examples, 271789 words/s, in_qsize 0, out_qsize 1\n",
      "2022-08-18 17:11:03,825 : INFO : EPOCH 0: training on 3802827 raw words (3047025 effective words) took 11.2s, 271761 effective words/s\n",
      "2022-08-18 17:11:04,841 : INFO : EPOCH 1 - PROGRESS: at 9.95% examples, 264356 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:05,850 : INFO : EPOCH 1 - PROGRESS: at 16.47% examples, 264255 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:06,895 : INFO : EPOCH 1 - PROGRESS: at 24.79% examples, 270164 words/s, in_qsize 4, out_qsize 1\n",
      "2022-08-18 17:11:07,900 : INFO : EPOCH 1 - PROGRESS: at 34.43% examples, 278116 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:08,904 : INFO : EPOCH 1 - PROGRESS: at 45.24% examples, 284042 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:09,928 : INFO : EPOCH 1 - PROGRESS: at 57.72% examples, 288051 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:10,955 : INFO : EPOCH 1 - PROGRESS: at 69.31% examples, 290004 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:11,972 : INFO : EPOCH 1 - PROGRESS: at 79.61% examples, 289144 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:12,975 : INFO : EPOCH 1 - PROGRESS: at 89.18% examples, 288657 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:13,975 : INFO : EPOCH 1 - PROGRESS: at 95.71% examples, 286892 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:14,421 : INFO : EPOCH 1: training on 3802827 raw words (3048053 effective words) took 10.6s, 287742 effective words/s\n",
      "2022-08-18 17:11:15,437 : INFO : EPOCH 2 - PROGRESS: at 10.99% examples, 287170 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:16,446 : INFO : EPOCH 2 - PROGRESS: at 17.98% examples, 292198 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:17,480 : INFO : EPOCH 2 - PROGRESS: at 26.38% examples, 292530 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:18,502 : INFO : EPOCH 2 - PROGRESS: at 37.00% examples, 296922 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:19,526 : INFO : EPOCH 2 - PROGRESS: at 48.29% examples, 297841 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:20,555 : INFO : EPOCH 2 - PROGRESS: at 59.85% examples, 295537 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:21,582 : INFO : EPOCH 2 - PROGRESS: at 70.64% examples, 293060 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:22,588 : INFO : EPOCH 2 - PROGRESS: at 79.61% examples, 288361 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:23,615 : INFO : EPOCH 2 - PROGRESS: at 88.87% examples, 286361 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:24,646 : INFO : EPOCH 2 - PROGRESS: at 94.68% examples, 282433 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:25,176 : INFO : EPOCH 2: training on 3802827 raw words (3047444 effective words) took 10.8s, 283423 effective words/s\n",
      "2022-08-18 17:11:26,184 : INFO : EPOCH 3 - PROGRESS: at 9.74% examples, 258310 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-18 17:11:27,219 : INFO : EPOCH 3 - PROGRESS: at 16.47% examples, 261345 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:28,229 : INFO : EPOCH 3 - PROGRESS: at 24.45% examples, 268713 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:29,271 : INFO : EPOCH 3 - PROGRESS: at 33.29% examples, 268722 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:30,274 : INFO : EPOCH 3 - PROGRESS: at 42.85% examples, 270504 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:31,274 : INFO : EPOCH 3 - PROGRESS: at 54.19% examples, 272531 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:32,292 : INFO : EPOCH 3 - PROGRESS: at 64.82% examples, 272599 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:33,325 : INFO : EPOCH 3 - PROGRESS: at 73.73% examples, 270539 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:34,325 : INFO : EPOCH 3 - PROGRESS: at 82.60% examples, 269693 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:35,365 : INFO : EPOCH 3 - PROGRESS: at 93.27% examples, 272359 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:36,266 : INFO : EPOCH 3: training on 3802827 raw words (3046968 effective words) took 11.1s, 274835 effective words/s\n",
      "2022-08-18 17:11:37,284 : INFO : EPOCH 4 - PROGRESS: at 10.99% examples, 286417 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:38,319 : INFO : EPOCH 4 - PROGRESS: at 17.70% examples, 284076 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:39,324 : INFO : EPOCH 4 - PROGRESS: at 26.00% examples, 287245 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-18 17:11:40,354 : INFO : EPOCH 4 - PROGRESS: at 35.61% examples, 286838 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:41,358 : INFO : EPOCH 4 - PROGRESS: at 45.99% examples, 287831 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:42,382 : INFO : EPOCH 4 - PROGRESS: at 57.85% examples, 287235 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:43,384 : INFO : EPOCH 4 - PROGRESS: at 66.79% examples, 280213 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:44,384 : INFO : EPOCH 4 - PROGRESS: at 76.46% examples, 279436 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:45,388 : INFO : EPOCH 4 - PROGRESS: at 85.68% examples, 280038 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:46,410 : INFO : EPOCH 4 - PROGRESS: at 93.97% examples, 281355 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-18 17:11:47,032 : INFO : EPOCH 4: training on 3802827 raw words (3047544 effective words) took 10.8s, 283120 effective words/s\n",
      "2022-08-18 17:11:47,034 : INFO : Word2Vec lifecycle event {'msg': 'training on 19014135 raw words (15237034 effective words) took 54.4s, 279969 effective words/s', 'datetime': '2022-08-18T17:11:47.034978', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-08-18 17:11:47,034 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=85482, vector_size=300, alpha=0.025>', 'datetime': '2022-08-18T17:11:47.034978', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# SG 300\n",
    "sg300 = gensim.models.Word2Vec(sentences=sentences, vector_size=300, sg=1, min_count=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:11:47,048 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'C:\\\\Users\\\\62774\\\\AppData\\\\Local\\\\Temp\\\\gensim-model-s86oeckd', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-08-18T17:11:47.048987', 'gensim': '4.2.0', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-08-18 17:11:47,049 : INFO : storing np array 'vectors' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-s86oeckd.wv.vectors.npy\n",
      "2022-08-18 17:11:47,141 : INFO : storing np array 'syn1neg' to C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-s86oeckd.syn1neg.npy\n",
      "2022-08-18 17:11:47,226 : INFO : not storing attribute cum_table\n",
      "2022-08-18 17:11:47,257 : INFO : saved C:\\Users\\62774\\AppData\\Local\\Temp\\gensim-model-s86oeckd\n"
     ]
    }
   ],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    sg300.save(temporary_filepath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Unnamed: 0\n0                                                     NaN\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[317417 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>317417 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算不同模型的名词词向量：model-CBOW200, cbow300-CBOW300 sg-SG200 sg300-SG300\n",
    "import pandas as pd\n",
    "\n",
    "nouns = pd.read_csv('../data/nouns.txt')\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    nouns\n0                                                     NaN\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[317417 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>317417 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns.columns = ['nouns']\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    nouns\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店\n5                房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图\n...                                                   ...\n317412                                                 孩子\n317413                                              房间 热水\n317414                                                  板\n317415                                                 位置\n317416                                                 商务\n\n[269156 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>269156 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = nouns[~ nouns['nouns'].isna()]\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\468032882.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns['temp'] = '1'\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                    nouns temp\n1                                 交通 房间 房间 面积 布局 感觉 卫浴 花洒    1\n2                               酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议    1\n3       好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...    1\n4                 酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店    1\n5                房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图    1\n...                                                   ...  ...\n317412                                                 孩子    1\n317413                                              房间 热水    1\n317414                                                  板    1\n317415                                                 位置    1\n317416                                                 商务    1\n\n[269156 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nouns</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通 房间 房间 面积 布局 感觉 卫浴 花洒</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>酒店 服装 餐饮 好评 早餐 宵夜 关键 贼 建议</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>好评 酒店 外观 装饰 绝绝子 房间 异味 酒店 房间 耳塞 行李 时候 小牌牌 夜宵 口味...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>酒店 位置 地铁站 大悦城 酒店 前台 小姐姐 阿姨 行李 时 时 个人 酒店</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>房间 窗户 头 酒店 水 味道 阿姨 房间 老实说 价格 位置 地铁口 特点 图</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317412</th>\n      <td>孩子</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间 热水</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>269156 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['temp'] = '1'\n",
    "nouns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       temp noun\n1         1   交通\n1         1   房间\n1         1   房间\n1         1   面积\n1         1   布局\n...     ...  ...\n317413    1   房间\n317413    1   热水\n317414    1    板\n317415    1   位置\n317416    1   商务\n\n[1365335 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp</th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>1</td>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>1</td>\n      <td>热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>1</td>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>1</td>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>1</td>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365335 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns.drop(\"nouns\", axis=1).join(\n",
    "    nouns[\"nouns\"].str.split(\" \", expand=True).stack().reset_index(level=1, drop=True).rename(\"noun\"))\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun\n1        交通\n1        房间\n1        房间\n1        面积\n1        布局\n...     ...\n317413   房间\n317413   热水\n317414    板\n317415   位置\n317416   商务\n\n[1365335 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>317413</th>\n      <td>热水</td>\n    </tr>\n    <tr>\n      <th>317414</th>\n      <td>板</td>\n    </tr>\n    <tr>\n      <th>317415</th>\n      <td>位置</td>\n    </tr>\n    <tr>\n      <th>317416</th>\n      <td>商务</td>\n    </tr>\n  </tbody>\n</table>\n<p>1365335 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split.drop('temp', axis=1)\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "             noun\n1              交通\n1              房间\n1              面积\n1              布局\n1              感觉\n...           ...\n317315        大方面\n317318  DorisFeng\n317322        热水浴\n317327        布草篓\n317327         草篓\n\n[35468 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317315</th>\n      <td>大方面</td>\n    </tr>\n    <tr>\n      <th>317318</th>\n      <td>DorisFeng</td>\n    </tr>\n    <tr>\n      <th>317322</th>\n      <td>热水浴</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>布草篓</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>草篓</td>\n    </tr>\n  </tbody>\n</table>\n<p>35468 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split.drop_duplicates(subset='noun')\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "       noun\n1        交通\n1        房间\n1        面积\n1        布局\n1        感觉\n...     ...\n317253   脸棉\n317315  大方面\n317322  热水浴\n317327  布草篓\n317327   草篓\n\n[32785 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317253</th>\n      <td>脸棉</td>\n    </tr>\n    <tr>\n      <th>317315</th>\n      <td>大方面</td>\n    </tr>\n    <tr>\n      <th>317322</th>\n      <td>热水浴</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>布草篓</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>草篓</td>\n    </tr>\n  </tbody>\n</table>\n<p>32785 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split = nouns_split[nouns_split['noun'].apply(lambda x: x in model.wv.index_to_key)]\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\3325037510.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\3325037510.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\3325037510.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\3325037510.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n"
     ]
    },
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n1        交通  [0.034047008, -0.18783545, -1.299804, -1.01228...   \n1        房间  [-0.4652253, 0.3168016, 1.064918, -1.3622832, ...   \n1        面积  [0.9510666, 0.4430117, 0.2960453, -1.9972214, ...   \n1        布局  [0.7596806, -0.19431868, -1.7565122, 0.3491828...   \n1        感觉  [0.48554716, 2.2194777, -1.6681529, 0.13167356...   \n...     ...                                                ...   \n317253   脸棉  [-0.0021949394, -0.025893047, -0.010230103, -0...   \n317315  大方面  [0.022226945, -0.0027089983, 0.014855035, -0.0...   \n317322  热水浴  [-0.0024113338, -0.021003751, -0.012401056, 0....   \n317327  布草篓  [0.009087267, -0.0153637715, -0.0028156568, -0...   \n317327   草篓  [-0.0016478475, -0.020653851, -0.01576617, 0.0...   \n\n                                                  CBOW300  \\\n1       [0.55288345, -0.54360896, -0.4363345, -1.32380...   \n1       [0.6416968, -0.2940462, -0.18148856, 0.9086283...   \n1       [0.7143586, -0.38870448, -0.018796831, -0.6137...   \n1       [-0.7559704, -0.21642762, -0.43315032, -0.7994...   \n1       [0.83209974, 0.3728747, -0.8813452, -0.8432752...   \n...                                                   ...   \n317253  [0.005617186, 0.007840116, -0.023488628, -0.01...   \n317315  [0.004840152, -0.0011603213, -0.00014366244, 0...   \n317322  [0.0033970366, 0.011517185, -0.0016587514, 0.0...   \n317327  [-0.00023642268, -0.0043262797, 0.01670745, 0....   \n317327  [-0.012592543, 0.005403701, 0.01280823, 0.0021...   \n\n                                                    SG200  \\\n1       [0.1442148, -0.5922812, -0.47248042, 0.1113898...   \n1       [0.018209785, -0.055876106, -0.19834118, 0.260...   \n1       [0.27370095, -0.16511375, 0.0072287326, 0.1861...   \n1       [0.3150586, -0.3247498, -0.45332047, 0.3361342...   \n1       [0.17310351, -0.08235176, -0.3628139, 0.147915...   \n...                                                   ...   \n317253  [-0.0018652065, -0.042670168, -0.008392116, 0....   \n317315  [0.0055906223, -0.055725712, -0.009346191, 0.0...   \n317322  [0.00067073083, -0.06620073, -0.026140908, 0.0...   \n317327  [0.014281251, -0.04282407, -0.009907236, 0.046...   \n317327  [0.008987084, -0.03468274, -0.01189743, 0.0593...   \n\n                                                    SG300  \n1       [0.28486893, 0.16787495, -0.42498508, 0.002507...  \n1       [-0.04350431, 0.19495256, -0.26816666, 0.11697...  \n1       [0.044400457, 0.14890768, -0.2680451, 0.083306...  \n1       [0.012324654, 0.12704839, -0.13137612, 0.01410...  \n1       [-0.10007713, 0.41509488, -0.4150747, -0.21696...  \n...                                                   ...  \n317253  [0.028019082, 0.09049404, -0.04824947, 0.02713...  \n317315  [0.004127539, 0.053255107, -0.03380062, 0.0279...  \n317322  [0.023912445, 0.09469688, -0.022893606, 0.0411...  \n317327  [0.019315615, 0.08770191, -0.026366714, 0.0349...  \n317327  [0.012447481, 0.07593932, -0.031280488, 0.0454...  \n\n[32785 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n      <td>[0.034047008, -0.18783545, -1.299804, -1.01228...</td>\n      <td>[0.55288345, -0.54360896, -0.4363345, -1.32380...</td>\n      <td>[0.1442148, -0.5922812, -0.47248042, 0.1113898...</td>\n      <td>[0.28486893, 0.16787495, -0.42498508, 0.002507...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>[-0.4652253, 0.3168016, 1.064918, -1.3622832, ...</td>\n      <td>[0.6416968, -0.2940462, -0.18148856, 0.9086283...</td>\n      <td>[0.018209785, -0.055876106, -0.19834118, 0.260...</td>\n      <td>[-0.04350431, 0.19495256, -0.26816666, 0.11697...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n      <td>[0.9510666, 0.4430117, 0.2960453, -1.9972214, ...</td>\n      <td>[0.7143586, -0.38870448, -0.018796831, -0.6137...</td>\n      <td>[0.27370095, -0.16511375, 0.0072287326, 0.1861...</td>\n      <td>[0.044400457, 0.14890768, -0.2680451, 0.083306...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n      <td>[0.7596806, -0.19431868, -1.7565122, 0.3491828...</td>\n      <td>[-0.7559704, -0.21642762, -0.43315032, -0.7994...</td>\n      <td>[0.3150586, -0.3247498, -0.45332047, 0.3361342...</td>\n      <td>[0.012324654, 0.12704839, -0.13137612, 0.01410...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n      <td>[0.48554716, 2.2194777, -1.6681529, 0.13167356...</td>\n      <td>[0.83209974, 0.3728747, -0.8813452, -0.8432752...</td>\n      <td>[0.17310351, -0.08235176, -0.3628139, 0.147915...</td>\n      <td>[-0.10007713, 0.41509488, -0.4150747, -0.21696...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317253</th>\n      <td>脸棉</td>\n      <td>[-0.0021949394, -0.025893047, -0.010230103, -0...</td>\n      <td>[0.005617186, 0.007840116, -0.023488628, -0.01...</td>\n      <td>[-0.0018652065, -0.042670168, -0.008392116, 0....</td>\n      <td>[0.028019082, 0.09049404, -0.04824947, 0.02713...</td>\n    </tr>\n    <tr>\n      <th>317315</th>\n      <td>大方面</td>\n      <td>[0.022226945, -0.0027089983, 0.014855035, -0.0...</td>\n      <td>[0.004840152, -0.0011603213, -0.00014366244, 0...</td>\n      <td>[0.0055906223, -0.055725712, -0.009346191, 0.0...</td>\n      <td>[0.004127539, 0.053255107, -0.03380062, 0.0279...</td>\n    </tr>\n    <tr>\n      <th>317322</th>\n      <td>热水浴</td>\n      <td>[-0.0024113338, -0.021003751, -0.012401056, 0....</td>\n      <td>[0.0033970366, 0.011517185, -0.0016587514, 0.0...</td>\n      <td>[0.00067073083, -0.06620073, -0.026140908, 0.0...</td>\n      <td>[0.023912445, 0.09469688, -0.022893606, 0.0411...</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>布草篓</td>\n      <td>[0.009087267, -0.0153637715, -0.0028156568, -0...</td>\n      <td>[-0.00023642268, -0.0043262797, 0.01670745, 0....</td>\n      <td>[0.014281251, -0.04282407, -0.009907236, 0.046...</td>\n      <td>[0.019315615, 0.08770191, -0.026366714, 0.0349...</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>草篓</td>\n      <td>[-0.0016478475, -0.020653851, -0.01576617, 0.0...</td>\n      <td>[-0.012592543, 0.005403701, 0.01280823, 0.0021...</td>\n      <td>[0.008987084, -0.03468274, -0.01189743, 0.0593...</td>\n      <td>[0.012447481, 0.07593932, -0.031280488, 0.0454...</td>\n    </tr>\n  </tbody>\n</table>\n<p>32785 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split['noun'].apply(\n",
    "    lambda x: model.wv[x]), nouns_split['noun'].apply(lambda x: cbow300.wv[x]), nouns_split['noun'].apply(\n",
    "    lambda x: sg.wv[x]), nouns_split['noun'].apply(lambda x: sg300.wv[x])\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62774\\AppData\\Local\\Temp\\ipykernel_30336\\939353274.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split[\n"
     ]
    },
    {
     "data": {
      "text/plain": "       noun                                            CBOW200  \\\n1        交通  0.034047008 -0.18783545 -1.299804 -1.0122857 -...   \n1        房间  -0.4652253 0.3168016 1.064918 -1.3622832 -0.74...   \n1        面积  0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...   \n1        布局  0.7596806 -0.19431868 -1.7565122 0.34918287 0....   \n1        感觉  0.48554716 2.2194777 -1.6681529 0.13167356 -0....   \n...     ...                                                ...   \n317253   脸棉  -0.0021949394 -0.025893047 -0.010230103 -0.020...   \n317315  大方面  0.022226945 -0.0027089983 0.014855035 -0.00197...   \n317322  热水浴  -0.0024113338 -0.021003751 -0.012401056 0.0074...   \n317327  布草篓  0.009087267 -0.0153637715 -0.0028156568 -0.031...   \n317327   草篓  -0.0016478475 -0.020653851 -0.01576617 0.01469...   \n\n                                                  CBOW300  \\\n1       0.55288345 -0.54360896 -0.4363345 -1.3238047 0...   \n1       0.6416968 -0.2940462 -0.18148856 0.90862834 0....   \n1       0.7143586 -0.38870448 -0.018796831 -0.61379194...   \n1       -0.7559704 -0.21642762 -0.43315032 -0.7994614 ...   \n1       0.83209974 0.3728747 -0.8813452 -0.8432752 -0....   \n...                                                   ...   \n317253  0.005617186 0.007840116 -0.023488628 -0.011419...   \n317315  0.004840152 -0.0011603213 -0.00014366244 0.005...   \n317322  0.0033970366 0.011517185 -0.0016587514 0.00995...   \n317327  -0.00023642268 -0.0043262797 0.01670745 0.0031...   \n317327  -0.012592543 0.005403701 0.01280823 0.00213704...   \n\n                                                    SG200  \\\n1       0.1442148 -0.5922812 -0.47248042 0.11138987 0....   \n1       0.018209785 -0.055876106 -0.19834118 0.2606311...   \n1       0.27370095 -0.16511375 0.0072287326 0.18619563...   \n1       0.3150586 -0.3247498 -0.45332047 0.33613428 0....   \n1       0.17310351 -0.08235176 -0.3628139 0.14791599 0...   \n...                                                   ...   \n317253  -0.0018652065 -0.042670168 -0.008392116 0.0578...   \n317315  0.0055906223 -0.055725712 -0.009346191 0.03960...   \n317322  0.00067073083 -0.06620073 -0.026140908 0.06589...   \n317327  0.014281251 -0.04282407 -0.009907236 0.0466108...   \n317327  0.008987084 -0.03468274 -0.01189743 0.0593813 ...   \n\n                                                    SG300  \n1       0.28486893 0.16787495 -0.42498508 0.002507531 ...  \n1       -0.04350431 0.19495256 -0.26816666 0.116979055...  \n1       0.044400457 0.14890768 -0.2680451 0.08330627 -...  \n1       0.012324654 0.12704839 -0.13137612 0.014105521...  \n1       -0.10007713 0.41509488 -0.4150747 -0.21696614 ...  \n...                                                   ...  \n317253  0.028019082 0.09049404 -0.04824947 0.027139384...  \n317315  0.004127539 0.053255107 -0.03380062 0.02797945...  \n317322  0.023912445 0.09469688 -0.022893606 0.04118145...  \n317327  0.019315615 0.08770191 -0.026366714 0.03490781...  \n317327  0.012447481 0.07593932 -0.031280488 0.04549775...  \n\n[32785 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>noun</th>\n      <th>CBOW200</th>\n      <th>CBOW300</th>\n      <th>SG200</th>\n      <th>SG300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>交通</td>\n      <td>0.034047008 -0.18783545 -1.299804 -1.0122857 -...</td>\n      <td>0.55288345 -0.54360896 -0.4363345 -1.3238047 0...</td>\n      <td>0.1442148 -0.5922812 -0.47248042 0.11138987 0....</td>\n      <td>0.28486893 0.16787495 -0.42498508 0.002507531 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>房间</td>\n      <td>-0.4652253 0.3168016 1.064918 -1.3622832 -0.74...</td>\n      <td>0.6416968 -0.2940462 -0.18148856 0.90862834 0....</td>\n      <td>0.018209785 -0.055876106 -0.19834118 0.2606311...</td>\n      <td>-0.04350431 0.19495256 -0.26816666 0.116979055...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>面积</td>\n      <td>0.9510666 0.4430117 0.2960453 -1.9972214 -1.07...</td>\n      <td>0.7143586 -0.38870448 -0.018796831 -0.61379194...</td>\n      <td>0.27370095 -0.16511375 0.0072287326 0.18619563...</td>\n      <td>0.044400457 0.14890768 -0.2680451 0.08330627 -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>布局</td>\n      <td>0.7596806 -0.19431868 -1.7565122 0.34918287 0....</td>\n      <td>-0.7559704 -0.21642762 -0.43315032 -0.7994614 ...</td>\n      <td>0.3150586 -0.3247498 -0.45332047 0.33613428 0....</td>\n      <td>0.012324654 0.12704839 -0.13137612 0.014105521...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>感觉</td>\n      <td>0.48554716 2.2194777 -1.6681529 0.13167356 -0....</td>\n      <td>0.83209974 0.3728747 -0.8813452 -0.8432752 -0....</td>\n      <td>0.17310351 -0.08235176 -0.3628139 0.14791599 0...</td>\n      <td>-0.10007713 0.41509488 -0.4150747 -0.21696614 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>317253</th>\n      <td>脸棉</td>\n      <td>-0.0021949394 -0.025893047 -0.010230103 -0.020...</td>\n      <td>0.005617186 0.007840116 -0.023488628 -0.011419...</td>\n      <td>-0.0018652065 -0.042670168 -0.008392116 0.0578...</td>\n      <td>0.028019082 0.09049404 -0.04824947 0.027139384...</td>\n    </tr>\n    <tr>\n      <th>317315</th>\n      <td>大方面</td>\n      <td>0.022226945 -0.0027089983 0.014855035 -0.00197...</td>\n      <td>0.004840152 -0.0011603213 -0.00014366244 0.005...</td>\n      <td>0.0055906223 -0.055725712 -0.009346191 0.03960...</td>\n      <td>0.004127539 0.053255107 -0.03380062 0.02797945...</td>\n    </tr>\n    <tr>\n      <th>317322</th>\n      <td>热水浴</td>\n      <td>-0.0024113338 -0.021003751 -0.012401056 0.0074...</td>\n      <td>0.0033970366 0.011517185 -0.0016587514 0.00995...</td>\n      <td>0.00067073083 -0.06620073 -0.026140908 0.06589...</td>\n      <td>0.023912445 0.09469688 -0.022893606 0.04118145...</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>布草篓</td>\n      <td>0.009087267 -0.0153637715 -0.0028156568 -0.031...</td>\n      <td>-0.00023642268 -0.0043262797 0.01670745 0.0031...</td>\n      <td>0.014281251 -0.04282407 -0.009907236 0.0466108...</td>\n      <td>0.019315615 0.08770191 -0.026366714 0.03490781...</td>\n    </tr>\n    <tr>\n      <th>317327</th>\n      <td>草篓</td>\n      <td>-0.0016478475 -0.020653851 -0.01576617 0.01469...</td>\n      <td>-0.012592543 0.005403701 0.01280823 0.00213704...</td>\n      <td>0.008987084 -0.03468274 -0.01189743 0.0593813 ...</td>\n      <td>0.012447481 0.07593932 -0.031280488 0.04549775...</td>\n    </tr>\n  </tbody>\n</table>\n<p>32785 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_split['CBOW200'], nouns_split['CBOW300'], nouns_split['SG200'], nouns_split['SG300'] = nouns_split[\n",
    "                                                                                                 'CBOW200'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['CBOW300'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['SG200'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x])), nouns_split['SG300'].apply(\n",
    "    lambda x: ' '.join([str(number) for number in x]))\n",
    "nouns_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "nouns_split.to_excel('../data/word2vec_min_count_1.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "85482"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
